[*] Reading checkpoints...
INFO:tensorflow:Restoring parameters from checkpoint\market_64_128_128\DCGAN.model-2
I0609 16:13:26.090103 28628 saver.py:1284] Restoring parameters from checkpoint\market_64_128_128\DCGAN.model-2
 [*] Success to read DCGAN.model-2
 [*] Load SUCCESS
2022-06-09 16:13:27.557795: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 67108864 exceeds 10% of system memory.
2022-06-09 16:13:27.835072: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 67108864 exceeds 10% of system memory.
2022-06-09 16:13:28.047110: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 67108864 exceeds 10% of system memory.
2022-06-09 16:13:28.162321: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 67108864 exceeds 10% of system memory.
2022-06-09 16:13:28.482709: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 67108864 exceeds 10% of system memory.
2022-06-09 16:13:35.224358: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2022-06-09 16:13:36.184721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2022-06-09 16:13:38.850215: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Internal: Invoking ptxas not supported on Windows
Relying on driver to perform ptx compilation. This message will be only logged once.
2022-06-09 16:13:39.146566: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 764.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-06-09 16:13:40.223390: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 416.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-06-09 16:13:42.132457: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 764.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-06-09 16:13:42.136449: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 764.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
Epoch: [ 0] [   0/ 202] time: 30.6695, d_loss: 12.34712601, g_loss: 0.00003809
Epoch: [ 0] [   1/ 202] time: 38.6866, d_loss: 14.86716270, g_loss: 0.00000144
Epoch: [ 0] [   2/ 202] time: 46.6818, d_loss: 14.34586525, g_loss: 0.00000344
Epoch: [ 0] [   3/ 202] time: 54.6588, d_loss: 11.03684902, g_loss: 0.00003481
Epoch: [ 0] [   4/ 202] time: 62.9222, d_loss: 15.79324055, g_loss: 0.00000189
Epoch: [ 0] [   5/ 202] time: 71.0552, d_loss: 13.96478653, g_loss: 0.00000671
Epoch: [ 0] [   6/ 202] time: 79.4718, d_loss: 13.09464741, g_loss: 0.00001882
Epoch: [ 0] [   7/ 202] time: 87.6684, d_loss: 17.35722542, g_loss: 0.00000124
Epoch: [ 0] [   8/ 202] time: 95.8690, d_loss: 20.02849388, g_loss: 0.00000008
Epoch: [ 0] [   9/ 202] time: 103.8984, d_loss: 18.62812424, g_loss: 0.00008491
Epoch: [ 0] [  10/ 202] time: 111.9612, d_loss: 15.06416988, g_loss: 0.00000173
Epoch: [ 0] [  11/ 202] time: 120.1740, d_loss: 11.24565315, g_loss: 0.00096712
Epoch: [ 0] [  12/ 202] time: 128.1720, d_loss: 13.55365753, g_loss: 0.00000794
Epoch: [ 0] [  13/ 202] time: 136.1640, d_loss: 6.94594955, g_loss: 0.08290879
Epoch: [ 0] [  14/ 202] time: 144.1825, d_loss: 14.94819641, g_loss: 0.00003910
Epoch: [ 0] [  15/ 202] time: 152.1874, d_loss: 8.45455265, g_loss: 0.07478241
Epoch: [ 0] [  16/ 202] time: 160.2962, d_loss: 13.59994411, g_loss: 0.00000713
Epoch: [ 0] [  17/ 202] time: 168.3771, d_loss: 4.84266758, g_loss: 0.23932648
Epoch: [ 0] [  18/ 202] time: 176.4950, d_loss: 12.82114220, g_loss: 0.00001237
Epoch: [ 0] [  19/ 202] time: 184.4595, d_loss: 4.38518715, g_loss: 0.93984431
Epoch: [ 0] [  20/ 202] time: 192.5265, d_loss: 13.00191975, g_loss: 0.00001557
Epoch: [ 0] [  21/ 202] time: 200.6573, d_loss: 9.30810261, g_loss: 0.00608823
Epoch: [ 0] [  22/ 202] time: 208.6692, d_loss: 17.97595406, g_loss: 0.00000796
Epoch: [ 0] [  23/ 202] time: 216.6566, d_loss: 8.41684437, g_loss: 2.76130986
Epoch: [ 0] [  24/ 202] time: 224.6697, d_loss: 11.81395817, g_loss: 0.00019293
Epoch: [ 0] [  25/ 202] time: 232.7178, d_loss: 1.97539794, g_loss: 8.57900429
Epoch: [ 0] [  26/ 202] time: 240.7069, d_loss: 13.30869007, g_loss: 0.00015618
Epoch: [ 0] [  27/ 202] time: 248.7713, d_loss: 4.97114992, g_loss: 3.15545177
Epoch: [ 0] [  28/ 202] time: 256.7446, d_loss: 12.02810001, g_loss: 0.00544642
Epoch: [ 0] [  29/ 202] time: 264.7698, d_loss: 1.76885223, g_loss: 9.32771778
Epoch: [ 0] [  30/ 202] time: 272.8573, d_loss: 9.04721642, g_loss: 0.12587768
Epoch: [ 0] [  31/ 202] time: 280.8190, d_loss: 1.27050912, g_loss: 1.84954405
Epoch: [ 0] [  32/ 202] time: 288.8122, d_loss: 14.08654308, g_loss: 0.00002024
Epoch: [ 0] [  33/ 202] time: 296.8754, d_loss: 8.64833546, g_loss: 5.30698872
Epoch: [ 0] [  34/ 202] time: 304.8604, d_loss: 9.47910500, g_loss: 0.00087840
Epoch: [ 0] [  35/ 202] time: 312.7970, d_loss: 2.30762434, g_loss: 12.89018917
Epoch: [ 0] [  36/ 202] time: 320.7874, d_loss: 0.75399125, g_loss: 10.23380470
Epoch: [ 0] [  37/ 202] time: 328.7729, d_loss: 3.98441720, g_loss: 0.17415491
Epoch: [ 0] [  38/ 202] time: 336.8734, d_loss: 10.72593880, g_loss: 0.03358725
Epoch: [ 0] [  39/ 202] time: 344.8054, d_loss: 6.59080505, g_loss: 1.36931300
Epoch: [ 0] [  40/ 202] time: 352.7684, d_loss: 6.45844841, g_loss: 1.08287668
Epoch: [ 0] [  41/ 202] time: 360.7744, d_loss: 9.20238018, g_loss: 0.29451731
Epoch: [ 0] [  42/ 202] time: 368.7818, d_loss: 5.50514984, g_loss: 0.62387860
Epoch: [ 0] [  43/ 202] time: 376.7810, d_loss: 8.43357468, g_loss: 0.06650910
Epoch: [ 0] [  44/ 202] time: 384.7621, d_loss: 8.62314129, g_loss: 0.14895990
Epoch: [ 0] [  45/ 202] time: 392.7214, d_loss: 5.95730972, g_loss: 1.03337336
Epoch: [ 0] [  46/ 202] time: 400.7712, d_loss: 8.78572083, g_loss: 0.15510580
Epoch: [ 0] [  47/ 202] time: 408.8056, d_loss: 7.93933582, g_loss: 0.01144283
Epoch: [ 0] [  48/ 202] time: 416.8505, d_loss: 5.15488052, g_loss: 1.25532365
Epoch: [ 0] [  49/ 202] time: 424.8849, d_loss: 7.37365723, g_loss: 0.40169168
Epoch: [ 0] [  50/ 202] time: 432.8531, d_loss: 5.86398077, g_loss: 0.10043547
Epoch: [ 0] [  51/ 202] time: 440.8333, d_loss: 5.51886845, g_loss: 0.10604854
Epoch: [ 0] [  52/ 202] time: 448.8953, d_loss: 5.11170101, g_loss: 0.33169937
Epoch: [ 0] [  53/ 202] time: 457.0499, d_loss: 4.35034704, g_loss: 0.45473248
Epoch: [ 0] [  54/ 202] time: 465.0503, d_loss: 5.77464771, g_loss: 0.14044283
Epoch: [ 0] [  55/ 202] time: 473.0521, d_loss: 5.17057467, g_loss: 0.26127607
Epoch: [ 0] [  56/ 202] time: 481.0980, d_loss: 4.41583061, g_loss: 0.47200266
Epoch: [ 0] [  57/ 202] time: 489.1342, d_loss: 4.26052427, g_loss: 0.28078651
Epoch: [ 0] [  58/ 202] time: 497.1579, d_loss: 2.75017977, g_loss: 0.47984812
Epoch: [ 0] [  59/ 202] time: 505.1399, d_loss: 3.01968431, g_loss: 0.24052462
Epoch: [ 0] [  60/ 202] time: 513.1806, d_loss: 3.16771650, g_loss: 0.35713130
Epoch: [ 0] [  61/ 202] time: 521.2920, d_loss: 2.09949732, g_loss: 1.24670970
Epoch: [ 0] [  62/ 202] time: 529.3652, d_loss: 2.33290458, g_loss: 1.11475980
Epoch: [ 0] [  63/ 202] time: 537.4391, d_loss: 2.07827020, g_loss: 0.56394875
Epoch: [ 0] [  64/ 202] time: 545.4959, d_loss: 2.94213486, g_loss: 0.26564980
Epoch: [ 0] [  65/ 202] time: 553.5880, d_loss: 3.24943089, g_loss: 0.47352505
Epoch: [ 0] [  66/ 202] time: 561.6838, d_loss: 1.94418836, g_loss: 1.31592333
Epoch: [ 0] [  67/ 202] time: 569.6234, d_loss: 3.57480383, g_loss: 0.49674812
Epoch: [ 0] [  68/ 202] time: 577.6545, d_loss: 3.92756248, g_loss: 0.25818309
Epoch: [ 0] [  69/ 202] time: 585.7620, d_loss: 3.52383518, g_loss: 0.28720310
Epoch: [ 0] [  70/ 202] time: 593.8571, d_loss: 3.08394694, g_loss: 0.98564279
Epoch: [ 0] [  71/ 202] time: 602.0355, d_loss: 2.47999167, g_loss: 0.30660284
Epoch: [ 0] [  72/ 202] time: 610.1294, d_loss: 2.04893756, g_loss: 0.56966329
Epoch: [ 0] [  73/ 202] time: 618.2032, d_loss: 2.57955933, g_loss: 0.52176708
Epoch: [ 0] [  74/ 202] time: 626.3125, d_loss: 2.94812059, g_loss: 0.34499753
Epoch: [ 0] [  75/ 202] time: 634.5269, d_loss: 1.90589738, g_loss: 0.70532680
Epoch: [ 0] [  76/ 202] time: 642.6496, d_loss: 2.23437619, g_loss: 0.56049931
Epoch: [ 0] [  77/ 202] time: 650.7102, d_loss: 1.69653392, g_loss: 0.65779006
Epoch: [ 0] [  78/ 202] time: 658.8479, d_loss: 1.56920290, g_loss: 1.08644032
Epoch: [ 0] [  79/ 202] time: 666.9313, d_loss: 2.13518119, g_loss: 0.49741733
Epoch: [ 0] [  80/ 202] time: 675.0137, d_loss: 1.87834466, g_loss: 0.61388218
Epoch: [ 0] [  81/ 202] time: 683.1180, d_loss: 2.34850526, g_loss: 0.33927429
Epoch: [ 0] [  82/ 202] time: 691.1719, d_loss: 2.01460171, g_loss: 0.72178161
Epoch: [ 0] [  83/ 202] time: 699.1520, d_loss: 1.95099473, g_loss: 1.15783310
Epoch: [ 0] [  84/ 202] time: 707.2206, d_loss: 3.05351090, g_loss: 0.19286074
Epoch: [ 0] [  85/ 202] time: 715.2477, d_loss: 2.00781107, g_loss: 1.10477257
Epoch: [ 0] [  86/ 202] time: 723.3507, d_loss: 1.98814952, g_loss: 0.47541633
Epoch: [ 0] [  87/ 202] time: 731.4304, d_loss: 1.68246031, g_loss: 0.66054958
Epoch: [ 0] [  88/ 202] time: 739.5527, d_loss: 2.26940918, g_loss: 0.36077455
Epoch: [ 0] [  89/ 202] time: 747.5764, d_loss: 2.70295739, g_loss: 0.34489313
Epoch: [ 0] [  90/ 202] time: 755.7013, d_loss: 1.81790757, g_loss: 0.77011573
Epoch: [ 0] [  91/ 202] time: 763.7291, d_loss: 2.33746862, g_loss: 0.33710647
Epoch: [ 0] [  92/ 202] time: 771.7762, d_loss: 3.23736453, g_loss: 0.28287259
Epoch: [ 0] [  93/ 202] time: 779.8550, d_loss: 1.83086848, g_loss: 1.35836315
Epoch: [ 0] [  94/ 202] time: 787.9223, d_loss: 1.85028291, g_loss: 0.35585922
Epoch: [ 0] [  95/ 202] time: 796.0190, d_loss: 1.60879934, g_loss: 0.74556386
Epoch: [ 0] [  96/ 202] time: 804.1050, d_loss: 2.08372831, g_loss: 0.51616287
Epoch: [ 0] [  97/ 202] time: 812.1186, d_loss: 1.90355682, g_loss: 0.93396425
Epoch: [ 0] [  98/ 202] time: 820.2727, d_loss: 1.59891140, g_loss: 0.97202373
[Sample] d_loss: 1.16504169, g_loss: 1.97564054
Epoch: [ 0] [  99/ 202] time: 830.6533, d_loss: 1.75154102, g_loss: 0.78557169
Epoch: [ 0] [ 100/ 202] time: 838.7404, d_loss: 1.82491088, g_loss: 0.57456183
Epoch: [ 0] [ 101/ 202] time: 846.8017, d_loss: 1.50092995, g_loss: 1.06977224
Epoch: [ 0] [ 102/ 202] time: 854.8417, d_loss: 2.19385719, g_loss: 0.48189977
Epoch: [ 0] [ 103/ 202] time: 862.9493, d_loss: 2.25938439, g_loss: 0.49777555
Epoch: [ 0] [ 104/ 202] time: 871.1013, d_loss: 2.05200624, g_loss: 0.81125385
Epoch: [ 0] [ 105/ 202] time: 879.1759, d_loss: 2.97126603, g_loss: 0.29515830
Epoch: [ 0] [ 106/ 202] time: 887.2070, d_loss: 3.52207685, g_loss: 0.71414500
Epoch: [ 0] [ 107/ 202] time: 895.2162, d_loss: 3.59641361, g_loss: 0.49149942
Epoch: [ 0] [ 108/ 202] time: 903.2796, d_loss: 3.33839989, g_loss: 0.72652328
Epoch: [ 0] [ 109/ 202] time: 911.3841, d_loss: 2.10819030, g_loss: 0.87997586
Epoch: [ 0] [ 110/ 202] time: 919.5090, d_loss: 1.68423617, g_loss: 0.63745046
Epoch: [ 0] [ 111/ 202] time: 927.6037, d_loss: 2.01859188, g_loss: 0.71992171
Epoch: [ 0] [ 112/ 202] time: 935.7403, d_loss: 1.32219410, g_loss: 1.20384407
Epoch: [ 0] [ 113/ 202] time: 943.8198, d_loss: 3.25223398, g_loss: 0.31511825
Epoch: [ 0] [ 114/ 202] time: 951.7981, d_loss: 1.86801982, g_loss: 0.78402734
Epoch: [ 0] [ 115/ 202] time: 959.8085, d_loss: 2.02793503, g_loss: 0.61370265
Epoch: [ 0] [ 116/ 202] time: 967.8407, d_loss: 2.04261541, g_loss: 0.43223375
Epoch: [ 0] [ 117/ 202] time: 975.9011, d_loss: 2.62583232, g_loss: 0.37063062
Epoch: [ 0] [ 118/ 202] time: 983.9672, d_loss: 1.87316620, g_loss: 0.43286192
Epoch: [ 0] [ 119/ 202] time: 991.9981, d_loss: 2.29530025, g_loss: 0.47342074
Epoch: [ 0] [ 120/ 202] time: 1000.0056, d_loss: 2.93216133, g_loss: 0.25722364
Epoch: [ 0] [ 121/ 202] time: 1008.0107, d_loss: 2.39749050, g_loss: 1.05259788
Epoch: [ 0] [ 122/ 202] time: 1016.0280, d_loss: 2.05045390, g_loss: 0.50233018
Epoch: [ 0] [ 123/ 202] time: 1024.0238, d_loss: 2.19512391, g_loss: 0.34488827
Epoch: [ 0] [ 124/ 202] time: 1032.0994, d_loss: 2.88312292, g_loss: 0.36889625
Epoch: [ 0] [ 125/ 202] time: 1040.0816, d_loss: 1.99769616, g_loss: 1.09163475
Epoch: [ 0] [ 126/ 202] time: 1048.0110, d_loss: 3.26141930, g_loss: 0.15815549
Epoch: [ 0] [ 127/ 202] time: 1055.9864, d_loss: 2.33514452, g_loss: 0.49966633
Epoch: [ 0] [ 128/ 202] time: 1064.0169, d_loss: 2.24253702, g_loss: 0.40431780
Epoch: [ 0] [ 129/ 202] time: 1072.0050, d_loss: 2.09204102, g_loss: 0.46880522
Epoch: [ 0] [ 130/ 202] time: 1079.9482, d_loss: 3.01621437, g_loss: 0.22369729
Epoch: [ 0] [ 131/ 202] time: 1087.9153, d_loss: 2.19916725, g_loss: 0.76010323
Epoch: [ 0] [ 132/ 202] time: 1095.9088, d_loss: 2.67559671, g_loss: 0.65219295
Epoch: [ 0] [ 133/ 202] time: 1103.9158, d_loss: 3.78482366, g_loss: 0.18463942
Epoch: [ 0] [ 134/ 202] time: 1111.8928, d_loss: 5.38673878, g_loss: 0.11405520
Epoch: [ 0] [ 135/ 202] time: 1119.8813, d_loss: 5.13622379, g_loss: 0.38469133
Epoch: [ 0] [ 136/ 202] time: 1127.9833, d_loss: 3.13595080, g_loss: 0.72624290
Epoch: [ 0] [ 137/ 202] time: 1136.0957, d_loss: 2.61326385, g_loss: 0.34676939
Epoch: [ 0] [ 138/ 202] time: 1144.0752, d_loss: 1.73444915, g_loss: 1.04869318
Epoch: [ 0] [ 139/ 202] time: 1152.1278, d_loss: 3.33410597, g_loss: 0.45305824
Epoch: [ 0] [ 140/ 202] time: 1160.2301, d_loss: 4.66299009, g_loss: 0.30859345
Epoch: [ 0] [ 141/ 202] time: 1168.2728, d_loss: 3.48526263, g_loss: 0.29110309
Epoch: [ 0] [ 142/ 202] time: 1176.2773, d_loss: 1.55952215, g_loss: 0.99661875
Epoch: [ 0] [ 143/ 202] time: 1184.3236, d_loss: 1.69390309, g_loss: 1.24975610
Epoch: [ 0] [ 144/ 202] time: 1192.3834, d_loss: 1.93033791, g_loss: 0.74619293
Epoch: [ 0] [ 145/ 202] time: 1200.4063, d_loss: 1.98127866, g_loss: 0.64046347
Epoch: [ 0] [ 146/ 202] time: 1208.4789, d_loss: 2.47845769, g_loss: 0.20768872
Epoch: [ 0] [ 147/ 202] time: 1216.5705, d_loss: 1.43297195, g_loss: 1.14162421
Epoch: [ 0] [ 148/ 202] time: 1224.7001, d_loss: 1.27045262, g_loss: 1.04195166
Epoch: [ 0] [ 149/ 202] time: 1232.7932, d_loss: 1.97673273, g_loss: 0.39568990
Epoch: [ 0] [ 150/ 202] time: 1240.7975, d_loss: 1.55817616, g_loss: 0.63660598
Epoch: [ 0] [ 151/ 202] time: 1248.7789, d_loss: 2.07239103, g_loss: 0.50174475
Epoch: [ 0] [ 152/ 202] time: 1256.9746, d_loss: 2.06162834, g_loss: 0.56390154
Epoch: [ 0] [ 153/ 202] time: 1265.0203, d_loss: 2.29643035, g_loss: 0.64426893
Epoch: [ 0] [ 154/ 202] time: 1273.0008, d_loss: 1.33244729, g_loss: 0.67945069
Epoch: [ 0] [ 155/ 202] time: 1280.9814, d_loss: 0.80756605, g_loss: 1.82741117
Epoch: [ 0] [ 156/ 202] time: 1289.0388, d_loss: 1.24041629, g_loss: 1.24538767
Epoch: [ 0] [ 157/ 202] time: 1297.0970, d_loss: 1.72622848, g_loss: 0.52520120
Epoch: [ 0] [ 158/ 202] time: 1305.1859, d_loss: 1.56533921, g_loss: 0.83040482
Epoch: [ 0] [ 159/ 202] time: 1313.2520, d_loss: 1.43636417, g_loss: 1.11639285
Epoch: [ 0] [ 160/ 202] time: 1321.2965, d_loss: 2.27387953, g_loss: 0.40473178
Epoch: [ 0] [ 161/ 202] time: 1329.3849, d_loss: 2.78329086, g_loss: 0.55976260
Epoch: [ 0] [ 162/ 202] time: 1337.3557, d_loss: 2.34701705, g_loss: 0.96968228
Epoch: [ 0] [ 163/ 202] time: 1345.2687, d_loss: 1.57563138, g_loss: 0.70219469
Epoch: [ 0] [ 164/ 202] time: 1353.2830, d_loss: 2.39129615, g_loss: 0.27384254
Epoch: [ 0] [ 165/ 202] time: 1361.3609, d_loss: 2.43715405, g_loss: 0.45766389
Epoch: [ 0] [ 166/ 202] time: 1369.3916, d_loss: 1.86697650, g_loss: 1.09212899
Epoch: [ 0] [ 167/ 202] time: 1377.3851, d_loss: 1.78324270, g_loss: 0.56916207
Epoch: [ 0] [ 168/ 202] time: 1385.3802, d_loss: 2.22152615, g_loss: 0.40741441
Epoch: [ 0] [ 169/ 202] time: 1393.3721, d_loss: 2.82780123, g_loss: 0.52341270
Epoch: [ 0] [ 170/ 202] time: 1401.3552, d_loss: 2.43972659, g_loss: 0.49781084
Epoch: [ 0] [ 171/ 202] time: 1409.3519, d_loss: 1.84847283, g_loss: 0.56120080
Epoch: [ 0] [ 172/ 202] time: 1417.3817, d_loss: 1.97294474, g_loss: 0.76692867
Epoch: [ 0] [ 173/ 202] time: 1425.4600, d_loss: 2.18929148, g_loss: 0.51649916
Epoch: [ 0] [ 174/ 202] time: 1433.5166, d_loss: 2.59532166, g_loss: 0.51888645
Epoch: [ 0] [ 175/ 202] time: 1441.5579, d_loss: 3.00906634, g_loss: 0.46558779
Epoch: [ 0] [ 176/ 202] time: 1449.6342, d_loss: 2.35411286, g_loss: 0.78932637
Epoch: [ 0] [ 177/ 202] time: 1457.6351, d_loss: 1.75236177, g_loss: 0.59306735
Epoch: [ 0] [ 178/ 202] time: 1465.6808, d_loss: 1.72995555, g_loss: 0.58044291
Epoch: [ 0] [ 179/ 202] time: 1473.6774, d_loss: 1.77522683, g_loss: 0.49096444
Epoch: [ 0] [ 180/ 202] time: 1481.7455, d_loss: 1.25502002, g_loss: 1.27823126
Epoch: [ 0] [ 181/ 202] time: 1490.3709, d_loss: 2.04462576, g_loss: 0.34625059
Epoch: [ 0] [ 182/ 202] time: 1498.7579, d_loss: 1.61974812, g_loss: 0.50654912
Epoch: [ 0] [ 183/ 202] time: 1507.0543, d_loss: 1.98112869, g_loss: 0.55271661
Epoch: [ 0] [ 184/ 202] time: 1515.0770, d_loss: 1.58735991, g_loss: 1.10197401
Epoch: [ 0] [ 185/ 202] time: 1523.1675, d_loss: 1.76808619, g_loss: 0.48493707
Epoch: [ 0] [ 186/ 202] time: 1531.2307, d_loss: 1.25045216, g_loss: 1.33439445
Epoch: [ 0] [ 187/ 202] time: 1539.2393, d_loss: 2.30823660, g_loss: 0.23520592
Epoch: [ 0] [ 188/ 202] time: 1547.2460, d_loss: 0.85079765, g_loss: 1.36547232
Epoch: [ 0] [ 189/ 202] time: 1555.4283, d_loss: 1.80250144, g_loss: 0.46348032
Epoch: [ 0] [ 190/ 202] time: 1563.4453, d_loss: 1.49346352, g_loss: 0.68631262
Epoch: [ 0] [ 191/ 202] time: 1571.4701, d_loss: 1.17781615, g_loss: 1.12615132
Epoch: [ 0] [ 192/ 202] time: 1579.5187, d_loss: 1.40060890, g_loss: 0.56705815
Epoch: [ 0] [ 193/ 202] time: 1587.6112, d_loss: 1.24858785, g_loss: 0.80407208
Epoch: [ 0] [ 194/ 202] time: 1595.6468, d_loss: 2.34304214, g_loss: 0.35703725
Epoch: [ 0] [ 195/ 202] time: 1603.7412, d_loss: 2.00994921, g_loss: 0.76700646
Epoch: [ 0] [ 196/ 202] time: 1611.7848, d_loss: 2.06985712, g_loss: 0.57588577
Epoch: [ 0] [ 197/ 202] time: 1619.8411, d_loss: 1.64385438, g_loss: 0.62500304
Epoch: [ 0] [ 198/ 202] time: 1627.8361, d_loss: 1.35404801, g_loss: 0.68543267
[Sample] d_loss: 1.10427678, g_loss: 1.13536203
Epoch: [ 0] [ 199/ 202] time: 1637.6731, d_loss: 1.64659393, g_loss: 0.40237039
Epoch: [ 0] [ 200/ 202] time: 1645.6757, d_loss: 1.23588789, g_loss: 1.02404130
Epoch: [ 0] [ 201/ 202] time: 1653.6875, d_loss: 1.75889277, g_loss: 0.38848877
Epoch: [ 1] [   0/ 202] time: 1662.0961, d_loss: 1.08912027, g_loss: 1.02483416
Epoch: [ 1] [   1/ 202] time: 1670.1507, d_loss: 1.62326431, g_loss: 0.54665744
Epoch: [ 1] [   2/ 202] time: 1678.1371, d_loss: 2.11091280, g_loss: 0.27360624
Epoch: [ 1] [   3/ 202] time: 1686.2562, d_loss: 1.63967240, g_loss: 0.95865452
Epoch: [ 1] [   4/ 202] time: 1694.3011, d_loss: 1.46724415, g_loss: 1.08556223
Epoch: [ 1] [   5/ 202] time: 1702.3647, d_loss: 1.66073692, g_loss: 0.64438272
Epoch: [ 1] [   6/ 202] time: 1710.3429, d_loss: 1.39063048, g_loss: 0.67698938
Epoch: [ 1] [   7/ 202] time: 1718.2897, d_loss: 1.44499815, g_loss: 0.56571376
Epoch: [ 1] [   8/ 202] time: 1726.3764, d_loss: 1.25347245, g_loss: 0.83244419
Epoch: [ 1] [   9/ 202] time: 1734.4298, d_loss: 1.48438168, g_loss: 0.83836198
Epoch: [ 1] [  10/ 202] time: 1742.4527, d_loss: 1.94244266, g_loss: 0.41665357
Epoch: [ 1] [  11/ 202] time: 1750.4366, d_loss: 1.74015355, g_loss: 0.61415058
Epoch: [ 1] [  12/ 202] time: 1758.4313, d_loss: 1.29294300, g_loss: 1.13779855
Epoch: [ 1] [  13/ 202] time: 1766.4408, d_loss: 1.45286882, g_loss: 0.81662309
Epoch: [ 1] [  14/ 202] time: 1774.5347, d_loss: 1.10940301, g_loss: 1.22236538
Epoch: [ 1] [  15/ 202] time: 1782.5659, d_loss: 1.09548616, g_loss: 1.48594224
Epoch: [ 1] [  16/ 202] time: 1790.5737, d_loss: 0.91524196, g_loss: 1.03786623
Epoch: [ 1] [  17/ 202] time: 1798.6557, d_loss: 0.73753345, g_loss: 1.16415727
Epoch: [ 1] [  18/ 202] time: 1806.7157, d_loss: 1.16645598, g_loss: 0.88978589
Epoch: [ 1] [  19/ 202] time: 1814.7107, d_loss: 1.31888926, g_loss: 0.80573094
Epoch: [ 1] [  20/ 202] time: 1822.7265, d_loss: 1.65929115, g_loss: 0.46656379
Epoch: [ 1] [  21/ 202] time: 1830.7227, d_loss: 0.90235603, g_loss: 1.14726233
Epoch: [ 1] [  22/ 202] time: 1838.7557, d_loss: 1.80719995, g_loss: 0.67652118
Epoch: [ 1] [  23/ 202] time: 1846.7353, d_loss: 1.65308261, g_loss: 0.66138136
Epoch: [ 1] [  24/ 202] time: 1854.8308, d_loss: 0.86700839, g_loss: 1.36188042
Epoch: [ 1] [  25/ 202] time: 1862.9127, d_loss: 1.72895360, g_loss: 0.46288526
Epoch: [ 1] [  26/ 202] time: 1870.9772, d_loss: 1.98877919, g_loss: 0.37701055
Epoch: [ 1] [  27/ 202] time: 1879.0446, d_loss: 1.63379908, g_loss: 0.98578060
Epoch: [ 1] [  28/ 202] time: 1887.0638, d_loss: 2.12180567, g_loss: 0.58817959
Epoch: [ 1] [  29/ 202] time: 1895.2591, d_loss: 1.38307333, g_loss: 0.80084282
Epoch: [ 1] [  30/ 202] time: 1903.4463, d_loss: 1.73152351, g_loss: 0.70771587
Epoch: [ 1] [  31/ 202] time: 1911.5258, d_loss: 1.45027971, g_loss: 0.81763506
Epoch: [ 1] [  32/ 202] time: 1919.6267, d_loss: 1.74419141, g_loss: 0.47949815
Epoch: [ 1] [  33/ 202] time: 1927.7426, d_loss: 2.01605105, g_loss: 0.28386277
Epoch: [ 1] [  34/ 202] time: 1935.9331, d_loss: 1.94334245, g_loss: 0.45521548
Epoch: [ 1] [  35/ 202] time: 1943.9340, d_loss: 1.77544785, g_loss: 0.78298974
Epoch: [ 1] [  36/ 202] time: 1951.9548, d_loss: 1.75005794, g_loss: 0.65389270
Epoch: [ 1] [  37/ 202] time: 1960.0640, d_loss: 1.53167617, g_loss: 0.64765060
Epoch: [ 1] [  38/ 202] time: 1968.2268, d_loss: 1.88709712, g_loss: 0.55585998
Epoch: [ 1] [  39/ 202] time: 1976.2659, d_loss: 1.47099793, g_loss: 0.80082607
Epoch: [ 1] [  40/ 202] time: 1984.3164, d_loss: 1.37714720, g_loss: 0.80229247
Epoch: [ 1] [  41/ 202] time: 1992.6526, d_loss: 1.69192255, g_loss: 0.51425374
Epoch: [ 1] [  42/ 202] time: 2000.7155, d_loss: 1.17754686, g_loss: 0.79553771
Epoch: [ 1] [  43/ 202] time: 2009.1514, d_loss: 1.72265804, g_loss: 1.49889529
Epoch: [ 1] [  44/ 202] time: 2017.4092, d_loss: 1.39987528, g_loss: 0.54881501
Epoch: [ 1] [  45/ 202] time: 2025.7951, d_loss: 1.67020977, g_loss: 0.40571415
Epoch: [ 1] [  46/ 202] time: 2033.9989, d_loss: 1.49497867, g_loss: 1.17978406
Epoch: [ 1] [  47/ 202] time: 2042.2760, d_loss: 1.27469492, g_loss: 1.12021041
Epoch: [ 1] [  48/ 202] time: 2050.3217, d_loss: 2.13276958, g_loss: 0.38651052
Epoch: [ 1] [  49/ 202] time: 2058.4038, d_loss: 1.92057419, g_loss: 0.72242022
Epoch: [ 1] [  50/ 202] time: 2066.4198, d_loss: 1.18282855, g_loss: 1.03529072
Epoch: [ 1] [  51/ 202] time: 2074.4296, d_loss: 1.74319625, g_loss: 0.49928546
Epoch: [ 1] [  52/ 202] time: 2082.4053, d_loss: 1.73156452, g_loss: 0.75874585
Epoch: [ 1] [  53/ 202] time: 2090.4982, d_loss: 1.66412330, g_loss: 0.99414688
Epoch: [ 1] [  54/ 202] time: 2098.5105, d_loss: 3.12696695, g_loss: 0.16305541
Epoch: [ 1] [  55/ 202] time: 2106.5101, d_loss: 2.23355818, g_loss: 0.58338737
Epoch: [ 1] [  56/ 202] time: 2114.5574, d_loss: 1.68551731, g_loss: 0.98327297
Epoch: [ 1] [  57/ 202] time: 2122.5878, d_loss: 2.58101678, g_loss: 0.39232099
Epoch: [ 1] [  58/ 202] time: 2130.6052, d_loss: 2.50934958, g_loss: 0.29856551
Epoch: [ 1] [  59/ 202] time: 2138.5841, d_loss: 1.66117215, g_loss: 0.64592004
Epoch: [ 1] [  60/ 202] time: 2146.5973, d_loss: 1.54832172, g_loss: 0.64225996
Epoch: [ 1] [  61/ 202] time: 2154.6621, d_loss: 1.57403696, g_loss: 0.60322905
Epoch: [ 1] [  62/ 202] time: 2162.6963, d_loss: 1.80895615, g_loss: 0.71659613
Epoch: [ 1] [  63/ 202] time: 2170.6934, d_loss: 2.02396774, g_loss: 0.35530153
Epoch: [ 1] [  64/ 202] time: 2178.6581, d_loss: 1.85368752, g_loss: 0.57246113
Epoch: [ 1] [  65/ 202] time: 2186.6932, d_loss: 1.87293911, g_loss: 0.41763401
Epoch: [ 1] [  66/ 202] time: 2194.6741, d_loss: 1.34902573, g_loss: 1.19779551
Epoch: [ 1] [  67/ 202] time: 2202.7125, d_loss: 1.24359059, g_loss: 1.02669668
Epoch: [ 1] [  68/ 202] time: 2210.6430, d_loss: 2.48175049, g_loss: 0.35245651
Epoch: [ 1] [  69/ 202] time: 2218.7178, d_loss: 2.76129174, g_loss: 0.24191993
Epoch: [ 1] [  70/ 202] time: 2226.7020, d_loss: 2.83644176, g_loss: 0.41365719
Epoch: [ 1] [  71/ 202] time: 2234.6741, d_loss: 1.78823006, g_loss: 0.76412570
Epoch: [ 1] [  72/ 202] time: 2242.6312, d_loss: 2.55157566, g_loss: 0.24257463
Epoch: [ 1] [  73/ 202] time: 2250.6007, d_loss: 2.45949769, g_loss: 0.36020190
Epoch: [ 1] [  74/ 202] time: 2258.6934, d_loss: 2.26025629, g_loss: 0.64996237
Epoch: [ 1] [  75/ 202] time: 2266.6711, d_loss: 2.66840768, g_loss: 0.24204463
Epoch: [ 1] [  76/ 202] time: 2274.6504, d_loss: 2.43940878, g_loss: 0.84538221
Epoch: [ 1] [  77/ 202] time: 2282.6028, d_loss: 2.40826726, g_loss: 0.23983574
Epoch: [ 1] [  78/ 202] time: 2290.7008, d_loss: 2.36978936, g_loss: 0.67083335
Epoch: [ 1] [  79/ 202] time: 2298.7006, d_loss: 2.26605177, g_loss: 0.48833078
Epoch: [ 1] [  80/ 202] time: 2306.6199, d_loss: 1.46454418, g_loss: 0.64357686
Epoch: [ 1] [  81/ 202] time: 2314.5812, d_loss: 1.68791509, g_loss: 0.58327556
Epoch: [ 1] [  82/ 202] time: 2322.6878, d_loss: 0.98074782, g_loss: 0.98521632
Epoch: [ 1] [  83/ 202] time: 2330.6332, d_loss: 1.68149567, g_loss: 0.51400751
Epoch: [ 1] [  84/ 202] time: 2338.6561, d_loss: 2.24550128, g_loss: 0.41781056
Epoch: [ 1] [  85/ 202] time: 2346.6178, d_loss: 1.80932045, g_loss: 0.73641950
Epoch: [ 1] [  86/ 202] time: 2354.6727, d_loss: 2.12087488, g_loss: 0.51500285
Epoch: [ 1] [  87/ 202] time: 2362.6698, d_loss: 2.25629711, g_loss: 0.29443276
Epoch: [ 1] [  88/ 202] time: 2370.6944, d_loss: 2.16146660, g_loss: 0.31276971
Epoch: [ 1] [  89/ 202] time: 2378.7044, d_loss: 1.91284227, g_loss: 0.51168156
Epoch: [ 1] [  90/ 202] time: 2386.7959, d_loss: 1.81158960, g_loss: 0.68469477
Epoch: [ 1] [  91/ 202] time: 2394.7367, d_loss: 2.67794943, g_loss: 0.28837168
Epoch: [ 1] [  92/ 202] time: 2402.7184, d_loss: 2.18697214, g_loss: 0.55226254
Epoch: [ 1] [  93/ 202] time: 2410.6661, d_loss: 1.49694896, g_loss: 1.03329396
Epoch: [ 1] [  94/ 202] time: 2418.6769, d_loss: 1.83260202, g_loss: 0.41863772
Epoch: [ 1] [  95/ 202] time: 2426.6058, d_loss: 1.95496750, g_loss: 0.41206706
Epoch: [ 1] [  96/ 202] time: 2434.5696, d_loss: 1.53179932, g_loss: 1.09672344
[Sample] d_loss: 1.35431743, g_loss: 1.65926099
Epoch: [ 1] [  97/ 202] time: 2444.3743, d_loss: 2.15018606, g_loss: 0.41612029
Epoch: [ 1] [  98/ 202] time: 2452.3959, d_loss: 1.70295691, g_loss: 0.53828222
Epoch: [ 1] [  99/ 202] time: 2460.4122, d_loss: 1.56902313, g_loss: 0.57418334
Epoch: [ 1] [ 100/ 202] time: 2468.3639, d_loss: 1.14979148, g_loss: 0.94159764
Epoch: [ 1] [ 101/ 202] time: 2476.3617, d_loss: 2.26535630, g_loss: 0.25390080
Epoch: [ 1] [ 102/ 202] time: 2484.2757, d_loss: 2.02683282, g_loss: 0.52020502
Epoch: [ 1] [ 103/ 202] time: 2492.2627, d_loss: 2.40639687, g_loss: 0.66555619
Epoch: [ 1] [ 104/ 202] time: 2500.3616, d_loss: 3.12859011, g_loss: 0.26186755
Epoch: [ 1] [ 105/ 202] time: 2508.3785, d_loss: 2.14624500, g_loss: 0.47907007
Epoch: [ 1] [ 106/ 202] time: 2516.4351, d_loss: 1.70163012, g_loss: 0.63464224
Epoch: [ 1] [ 107/ 202] time: 2524.4959, d_loss: 2.00594711, g_loss: 0.62566859
Epoch: [ 1] [ 108/ 202] time: 2532.5885, d_loss: 1.51026380, g_loss: 0.99726999
Epoch: [ 1] [ 109/ 202] time: 2540.5629, d_loss: 2.03034687, g_loss: 0.55926013
Epoch: [ 1] [ 110/ 202] time: 2548.5799, d_loss: 1.76887941, g_loss: 0.42642313
Epoch: [ 1] [ 111/ 202] time: 2556.6763, d_loss: 1.81718969, g_loss: 0.81955147
Epoch: [ 1] [ 112/ 202] time: 2564.8503, d_loss: 1.53444183, g_loss: 0.58730435
Epoch: [ 1] [ 113/ 202] time: 2572.9140, d_loss: 2.08448982, g_loss: 0.39426553
Epoch: [ 1] [ 114/ 202] time: 2581.0496, d_loss: 1.90363777, g_loss: 0.86717474
Epoch: [ 1] [ 115/ 202] time: 2589.0597, d_loss: 2.02022934, g_loss: 0.64081949
Epoch: [ 1] [ 116/ 202] time: 2597.5819, d_loss: 1.53783846, g_loss: 0.81833959
Epoch: [ 1] [ 117/ 202] time: 2605.5796, d_loss: 2.31502342, g_loss: 0.32151806
Epoch: [ 1] [ 118/ 202] time: 2613.5772, d_loss: 1.89390314, g_loss: 0.37961537
Epoch: [ 1] [ 119/ 202] time: 2621.5356, d_loss: 1.58566666, g_loss: 0.78018945
Epoch: [ 1] [ 120/ 202] time: 2629.5678, d_loss: 2.16626668, g_loss: 0.49959752
Epoch: [ 1] [ 121/ 202] time: 2637.6550, d_loss: 2.23778629, g_loss: 0.44749394
Epoch: [ 1] [ 122/ 202] time: 2645.6702, d_loss: 2.13110662, g_loss: 0.40698680
Epoch: [ 1] [ 123/ 202] time: 2653.7572, d_loss: 1.83376086, g_loss: 0.63067293
Epoch: [ 1] [ 124/ 202] time: 2661.7987, d_loss: 1.59722281, g_loss: 0.99781430
Epoch: [ 1] [ 125/ 202] time: 2669.8337, d_loss: 2.40717435, g_loss: 0.44065911
Epoch: [ 1] [ 126/ 202] time: 2677.8127, d_loss: 1.43483102, g_loss: 0.67876959
Epoch: [ 1] [ 127/ 202] time: 2685.8075, d_loss: 1.37081373, g_loss: 0.87474239
Epoch: [ 1] [ 128/ 202] time: 2693.8454, d_loss: 2.49517322, g_loss: 0.21887407
Epoch: [ 1] [ 129/ 202] time: 2701.9155, d_loss: 1.89289594, g_loss: 0.68500233
Epoch: [ 1] [ 130/ 202] time: 2709.9065, d_loss: 1.87673092, g_loss: 0.84368575
Epoch: [ 1] [ 131/ 202] time: 2717.9248, d_loss: 1.54186475, g_loss: 0.64413655
Epoch: [ 1] [ 132/ 202] time: 2726.0094, d_loss: 1.46983528, g_loss: 0.72420204
Epoch: [ 1] [ 133/ 202] time: 2734.0103, d_loss: 1.11183178, g_loss: 0.82031620
Epoch: [ 1] [ 134/ 202] time: 2741.9722, d_loss: 1.51352000, g_loss: 0.63175422
Epoch: [ 1] [ 135/ 202] time: 2749.8959, d_loss: 1.90111041, g_loss: 0.53900898
Epoch: [ 1] [ 136/ 202] time: 2758.0547, d_loss: 1.90997481, g_loss: 0.72541118
Epoch: [ 1] [ 137/ 202] time: 2765.9996, d_loss: 1.50219107, g_loss: 1.31119633
Epoch: [ 1] [ 138/ 202] time: 2773.9808, d_loss: 1.19935024, g_loss: 0.67482233
Epoch: [ 1] [ 139/ 202] time: 2782.0539, d_loss: 1.63672936, g_loss: 0.78375924
Epoch: [ 1] [ 140/ 202] time: 2790.0852, d_loss: 1.72754097, g_loss: 0.82815951
Epoch: [ 1] [ 141/ 202] time: 2798.1031, d_loss: 2.03185034, g_loss: 0.37111783
Epoch: [ 1] [ 142/ 202] time: 2806.0333, d_loss: 1.33626962, g_loss: 0.94909930
Epoch: [ 1] [ 143/ 202] time: 2814.0542, d_loss: 1.63637662, g_loss: 0.91870737
Epoch: [ 1] [ 144/ 202] time: 2822.0642, d_loss: 1.63855362, g_loss: 0.44488865
Epoch: [ 1] [ 145/ 202] time: 2830.1344, d_loss: 1.36848128, g_loss: 0.83985400
Epoch: [ 1] [ 146/ 202] time: 2838.1288, d_loss: 1.49907029, g_loss: 0.52436388
Epoch: [ 1] [ 147/ 202] time: 2846.2000, d_loss: 1.01971519, g_loss: 1.16397369
Epoch: [ 1] [ 148/ 202] time: 2854.1776, d_loss: 1.13591373, g_loss: 0.78840637
Epoch: [ 1] [ 149/ 202] time: 2862.1248, d_loss: 1.78155446, g_loss: 0.42232597
Epoch: [ 1] [ 150/ 202] time: 2870.1369, d_loss: 1.30316138, g_loss: 0.78322172
Epoch: [ 1] [ 151/ 202] time: 2878.1714, d_loss: 1.32904017, g_loss: 0.77566683
Epoch: [ 1] [ 152/ 202] time: 2886.2313, d_loss: 1.10697448, g_loss: 0.87574816
Epoch: [ 1] [ 153/ 202] time: 2894.2434, d_loss: 1.89289308, g_loss: 0.34887332
Epoch: [ 1] [ 154/ 202] time: 2902.2252, d_loss: 1.44494808, g_loss: 0.79248941
Epoch: [ 1] [ 155/ 202] time: 2910.1983, d_loss: 1.82974625, g_loss: 0.48272923
Epoch: [ 1] [ 156/ 202] time: 2918.2600, d_loss: 1.80862391, g_loss: 0.80192828
Epoch: [ 1] [ 157/ 202] time: 2926.2184, d_loss: 2.10212946, g_loss: 0.33633044
Epoch: [ 1] [ 158/ 202] time: 2934.2240, d_loss: 1.47244954, g_loss: 0.84766895
Epoch: [ 1] [ 159/ 202] time: 2942.2173, d_loss: 1.78597403, g_loss: 0.40385199
Epoch: [ 1] [ 160/ 202] time: 2950.2356, d_loss: 1.82472181, g_loss: 0.46013421
Epoch: [ 1] [ 161/ 202] time: 2958.2424, d_loss: 1.60560036, g_loss: 0.83880627
Epoch: [ 1] [ 162/ 202] time: 2966.2268, d_loss: 1.43367577, g_loss: 0.69466734
Epoch: [ 1] [ 163/ 202] time: 2974.2211, d_loss: 1.40407562, g_loss: 0.56635392
Epoch: [ 1] [ 164/ 202] time: 2982.3281, d_loss: 1.53828061, g_loss: 0.73111922
Epoch: [ 1] [ 165/ 202] time: 2990.4256, d_loss: 1.74848771, g_loss: 0.41633618
Epoch: [ 1] [ 166/ 202] time: 2998.4166, d_loss: 1.79492986, g_loss: 0.40897125
Epoch: [ 1] [ 167/ 202] time: 3006.4125, d_loss: 1.26873159, g_loss: 1.24275923
Epoch: [ 1] [ 168/ 202] time: 3014.4529, d_loss: 1.16892385, g_loss: 0.91943020
Epoch: [ 1] [ 169/ 202] time: 3022.5403, d_loss: 1.67094684, g_loss: 0.57966864
Epoch: [ 1] [ 170/ 202] time: 3030.5209, d_loss: 1.65098906, g_loss: 0.90197730
Epoch: [ 1] [ 171/ 202] time: 3038.5195, d_loss: 1.68138313, g_loss: 0.44970733
Epoch: [ 1] [ 172/ 202] time: 3046.5333, d_loss: 1.86619258, g_loss: 0.47938460
Epoch: [ 1] [ 173/ 202] time: 3054.5737, d_loss: 1.75495744, g_loss: 0.58200622
Epoch: [ 1] [ 174/ 202] time: 3062.5843, d_loss: 1.50493360, g_loss: 1.03407085
Epoch: [ 1] [ 175/ 202] time: 3070.6156, d_loss: 1.88977134, g_loss: 0.45606741
Epoch: [ 1] [ 176/ 202] time: 3078.6334, d_loss: 2.05785751, g_loss: 0.50369745
Epoch: [ 1] [ 177/ 202] time: 3086.6294, d_loss: 2.22533965, g_loss: 0.34084082
Epoch: [ 1] [ 178/ 202] time: 3094.5759, d_loss: 1.90549922, g_loss: 0.53199768
Epoch: [ 1] [ 179/ 202] time: 3102.5617, d_loss: 1.56268358, g_loss: 1.38026619
Epoch: [ 1] [ 180/ 202] time: 3110.5280, d_loss: 1.16435599, g_loss: 0.83178079
Epoch: [ 1] [ 181/ 202] time: 3118.5102, d_loss: 1.82885337, g_loss: 0.29883310
Epoch: [ 1] [ 182/ 202] time: 3126.5138, d_loss: 1.73414624, g_loss: 0.45204568
Epoch: [ 1] [ 183/ 202] time: 3134.4364, d_loss: 2.12828779, g_loss: 0.51120037
Epoch: [ 1] [ 184/ 202] time: 3142.4082, d_loss: 2.00182223, g_loss: 0.87671715
Epoch: [ 1] [ 185/ 202] time: 3150.4292, d_loss: 2.01388407, g_loss: 0.56476140
Epoch: [ 1] [ 186/ 202] time: 3158.3817, d_loss: 1.58503652, g_loss: 0.77052981
Epoch: [ 1] [ 187/ 202] time: 3166.4618, d_loss: 1.94783068, g_loss: 0.50061226
Epoch: [ 1] [ 188/ 202] time: 3174.4361, d_loss: 1.33180416, g_loss: 0.74191105
Epoch: [ 1] [ 189/ 202] time: 3182.5643, d_loss: 2.16389465, g_loss: 0.31384158
Epoch: [ 1] [ 190/ 202] time: 3190.5342, d_loss: 1.85382628, g_loss: 0.71888763
Epoch: [ 1] [ 191/ 202] time: 3198.5047, d_loss: 1.41632771, g_loss: 0.76349783
Epoch: [ 1] [ 192/ 202] time: 3206.5266, d_loss: 1.37366724, g_loss: 0.73096311
Epoch: [ 1] [ 193/ 202] time: 3214.5269, d_loss: 1.32601798, g_loss: 0.59842068
Epoch: [ 1] [ 194/ 202] time: 3222.5006, d_loss: 1.68343651, g_loss: 0.64053500
Epoch: [ 1] [ 195/ 202] time: 3230.5026, d_loss: 1.68572521, g_loss: 0.54684377
Epoch: [ 1] [ 196/ 202] time: 3238.5184, d_loss: 1.88296187, g_loss: 0.62131310
[Sample] d_loss: 1.59709978, g_loss: 1.05071568
Epoch: [ 1] [ 197/ 202] time: 3248.4096, d_loss: 2.28949738, g_loss: 0.31447887
Epoch: [ 1] [ 198/ 202] time: 3256.3451, d_loss: 1.54347682, g_loss: 1.49728465
Epoch: [ 1] [ 199/ 202] time: 3264.3162, d_loss: 1.52850688, g_loss: 0.45731670
Epoch: [ 1] [ 200/ 202] time: 3272.2235, d_loss: 1.06375480, g_loss: 1.50186658
Epoch: [ 1] [ 201/ 202] time: 3280.2028, d_loss: 2.21393514, g_loss: 0.22300553
Epoch: [ 2] [   0/ 202] time: 3288.3150, d_loss: 1.27164936, g_loss: 0.94115275
Epoch: [ 2] [   1/ 202] time: 3296.2642, d_loss: 1.58069253, g_loss: 0.50878322
Epoch: [ 2] [   2/ 202] time: 3304.3067, d_loss: 1.76884854, g_loss: 0.53789586
Epoch: [ 2] [   3/ 202] time: 3312.2504, d_loss: 1.21268249, g_loss: 0.80133289
Epoch: [ 2] [   4/ 202] time: 3320.2177, d_loss: 1.06020939, g_loss: 1.11260271
Epoch: [ 2] [   5/ 202] time: 3328.2266, d_loss: 1.35039949, g_loss: 0.74174559
Epoch: [ 2] [   6/ 202] time: 3336.2001, d_loss: 1.47573662, g_loss: 0.53710043
Epoch: [ 2] [   7/ 202] time: 3344.1680, d_loss: 1.83308506, g_loss: 1.03938961
Epoch: [ 2] [   8/ 202] time: 3352.1042, d_loss: 1.45312548, g_loss: 0.45315579
Epoch: [ 2] [   9/ 202] time: 3360.0827, d_loss: 1.72854662, g_loss: 0.51956511
Epoch: [ 2] [  10/ 202] time: 3368.1041, d_loss: 1.46111751, g_loss: 0.74668396
Epoch: [ 2] [  11/ 202] time: 3376.1427, d_loss: 1.62826371, g_loss: 0.49045649
Epoch: [ 2] [  12/ 202] time: 3384.1179, d_loss: 1.36710513, g_loss: 0.62655210
Epoch: [ 2] [  13/ 202] time: 3392.1058, d_loss: 1.23128653, g_loss: 0.71562618
Epoch: [ 2] [  14/ 202] time: 3400.1675, d_loss: 1.69155478, g_loss: 0.55537808
Epoch: [ 2] [  15/ 202] time: 3408.1447, d_loss: 1.42176580, g_loss: 0.90381980
Epoch: [ 2] [  16/ 202] time: 3416.0840, d_loss: 1.40224934, g_loss: 0.47724551
Epoch: [ 2] [  17/ 202] time: 3424.0937, d_loss: 1.43575537, g_loss: 0.44846138
Epoch: [ 2] [  18/ 202] time: 3432.1527, d_loss: 1.82466829, g_loss: 0.71422517
Epoch: [ 2] [  19/ 202] time: 3440.1088, d_loss: 1.88052046, g_loss: 0.38079125
Epoch: [ 2] [  20/ 202] time: 3448.0645, d_loss: 1.81228518, g_loss: 0.40347505
Epoch: [ 2] [  21/ 202] time: 3456.0111, d_loss: 1.86496031, g_loss: 0.63694233
Epoch: [ 2] [  22/ 202] time: 3464.0784, d_loss: 1.83358097, g_loss: 0.65400881
Epoch: [ 2] [  23/ 202] time: 3472.1346, d_loss: 2.04009843, g_loss: 0.48650628
Epoch: [ 2] [  24/ 202] time: 3480.1326, d_loss: 1.70842099, g_loss: 0.72884190
Epoch: [ 2] [  25/ 202] time: 3488.1884, d_loss: 1.96834493, g_loss: 0.39656535
Epoch: [ 2] [  26/ 202] time: 3496.1860, d_loss: 1.62509859, g_loss: 0.86778271
Epoch: [ 2] [  27/ 202] time: 3504.2291, d_loss: 1.98365831, g_loss: 0.36053419
Epoch: [ 2] [  28/ 202] time: 3512.3158, d_loss: 1.38890660, g_loss: 0.81458539
Epoch: [ 2] [  29/ 202] time: 3520.4141, d_loss: 1.41415298, g_loss: 0.89700300
Epoch: [ 2] [  30/ 202] time: 3528.4979, d_loss: 1.67652798, g_loss: 0.33656773
Epoch: [ 2] [  31/ 202] time: 3536.5545, d_loss: 1.33343327, g_loss: 1.20956731
Epoch: [ 2] [  32/ 202] time: 3544.6220, d_loss: 1.67106986, g_loss: 0.37448376
Epoch: [ 2] [  33/ 202] time: 3552.7090, d_loss: 2.11917925, g_loss: 0.20925671
Epoch: [ 2] [  34/ 202] time: 3560.7489, d_loss: 1.34046030, g_loss: 1.31407368
Epoch: [ 2] [  35/ 202] time: 3568.7640, d_loss: 1.33953691, g_loss: 0.84124887
Epoch: [ 2] [  36/ 202] time: 3576.7721, d_loss: 1.58741808, g_loss: 0.45777670
Epoch: [ 2] [  37/ 202] time: 3584.7968, d_loss: 1.43765712, g_loss: 0.93245149
Epoch: [ 2] [  38/ 202] time: 3592.9169, d_loss: 1.95720029, g_loss: 0.36070049
Epoch: [ 2] [  39/ 202] time: 3601.0683, d_loss: 1.38893294, g_loss: 0.68667078
Epoch: [ 2] [  40/ 202] time: 3609.0995, d_loss: 1.83942509, g_loss: 0.35231739
Epoch: [ 2] [  41/ 202] time: 3617.1023, d_loss: 1.66568756, g_loss: 0.66006625
Epoch: [ 2] [  42/ 202] time: 3625.1861, d_loss: 1.45444095, g_loss: 1.24131775
Epoch: [ 2] [  43/ 202] time: 3633.2644, d_loss: 1.52785838, g_loss: 0.46762824
Epoch: [ 2] [  44/ 202] time: 3641.4566, d_loss: 1.68312752, g_loss: 0.56515390
Epoch: [ 2] [  45/ 202] time: 3649.5843, d_loss: 2.09449244, g_loss: 0.39609817
Epoch: [ 2] [  46/ 202] time: 3657.6016, d_loss: 1.75047648, g_loss: 0.40065372
Epoch: [ 2] [  47/ 202] time: 3665.9188, d_loss: 1.45590603, g_loss: 0.67967451
Epoch: [ 2] [  48/ 202] time: 3674.3748, d_loss: 1.63485265, g_loss: 0.56889224
Epoch: [ 2] [  49/ 202] time: 3682.8190, d_loss: 2.05722117, g_loss: 0.33688998
Epoch: [ 2] [  50/ 202] time: 3691.4841, d_loss: 1.58331919, g_loss: 0.72797877
Epoch: [ 2] [  51/ 202] time: 3699.6770, d_loss: 2.06188178, g_loss: 0.39259994
Epoch: [ 2] [  52/ 202] time: 3707.9465, d_loss: 1.80202544, g_loss: 0.72527844
Epoch: [ 2] [  53/ 202] time: 3715.9974, d_loss: 1.81229758, g_loss: 0.96487987
Epoch: [ 2] [  54/ 202] time: 3724.0543, d_loss: 2.44074893, g_loss: 0.20259425
Epoch: [ 2] [  55/ 202] time: 3732.3457, d_loss: 1.76211905, g_loss: 0.78905654
Epoch: [ 2] [  56/ 202] time: 3740.3657, d_loss: 1.58069170, g_loss: 0.74441266
Epoch: [ 2] [  57/ 202] time: 3748.4071, d_loss: 1.96503711, g_loss: 0.58713853
Epoch: [ 2] [  58/ 202] time: 3756.7480, d_loss: 1.74094296, g_loss: 0.44225389
Epoch: [ 2] [  59/ 202] time: 3764.8359, d_loss: 1.64162922, g_loss: 0.64201069
Epoch: [ 2] [  60/ 202] time: 3773.0058, d_loss: 1.36988676, g_loss: 0.84983659
Epoch: [ 2] [  61/ 202] time: 3781.1244, d_loss: 1.76195037, g_loss: 0.39541271
Epoch: [ 2] [  62/ 202] time: 3789.3777, d_loss: 1.45832980, g_loss: 0.75770807
Epoch: [ 2] [  63/ 202] time: 3797.4395, d_loss: 1.21127915, g_loss: 1.28095078
Epoch: [ 2] [  64/ 202] time: 3805.4503, d_loss: 2.05753350, g_loss: 0.29778153
Epoch: [ 2] [  65/ 202] time: 3813.4966, d_loss: 1.56930685, g_loss: 0.83694994
Epoch: [ 2] [  66/ 202] time: 3821.5672, d_loss: 1.62594557, g_loss: 0.49520025
Epoch: [ 2] [  67/ 202] time: 3829.5560, d_loss: 2.29376292, g_loss: 0.30277127
Epoch: [ 2] [  68/ 202] time: 3837.5557, d_loss: 1.89518011, g_loss: 0.52214026
Epoch: [ 2] [  69/ 202] time: 3845.6613, d_loss: 2.00537658, g_loss: 0.55707276
Epoch: [ 2] [  70/ 202] time: 3853.8075, d_loss: 2.25401187, g_loss: 0.41120255
Epoch: [ 2] [  71/ 202] time: 3862.7762, d_loss: 1.71189523, g_loss: 0.79670835
Epoch: [ 2] [  72/ 202] time: 3871.6939, d_loss: 1.94169354, g_loss: 0.51941931
Epoch: [ 2] [  73/ 202] time: 3879.8414, d_loss: 2.22029066, g_loss: 0.37691396
Epoch: [ 2] [  74/ 202] time: 3887.9307, d_loss: 2.59777737, g_loss: 0.28540239
Epoch: [ 2] [  75/ 202] time: 3895.9529, d_loss: 1.66690588, g_loss: 0.85193431
Epoch: [ 2] [  76/ 202] time: 3904.0001, d_loss: 2.20563030, g_loss: 0.52940977
Epoch: [ 2] [  77/ 202] time: 3912.0645, d_loss: 2.45651984, g_loss: 0.20883837
Epoch: [ 2] [  78/ 202] time: 3920.1449, d_loss: 1.70312381, g_loss: 2.71986747
Epoch: [ 2] [  79/ 202] time: 3928.2021, d_loss: 1.35748661, g_loss: 0.76092643
Epoch: [ 2] [  80/ 202] time: 3936.3171, d_loss: 2.66408205, g_loss: 0.15232348
Epoch: [ 2] [  81/ 202] time: 3944.4228, d_loss: 1.62969446, g_loss: 0.75356281
Epoch: [ 2] [  82/ 202] time: 3952.4534, d_loss: 1.42989397, g_loss: 1.02547193
Epoch: [ 2] [  83/ 202] time: 3960.5270, d_loss: 1.68115008, g_loss: 0.41300946
Epoch: [ 2] [  84/ 202] time: 3968.5345, d_loss: 1.62390780, g_loss: 0.67609906
Epoch: [ 2] [  85/ 202] time: 3976.8205, d_loss: 1.58697557, g_loss: 1.03118622
Epoch: [ 2] [  86/ 202] time: 3984.8472, d_loss: 1.54528284, g_loss: 0.44891053
Epoch: [ 2] [  87/ 202] time: 3992.8888, d_loss: 1.65948319, g_loss: 0.56952763
Epoch: [ 2] [  88/ 202] time: 4001.8406, d_loss: 1.99122572, g_loss: 0.40442330
Epoch: [ 2] [  89/ 202] time: 4010.6673, d_loss: 1.66659427, g_loss: 0.48784921
Epoch: [ 2] [  90/ 202] time: 4018.8765, d_loss: 1.61978245, g_loss: 1.05259633
Epoch: [ 2] [  91/ 202] time: 4026.9279, d_loss: 1.23169100, g_loss: 0.65281022
Epoch: [ 2] [  92/ 202] time: 4035.0037, d_loss: 1.25921512, g_loss: 0.85185456
Epoch: [ 2] [  93/ 202] time: 4043.1354, d_loss: 1.17741060, g_loss: 0.90529490
Epoch: [ 2] [  94/ 202] time: 4051.2392, d_loss: 1.49297798, g_loss: 0.46164608
[Sample] d_loss: 1.07600832, g_loss: 0.78650224
Epoch: [ 2] [  95/ 202] time: 4061.1290, d_loss: 1.33557296, g_loss: 1.07179999
Epoch: [ 2] [  96/ 202] time: 4070.6164, d_loss: 0.75737035, g_loss: 1.14531410
Epoch: [ 2] [  97/ 202] time: 4079.0792, d_loss: 1.14763141, g_loss: 0.63146174
Epoch: [ 2] [  98/ 202] time: 4087.2803, d_loss: 0.92817324, g_loss: 1.37987304
Epoch: [ 2] [  99/ 202] time: 4095.3288, d_loss: 1.41072083, g_loss: 0.41337359
Epoch: [ 2] [ 100/ 202] time: 4103.3946, d_loss: 1.07987940, g_loss: 1.32782269
Epoch: [ 2] [ 101/ 202] time: 4111.7126, d_loss: 1.22301674, g_loss: 0.74149847
Epoch: [ 2] [ 102/ 202] time: 4119.8054, d_loss: 0.89039248, g_loss: 1.01739514
Epoch: [ 2] [ 103/ 202] time: 4127.8210, d_loss: 0.81622678, g_loss: 1.14126611
Epoch: [ 2] [ 104/ 202] time: 4135.8458, d_loss: 1.12835932, g_loss: 0.74127358
Epoch: [ 2] [ 105/ 202] time: 4143.9352, d_loss: 1.40548348, g_loss: 0.54406404
Epoch: [ 2] [ 106/ 202] time: 4151.9124, d_loss: 1.15706325, g_loss: 0.99166918
Epoch: [ 2] [ 107/ 202] time: 4159.9170, d_loss: 1.49945652, g_loss: 0.88245755
Epoch: [ 2] [ 108/ 202] time: 4167.9662, d_loss: 2.48229122, g_loss: 0.21672146
Epoch: [ 2] [ 109/ 202] time: 4176.0260, d_loss: 1.97666669, g_loss: 1.11736071
Epoch: [ 2] [ 110/ 202] time: 4184.0160, d_loss: 1.33691788, g_loss: 1.10058737
Epoch: [ 2] [ 111/ 202] time: 4191.9988, d_loss: 1.49176741, g_loss: 0.62236547
Epoch: [ 2] [ 112/ 202] time: 4200.0403, d_loss: 2.00788665, g_loss: 0.28606999
Epoch: [ 2] [ 113/ 202] time: 4208.0994, d_loss: 1.89600039, g_loss: 0.71985060
Epoch: [ 2] [ 114/ 202] time: 4216.2060, d_loss: 2.36828923, g_loss: 0.20789184
Epoch: [ 2] [ 115/ 202] time: 4224.3163, d_loss: 1.65629065, g_loss: 0.90466166
Epoch: [ 2] [ 116/ 202] time: 4232.5027, d_loss: 1.15927768, g_loss: 1.43515015
Epoch: [ 2] [ 117/ 202] time: 4240.5142, d_loss: 1.93963671, g_loss: 0.34575361
Epoch: [ 2] [ 118/ 202] time: 4248.5390, d_loss: 1.17899489, g_loss: 0.68955636
Epoch: [ 2] [ 119/ 202] time: 4256.6092, d_loss: 1.04012656, g_loss: 1.01645148
Epoch: [ 2] [ 120/ 202] time: 4264.6841, d_loss: 1.99901271, g_loss: 0.39979196
Epoch: [ 2] [ 121/ 202] time: 4272.7502, d_loss: 1.80021894, g_loss: 0.66109824
Epoch: [ 2] [ 122/ 202] time: 4280.7092, d_loss: 1.70894969, g_loss: 0.69262826
Epoch: [ 2] [ 123/ 202] time: 4288.6628, d_loss: 2.03642178, g_loss: 0.30318272
Epoch: [ 2] [ 124/ 202] time: 4296.7425, d_loss: 1.32019114, g_loss: 1.44377184
Epoch: [ 2] [ 125/ 202] time: 4304.8145, d_loss: 1.35292101, g_loss: 0.54376543
Epoch: [ 2] [ 126/ 202] time: 4313.5976, d_loss: 1.42427492, g_loss: 0.48061624
Epoch: [ 2] [ 127/ 202] time: 4321.5897, d_loss: 1.61075997, g_loss: 0.93920457
Epoch: [ 2] [ 128/ 202] time: 4329.9550, d_loss: 2.00017548, g_loss: 0.42486513
Epoch: [ 2] [ 129/ 202] time: 4337.9210, d_loss: 1.70495915, g_loss: 0.63317728
Epoch: [ 2] [ 130/ 202] time: 4345.9923, d_loss: 1.34947467, g_loss: 0.88321209
Epoch: [ 2] [ 131/ 202] time: 4354.0154, d_loss: 1.18486774, g_loss: 0.86169302
Epoch: [ 2] [ 132/ 202] time: 4362.3960, d_loss: 2.10326791, g_loss: 0.27568504
Epoch: [ 2] [ 133/ 202] time: 4370.4595, d_loss: 1.81874919, g_loss: 0.46571141
Epoch: [ 2] [ 134/ 202] time: 4378.5074, d_loss: 2.34664440, g_loss: 0.42244631
Epoch: [ 2] [ 135/ 202] time: 4386.8962, d_loss: 1.83283532, g_loss: 0.68537700
Epoch: [ 2] [ 136/ 202] time: 4394.9336, d_loss: 1.61763978, g_loss: 0.43414187
Epoch: [ 2] [ 137/ 202] time: 4402.9010, d_loss: 1.42931008, g_loss: 1.29296398
Epoch: [ 2] [ 138/ 202] time: 4410.8513, d_loss: 1.92112243, g_loss: 0.34118360
Epoch: [ 2] [ 139/ 202] time: 4418.8883, d_loss: 2.33059931, g_loss: 0.32425094
Epoch: [ 2] [ 140/ 202] time: 4426.8175, d_loss: 1.52264309, g_loss: 0.88623869
Epoch: [ 2] [ 141/ 202] time: 4434.8131, d_loss: 1.41235673, g_loss: 0.77879131
Epoch: [ 2] [ 142/ 202] time: 4442.7869, d_loss: 1.13113475, g_loss: 0.95438457
Epoch: [ 2] [ 143/ 202] time: 4450.7196, d_loss: 1.48081326, g_loss: 0.66281968
Epoch: [ 2] [ 144/ 202] time: 4458.7068, d_loss: 1.45608115, g_loss: 0.57785916
Epoch: [ 2] [ 145/ 202] time: 4466.8407, d_loss: 1.49191105, g_loss: 0.79433101
Epoch: [ 2] [ 146/ 202] time: 4474.8243, d_loss: 1.79201150, g_loss: 0.32389212
Epoch: [ 2] [ 147/ 202] time: 4482.8445, d_loss: 1.46886027, g_loss: 1.82383776
Epoch: [ 2] [ 148/ 202] time: 4490.9471, d_loss: 2.06337810, g_loss: 0.23346081
Epoch: [ 2] [ 149/ 202] time: 4498.9777, d_loss: 1.73448896, g_loss: 0.42974406
Epoch: [ 2] [ 150/ 202] time: 4506.9766, d_loss: 1.34711599, g_loss: 1.15505672
Epoch: [ 2] [ 151/ 202] time: 4515.0228, d_loss: 1.39756429, g_loss: 0.65280980
Epoch: [ 2] [ 152/ 202] time: 4523.1025, d_loss: 0.95287007, g_loss: 0.92833912
Epoch: [ 2] [ 153/ 202] time: 4531.1848, d_loss: 1.45230186, g_loss: 0.64780557
Epoch: [ 2] [ 154/ 202] time: 4539.1381, d_loss: 1.19688070, g_loss: 0.67093271
Epoch: [ 2] [ 155/ 202] time: 4547.1406, d_loss: 1.31193316, g_loss: 0.81034666
Epoch: [ 2] [ 156/ 202] time: 4555.1467, d_loss: 1.50519085, g_loss: 0.61881715
Epoch: [ 2] [ 157/ 202] time: 4563.1674, d_loss: 1.30536318, g_loss: 0.88632840
Epoch: [ 2] [ 158/ 202] time: 4571.1841, d_loss: 1.63517368, g_loss: 0.40119344
Epoch: [ 2] [ 159/ 202] time: 4579.1786, d_loss: 1.18855524, g_loss: 1.53868914
Epoch: [ 2] [ 160/ 202] time: 4587.1905, d_loss: 1.74271977, g_loss: 0.29734707
Epoch: [ 2] [ 161/ 202] time: 4595.1391, d_loss: 1.14392853, g_loss: 1.20125246
Epoch: [ 2] [ 162/ 202] time: 4603.1646, d_loss: 1.24258471, g_loss: 0.67859715
Epoch: [ 2] [ 163/ 202] time: 4611.1760, d_loss: 0.90485561, g_loss: 1.08207285
Epoch: [ 2] [ 164/ 202] time: 4619.2011, d_loss: 1.30143380, g_loss: 0.55490971
Epoch: [ 2] [ 165/ 202] time: 4627.1771, d_loss: 1.28122544, g_loss: 0.74423414
Epoch: [ 2] [ 166/ 202] time: 4635.1720, d_loss: 1.41269970, g_loss: 0.74997884
Epoch: [ 2] [ 167/ 202] time: 4643.1265, d_loss: 1.60008633, g_loss: 0.44417679
Epoch: [ 2] [ 168/ 202] time: 4651.1756, d_loss: 1.46705604, g_loss: 1.11096275
Epoch: [ 2] [ 169/ 202] time: 4659.1318, d_loss: 1.44278288, g_loss: 0.48579139
Epoch: [ 2] [ 170/ 202] time: 4667.1261, d_loss: 1.29249907, g_loss: 1.69593215
Epoch: [ 2] [ 171/ 202] time: 4675.1538, d_loss: 1.35342383, g_loss: 0.43131879
Epoch: [ 2] [ 172/ 202] time: 4683.1664, d_loss: 1.05001605, g_loss: 1.15677488
Epoch: [ 2] [ 173/ 202] time: 4691.1552, d_loss: 1.60569692, g_loss: 0.62373531
Epoch: [ 2] [ 174/ 202] time: 4699.1493, d_loss: 0.89299428, g_loss: 1.05983233
Epoch: [ 2] [ 175/ 202] time: 4707.1192, d_loss: 2.00989962, g_loss: 0.23596196
Epoch: [ 2] [ 176/ 202] time: 4715.2226, d_loss: 2.23150349, g_loss: 0.64410830
Epoch: [ 2] [ 177/ 202] time: 4723.2465, d_loss: 1.73893571, g_loss: 0.44523343
Epoch: [ 2] [ 178/ 202] time: 4731.2260, d_loss: 1.17194498, g_loss: 0.93736863
Epoch: [ 2] [ 179/ 202] time: 4739.1636, d_loss: 0.92150968, g_loss: 1.39278054
Epoch: [ 2] [ 180/ 202] time: 4747.1725, d_loss: 1.28525937, g_loss: 0.67388010
Epoch: [ 2] [ 181/ 202] time: 4755.1797, d_loss: 1.98759246, g_loss: 0.25222388
Epoch: [ 2] [ 182/ 202] time: 4763.1606, d_loss: 2.49253297, g_loss: 0.31790224
Epoch: [ 2] [ 183/ 202] time: 4771.1368, d_loss: 2.06243849, g_loss: 0.52912289
Epoch: [ 2] [ 184/ 202] time: 4779.1843, d_loss: 1.43835723, g_loss: 0.80265450
Epoch: [ 2] [ 185/ 202] time: 4787.1657, d_loss: 1.46564174, g_loss: 0.45949587
Epoch: [ 2] [ 186/ 202] time: 4795.1628, d_loss: 1.02961564, g_loss: 1.06390083
Epoch: [ 2] [ 187/ 202] time: 4803.1244, d_loss: 2.32975936, g_loss: 0.29125655
Epoch: [ 2] [ 188/ 202] time: 4811.1734, d_loss: 1.37018609, g_loss: 1.46088493
Epoch: [ 2] [ 189/ 202] time: 4819.2354, d_loss: 2.46249557, g_loss: 0.20300777
Epoch: [ 2] [ 190/ 202] time: 4827.2004, d_loss: 2.15761518, g_loss: 1.76102090
Epoch: [ 2] [ 191/ 202] time: 4835.1743, d_loss: 2.00041413, g_loss: 0.22228622
Epoch: [ 2] [ 192/ 202] time: 4843.2695, d_loss: 1.24249876, g_loss: 1.63740921
Epoch: [ 2] [ 193/ 202] time: 4851.2533, d_loss: 1.24010921, g_loss: 0.61787832
Epoch: [ 2] [ 194/ 202] time: 4859.2497, d_loss: 1.63534272, g_loss: 0.42672765
[Sample] d_loss: 1.06932533, g_loss: 0.73229110
Epoch: [ 2] [ 195/ 202] time: 4868.9621, d_loss: 1.29354763, g_loss: 1.07570755
Epoch: [ 2] [ 196/ 202] time: 4876.9532, d_loss: 1.40752077, g_loss: 0.66592371
Epoch: [ 2] [ 197/ 202] time: 4884.8969, d_loss: 1.33378983, g_loss: 0.54160321
Epoch: [ 2] [ 198/ 202] time: 4892.8387, d_loss: 0.88195717, g_loss: 1.14111948
Epoch: [ 2] [ 199/ 202] time: 4900.8876, d_loss: 1.59309947, g_loss: 0.40511563
Epoch: [ 2] [ 200/ 202] time: 4908.9416, d_loss: 1.13145208, g_loss: 1.57486343
Epoch: [ 2] [ 201/ 202] time: 4916.9025, d_loss: 2.24162126, g_loss: 0.22460322
Epoch: [ 3] [   0/ 202] time: 4925.0367, d_loss: 1.42246389, g_loss: 2.19061971
Epoch: [ 3] [   1/ 202] time: 4933.1120, d_loss: 2.44101310, g_loss: 0.15879098
Epoch: [ 3] [   2/ 202] time: 4941.3902, d_loss: 1.79579508, g_loss: 0.85911119
Epoch: [ 3] [   3/ 202] time: 4949.4753, d_loss: 1.44414377, g_loss: 1.10803950
Epoch: [ 3] [   4/ 202] time: 4957.6000, d_loss: 1.93922341, g_loss: 0.44364178
Epoch: [ 3] [   5/ 202] time: 4965.6258, d_loss: 1.93865752, g_loss: 0.70778209
Epoch: [ 3] [   6/ 202] time: 4973.7119, d_loss: 1.72698259, g_loss: 0.50385296
Epoch: [ 3] [   7/ 202] time: 4981.6496, d_loss: 1.27949047, g_loss: 0.72586954
Epoch: [ 3] [   8/ 202] time: 4989.6344, d_loss: 1.29829395, g_loss: 1.43142343
Epoch: [ 3] [   9/ 202] time: 4997.6883, d_loss: 2.22541690, g_loss: 0.29436386
Epoch: [ 3] [  10/ 202] time: 5005.7431, d_loss: 2.17361164, g_loss: 0.45217294
Epoch: [ 3] [  11/ 202] time: 5013.7267, d_loss: 1.96789563, g_loss: 0.56534386
Epoch: [ 3] [  12/ 202] time: 5021.6917, d_loss: 1.18233955, g_loss: 0.86611116
Epoch: [ 3] [  13/ 202] time: 5029.8337, d_loss: 0.89783704, g_loss: 1.23123133
Epoch: [ 3] [  14/ 202] time: 5037.7999, d_loss: 2.37672734, g_loss: 0.23600681
Epoch: [ 3] [  15/ 202] time: 5045.8301, d_loss: 1.57110405, g_loss: 0.83420098
Epoch: [ 3] [  16/ 202] time: 5053.7946, d_loss: 1.44396067, g_loss: 0.76086235
Epoch: [ 3] [  17/ 202] time: 5061.8481, d_loss: 1.53196776, g_loss: 0.51412076
Epoch: [ 3] [  18/ 202] time: 5069.8580, d_loss: 1.57375407, g_loss: 0.54417515
Epoch: [ 3] [  19/ 202] time: 5077.8433, d_loss: 1.39412737, g_loss: 0.77946234
Epoch: [ 3] [  20/ 202] time: 5085.8452, d_loss: 1.60265851, g_loss: 0.45045370
Epoch: [ 3] [  21/ 202] time: 5093.9177, d_loss: 1.62068427, g_loss: 0.51399815
Epoch: [ 3] [  22/ 202] time: 5101.9762, d_loss: 1.41255236, g_loss: 1.02950299
Epoch: [ 3] [  23/ 202] time: 5110.0133, d_loss: 1.86913776, g_loss: 0.22938733
Epoch: [ 3] [  24/ 202] time: 5117.9806, d_loss: 1.67057300, g_loss: 1.82666183
Epoch: [ 3] [  25/ 202] time: 5126.1281, d_loss: 1.31364906, g_loss: 0.58198029
Epoch: [ 3] [  26/ 202] time: 5134.1387, d_loss: 1.55710363, g_loss: 0.41638547
Epoch: [ 3] [  27/ 202] time: 5142.1318, d_loss: 1.06611896, g_loss: 1.69697404
Epoch: [ 3] [  28/ 202] time: 5150.1176, d_loss: 1.65310931, g_loss: 0.60230500
Epoch: [ 3] [  29/ 202] time: 5158.1958, d_loss: 1.79353976, g_loss: 0.38093156
Epoch: [ 3] [  30/ 202] time: 5166.2854, d_loss: 1.53730214, g_loss: 1.40551829
Epoch: [ 3] [  31/ 202] time: 5174.3798, d_loss: 1.43076861, g_loss: 0.46487436
Epoch: [ 3] [  32/ 202] time: 5182.3465, d_loss: 1.38490343, g_loss: 1.28450418
Epoch: [ 3] [  33/ 202] time: 5190.4156, d_loss: 2.46353984, g_loss: 0.22368807
Epoch: [ 3] [  34/ 202] time: 5199.0269, d_loss: 1.67014170, g_loss: 0.83006060
Epoch: [ 3] [  35/ 202] time: 5207.0027, d_loss: 1.99781621, g_loss: 0.61195350
Epoch: [ 3] [  36/ 202] time: 5214.9613, d_loss: 1.65740180, g_loss: 0.48223811
Epoch: [ 3] [  37/ 202] time: 5222.9211, d_loss: 1.56209600, g_loss: 0.92181325
Epoch: [ 3] [  38/ 202] time: 5230.9734, d_loss: 1.19387245, g_loss: 0.64794731
Epoch: [ 3] [  39/ 202] time: 5238.9187, d_loss: 0.92306322, g_loss: 1.08416796
Epoch: [ 3] [  40/ 202] time: 5246.8567, d_loss: 1.58629870, g_loss: 0.40681136
Epoch: [ 3] [  41/ 202] time: 5254.8267, d_loss: 2.03153110, g_loss: 0.35471529
Epoch: [ 3] [  42/ 202] time: 5262.9280, d_loss: 1.87675834, g_loss: 0.59580022
Epoch: [ 3] [  43/ 202] time: 5270.8263, d_loss: 1.97783637, g_loss: 0.35898864
Epoch: [ 3] [  44/ 202] time: 5278.8129, d_loss: 2.05810118, g_loss: 0.70569485
Epoch: [ 3] [  45/ 202] time: 5286.8300, d_loss: 2.00042677, g_loss: 0.39097759
Epoch: [ 3] [  46/ 202] time: 5294.7519, d_loss: 2.14524460, g_loss: 0.37430656
Epoch: [ 3] [  47/ 202] time: 5302.6791, d_loss: 1.70805478, g_loss: 0.78052098
Epoch: [ 3] [  48/ 202] time: 5310.6089, d_loss: 2.04162621, g_loss: 0.32837051
Epoch: [ 3] [  49/ 202] time: 5318.5729, d_loss: 1.61402678, g_loss: 0.76877290
Epoch: [ 3] [  50/ 202] time: 5326.5136, d_loss: 1.61683154, g_loss: 0.84903353
Epoch: [ 3] [  51/ 202] time: 5334.4174, d_loss: 2.26087046, g_loss: 0.27769127
Epoch: [ 3] [  52/ 202] time: 5342.3627, d_loss: 1.90186071, g_loss: 0.72967756
Epoch: [ 3] [  53/ 202] time: 5350.2912, d_loss: 1.50143766, g_loss: 1.20007825
Epoch: [ 3] [  54/ 202] time: 5358.2637, d_loss: 2.44668794, g_loss: 0.21392387
Epoch: [ 3] [  55/ 202] time: 5366.2026, d_loss: 1.69485521, g_loss: 0.75522584
Epoch: [ 3] [  56/ 202] time: 5374.2071, d_loss: 1.03379357, g_loss: 1.31299758
Epoch: [ 3] [  57/ 202] time: 5382.1960, d_loss: 1.77985215, g_loss: 0.61315489
Epoch: [ 3] [  58/ 202] time: 5390.1116, d_loss: 1.42950535, g_loss: 0.48091850
Epoch: [ 3] [  59/ 202] time: 5398.0583, d_loss: 1.39470935, g_loss: 0.69769514
Epoch: [ 3] [  60/ 202] time: 5406.0201, d_loss: 1.32988250, g_loss: 0.72830045
Epoch: [ 3] [  61/ 202] time: 5413.9632, d_loss: 2.12392664, g_loss: 0.30390704
Epoch: [ 3] [  62/ 202] time: 5421.9203, d_loss: 1.97020888, g_loss: 0.67626441
Epoch: [ 3] [  63/ 202] time: 5429.8225, d_loss: 1.34574282, g_loss: 0.59909880
Epoch: [ 3] [  64/ 202] time: 5437.7848, d_loss: 1.42749023, g_loss: 0.54394263
Epoch: [ 3] [  65/ 202] time: 5445.7937, d_loss: 0.95225829, g_loss: 1.11331892
Epoch: [ 3] [  66/ 202] time: 5453.7844, d_loss: 1.55597639, g_loss: 0.58448756
Epoch: [ 3] [  67/ 202] time: 5461.7179, d_loss: 2.07437897, g_loss: 0.50394905
Epoch: [ 3] [  68/ 202] time: 5469.6334, d_loss: 1.40681374, g_loss: 2.12926340
Epoch: [ 3] [  69/ 202] time: 5477.6160, d_loss: 2.99059701, g_loss: 0.13383776
Epoch: [ 3] [  70/ 202] time: 5485.5971, d_loss: 2.33725357, g_loss: 0.47302875
Epoch: [ 3] [  71/ 202] time: 5493.5779, d_loss: 2.55548286, g_loss: 1.36107457
Epoch: [ 3] [  72/ 202] time: 5501.5539, d_loss: 2.51629186, g_loss: 0.33622220
Epoch: [ 3] [  73/ 202] time: 5509.5166, d_loss: 2.04760265, g_loss: 0.91242021
Epoch: [ 3] [  74/ 202] time: 5517.5189, d_loss: 2.29056573, g_loss: 0.52328688
Epoch: [ 3] [  75/ 202] time: 5525.4934, d_loss: 2.11611342, g_loss: 1.57882142
Epoch: [ 3] [  76/ 202] time: 5533.4447, d_loss: 2.18211913, g_loss: 0.20599967
Epoch: [ 3] [  77/ 202] time: 5541.4688, d_loss: 1.37505865, g_loss: 0.67411512
Epoch: [ 3] [  78/ 202] time: 5549.4444, d_loss: 1.98035574, g_loss: 1.01050758
Epoch: [ 3] [  79/ 202] time: 5557.3819, d_loss: 2.18136668, g_loss: 0.28543594
Epoch: [ 3] [  80/ 202] time: 5565.3900, d_loss: 2.48959494, g_loss: 0.39148843
Epoch: [ 3] [  81/ 202] time: 5573.3238, d_loss: 2.25125241, g_loss: 0.40685207
Epoch: [ 3] [  82/ 202] time: 5581.2652, d_loss: 1.54532611, g_loss: 0.59170866
Epoch: [ 3] [  83/ 202] time: 5589.1850, d_loss: 1.43514383, g_loss: 0.69117939
Epoch: [ 3] [  84/ 202] time: 5597.1038, d_loss: 1.93882453, g_loss: 0.37194341
Epoch: [ 3] [  85/ 202] time: 5604.9786, d_loss: 1.80126405, g_loss: 0.65432692
Epoch: [ 3] [  86/ 202] time: 5612.9885, d_loss: 1.53667068, g_loss: 0.65871745
Epoch: [ 3] [  87/ 202] time: 5620.9456, d_loss: 1.45400429, g_loss: 0.69961810
Epoch: [ 3] [  88/ 202] time: 5628.8630, d_loss: 1.78128541, g_loss: 0.36825746
Epoch: [ 3] [  89/ 202] time: 5636.8128, d_loss: 1.39505637, g_loss: 1.54154873
Epoch: [ 3] [  90/ 202] time: 5644.6982, d_loss: 2.10419083, g_loss: 0.22438313
Epoch: [ 3] [  91/ 202] time: 5652.6402, d_loss: 1.53884172, g_loss: 0.67051542
Epoch: [ 3] [  92/ 202] time: 5660.5625, d_loss: 1.89604211, g_loss: 0.74178326
[Sample] d_loss: 1.18591142, g_loss: 1.21486163
Epoch: [ 3] [  93/ 202] time: 5670.2943, d_loss: 2.02825904, g_loss: 0.59669614
Epoch: [ 3] [  94/ 202] time: 5678.2171, d_loss: 1.69448185, g_loss: 0.45472300
Epoch: [ 3] [  95/ 202] time: 5686.0916, d_loss: 1.13690400, g_loss: 0.90170193
Epoch: [ 3] [  96/ 202] time: 5694.0833, d_loss: 1.15499258, g_loss: 0.75722879
Epoch: [ 3] [  97/ 202] time: 5702.0549, d_loss: 1.77347624, g_loss: 0.55539382
Epoch: [ 3] [  98/ 202] time: 5710.0055, d_loss: 1.75177681, g_loss: 0.53817165
Epoch: [ 3] [  99/ 202] time: 5717.9191, d_loss: 1.84547663, g_loss: 0.54678404
Epoch: [ 3] [ 100/ 202] time: 5725.8057, d_loss: 1.35876215, g_loss: 1.16894484
Epoch: [ 3] [ 101/ 202] time: 5733.7125, d_loss: 1.89718294, g_loss: 0.36942929
Epoch: [ 3] [ 102/ 202] time: 5741.6528, d_loss: 1.79885864, g_loss: 0.54002565
Epoch: [ 3] [ 103/ 202] time: 5749.5726, d_loss: 1.46842241, g_loss: 0.65002549
Epoch: [ 3] [ 104/ 202] time: 5757.4882, d_loss: 1.79828906, g_loss: 0.55414820
Epoch: [ 3] [ 105/ 202] time: 5765.4679, d_loss: 2.13265848, g_loss: 0.23676516
Epoch: [ 3] [ 106/ 202] time: 5773.3723, d_loss: 1.48825312, g_loss: 1.35965228
Epoch: [ 3] [ 107/ 202] time: 5781.3599, d_loss: 1.39509094, g_loss: 1.00534439
Epoch: [ 3] [ 108/ 202] time: 5789.2902, d_loss: 1.55768490, g_loss: 0.65202290
Epoch: [ 3] [ 109/ 202] time: 5797.2505, d_loss: 1.63885689, g_loss: 0.74115580
Epoch: [ 3] [ 110/ 202] time: 5805.1648, d_loss: 1.00985730, g_loss: 1.46632135
Epoch: [ 3] [ 111/ 202] time: 5813.1440, d_loss: 1.12099671, g_loss: 0.86157870
Epoch: [ 3] [ 112/ 202] time: 5821.0563, d_loss: 1.14200759, g_loss: 0.72625357
Epoch: [ 3] [ 113/ 202] time: 5829.0031, d_loss: 1.14651084, g_loss: 0.80530256
Epoch: [ 3] [ 114/ 202] time: 5836.9467, d_loss: 1.42191005, g_loss: 0.67511183
Epoch: [ 3] [ 115/ 202] time: 5844.8788, d_loss: 1.34286547, g_loss: 1.05848193
Epoch: [ 3] [ 116/ 202] time: 5852.8614, d_loss: 1.52806950, g_loss: 0.54788113
Epoch: [ 3] [ 117/ 202] time: 5860.7657, d_loss: 2.47892666, g_loss: 0.22792524
Epoch: [ 3] [ 118/ 202] time: 5868.6978, d_loss: 1.66279006, g_loss: 0.81435990
Epoch: [ 3] [ 119/ 202] time: 5876.5810, d_loss: 1.81389678, g_loss: 0.33469379
Epoch: [ 3] [ 120/ 202] time: 5884.5542, d_loss: 1.10654950, g_loss: 1.01045132
Epoch: [ 3] [ 121/ 202] time: 5892.5223, d_loss: 1.55291319, g_loss: 0.71765459
Epoch: [ 3] [ 122/ 202] time: 5900.4324, d_loss: 1.63872671, g_loss: 0.59612709
Epoch: [ 3] [ 123/ 202] time: 5908.3488, d_loss: 0.95523745, g_loss: 1.74914408
Epoch: [ 3] [ 124/ 202] time: 5916.3597, d_loss: 2.06118536, g_loss: 0.33627552
Epoch: [ 3] [ 125/ 202] time: 5924.3443, d_loss: 1.31316233, g_loss: 0.78062838
Epoch: [ 3] [ 126/ 202] time: 5932.2553, d_loss: 0.85147458, g_loss: 1.78340530
Epoch: [ 3] [ 127/ 202] time: 5940.1817, d_loss: 1.41947532, g_loss: 0.59510553
Epoch: [ 3] [ 128/ 202] time: 5948.1371, d_loss: 1.94830489, g_loss: 0.30579805
Epoch: [ 3] [ 129/ 202] time: 5956.0620, d_loss: 1.56854343, g_loss: 1.01493382
Epoch: [ 3] [ 130/ 202] time: 5964.0437, d_loss: 2.13733315, g_loss: 0.36196867
Epoch: [ 3] [ 131/ 202] time: 5971.9695, d_loss: 2.34928513, g_loss: 0.47298184
Epoch: [ 3] [ 132/ 202] time: 5979.9395, d_loss: 1.77968383, g_loss: 0.40149403
Epoch: [ 3] [ 133/ 202] time: 5987.9101, d_loss: 1.46555257, g_loss: 0.67859936
Epoch: [ 3] [ 134/ 202] time: 5995.8310, d_loss: 1.28925765, g_loss: 0.91687006
Epoch: [ 3] [ 135/ 202] time: 6003.7918, d_loss: 1.78614259, g_loss: 0.60699946
Epoch: [ 3] [ 136/ 202] time: 6011.7376, d_loss: 1.88667977, g_loss: 0.37308949
Epoch: [ 3] [ 137/ 202] time: 6019.7163, d_loss: 2.43621111, g_loss: 0.62745380
Epoch: [ 3] [ 138/ 202] time: 6027.7196, d_loss: 2.57541084, g_loss: 0.26381108
Epoch: [ 3] [ 139/ 202] time: 6035.6374, d_loss: 2.22713637, g_loss: 0.63746053
Epoch: [ 3] [ 140/ 202] time: 6043.5349, d_loss: 1.53610802, g_loss: 0.48556572
Epoch: [ 3] [ 141/ 202] time: 6051.4278, d_loss: 1.72603679, g_loss: 0.49945390
Epoch: [ 3] [ 142/ 202] time: 6059.3181, d_loss: 1.88324308, g_loss: 0.53601760
Epoch: [ 3] [ 143/ 202] time: 6067.2385, d_loss: 2.38354969, g_loss: 0.33527422
Epoch: [ 3] [ 144/ 202] time: 6075.2135, d_loss: 1.54485881, g_loss: 0.63336927
Epoch: [ 3] [ 145/ 202] time: 6083.1624, d_loss: 1.29671443, g_loss: 1.02955198
Epoch: [ 3] [ 146/ 202] time: 6091.0562, d_loss: 1.41306877, g_loss: 0.66670841
Epoch: [ 3] [ 147/ 202] time: 6098.9732, d_loss: 1.50648344, g_loss: 0.50287557
Epoch: [ 3] [ 148/ 202] time: 6106.9479, d_loss: 1.52586496, g_loss: 0.77069926
Epoch: [ 3] [ 149/ 202] time: 6114.8661, d_loss: 2.01906872, g_loss: 0.44789416
Epoch: [ 3] [ 150/ 202] time: 6122.8170, d_loss: 0.94408292, g_loss: 1.28190732
Epoch: [ 3] [ 151/ 202] time: 6130.7174, d_loss: 1.13565016, g_loss: 0.70340759
Epoch: [ 3] [ 152/ 202] time: 6138.7221, d_loss: 1.78261888, g_loss: 0.30780566
Epoch: [ 3] [ 153/ 202] time: 6146.6344, d_loss: 2.12077928, g_loss: 0.50490487
Epoch: [ 3] [ 154/ 202] time: 6154.5384, d_loss: 1.89214110, g_loss: 0.36344352
Epoch: [ 3] [ 155/ 202] time: 6162.4332, d_loss: 1.68875551, g_loss: 0.63035202
Epoch: [ 3] [ 156/ 202] time: 6170.3528, d_loss: 1.66955161, g_loss: 0.94799721
Epoch: [ 3] [ 157/ 202] time: 6178.3396, d_loss: 1.42682672, g_loss: 0.61336398
Epoch: [ 3] [ 158/ 202] time: 6186.3110, d_loss: 1.75266337, g_loss: 0.54865277
Epoch: [ 3] [ 159/ 202] time: 6194.2729, d_loss: 1.40157199, g_loss: 0.72895455
Epoch: [ 3] [ 160/ 202] time: 6202.2206, d_loss: 1.31070256, g_loss: 0.64651686
Epoch: [ 3] [ 161/ 202] time: 6210.1344, d_loss: 1.27521634, g_loss: 1.01144218
Epoch: [ 3] [ 162/ 202] time: 6218.0123, d_loss: 1.29353273, g_loss: 0.61929870
Epoch: [ 3] [ 163/ 202] time: 6225.9226, d_loss: 1.13177514, g_loss: 1.21506524
Epoch: [ 3] [ 164/ 202] time: 6233.8963, d_loss: 1.54338455, g_loss: 0.40621769
Epoch: [ 3] [ 165/ 202] time: 6241.8101, d_loss: 1.21616411, g_loss: 1.24671555
Epoch: [ 3] [ 166/ 202] time: 6249.7409, d_loss: 2.01259470, g_loss: 0.25702727
Epoch: [ 3] [ 167/ 202] time: 6257.6525, d_loss: 0.99437511, g_loss: 1.57074344
Epoch: [ 3] [ 168/ 202] time: 6265.6113, d_loss: 1.37787545, g_loss: 0.80334580
Epoch: [ 3] [ 169/ 202] time: 6273.5338, d_loss: 1.20584953, g_loss: 0.86233950
Epoch: [ 3] [ 170/ 202] time: 6281.4678, d_loss: 1.25645018, g_loss: 0.85970902
Epoch: [ 3] [ 171/ 202] time: 6289.4185, d_loss: 1.18063378, g_loss: 0.75072980
Epoch: [ 3] [ 172/ 202] time: 6297.3614, d_loss: 1.40847802, g_loss: 0.71100450
Epoch: [ 3] [ 173/ 202] time: 6305.3606, d_loss: 1.30784130, g_loss: 0.84655726
Epoch: [ 3] [ 174/ 202] time: 6313.2721, d_loss: 1.39218235, g_loss: 0.56171966
Epoch: [ 3] [ 175/ 202] time: 6321.2088, d_loss: 1.73613238, g_loss: 0.35152230
Epoch: [ 3] [ 176/ 202] time: 6329.1493, d_loss: 1.37256551, g_loss: 1.10981095
Epoch: [ 3] [ 177/ 202] time: 6337.0477, d_loss: 1.19365883, g_loss: 0.63317525
Epoch: [ 3] [ 178/ 202] time: 6344.9988, d_loss: 1.85018992, g_loss: 0.27099794
Epoch: [ 3] [ 179/ 202] time: 6352.9456, d_loss: 1.64258313, g_loss: 0.81672692
Epoch: [ 3] [ 180/ 202] time: 6360.9093, d_loss: 1.50641477, g_loss: 0.70094615
Epoch: [ 3] [ 181/ 202] time: 6368.8481, d_loss: 1.49243057, g_loss: 0.48265699
Epoch: [ 3] [ 182/ 202] time: 6376.8005, d_loss: 1.24574268, g_loss: 0.70376688
Epoch: [ 3] [ 183/ 202] time: 6384.7300, d_loss: 1.85995412, g_loss: 0.34387529
Epoch: [ 3] [ 184/ 202] time: 6392.6378, d_loss: 1.91611218, g_loss: 0.72090197
Epoch: [ 3] [ 185/ 202] time: 6400.5363, d_loss: 2.13180828, g_loss: 0.22989681
Epoch: [ 3] [ 186/ 202] time: 6408.5300, d_loss: 2.23991585, g_loss: 1.02012289
Epoch: [ 3] [ 187/ 202] time: 6416.4526, d_loss: 2.42469025, g_loss: 0.25044519
Epoch: [ 3] [ 188/ 202] time: 6424.4289, d_loss: 1.61213112, g_loss: 1.06707644
Epoch: [ 3] [ 189/ 202] time: 6432.4085, d_loss: 1.74870539, g_loss: 0.40371221
Epoch: [ 3] [ 190/ 202] time: 6440.2994, d_loss: 1.35751736, g_loss: 0.63544893
Epoch: [ 3] [ 191/ 202] time: 6448.2422, d_loss: 1.45659542, g_loss: 1.01883411
Epoch: [ 3] [ 192/ 202] time: 6456.2136, d_loss: 1.75964916, g_loss: 0.32153761
[Sample] d_loss: 2.57607079, g_loss: 0.35792971
Epoch: [ 3] [ 193/ 202] time: 6465.8956, d_loss: 1.59188378, g_loss: 0.56806648
Epoch: [ 3] [ 194/ 202] time: 6473.8055, d_loss: 1.98782241, g_loss: 2.01364827
Epoch: [ 3] [ 195/ 202] time: 6481.7303, d_loss: 1.86230612, g_loss: 0.26619053
Epoch: [ 3] [ 196/ 202] time: 6489.6920, d_loss: 1.47387064, g_loss: 0.82023734
Epoch: [ 3] [ 197/ 202] time: 6497.6667, d_loss: 1.31857014, g_loss: 1.10159385
Epoch: [ 3] [ 198/ 202] time: 6505.5985, d_loss: 1.13490129, g_loss: 0.71708786
Epoch: [ 3] [ 199/ 202] time: 6513.4941, d_loss: 1.04771352, g_loss: 0.68031716
Epoch: [ 3] [ 200/ 202] time: 6521.4270, d_loss: 0.64344424, g_loss: 1.41657734
Epoch: [ 3] [ 201/ 202] time: 6529.3292, d_loss: 1.17924714, g_loss: 0.60325319
Epoch: [ 4] [   0/ 202] time: 6537.3567, d_loss: 1.20502424, g_loss: 0.68206728
Epoch: [ 4] [   1/ 202] time: 6545.3364, d_loss: 1.60830235, g_loss: 0.68100011
Epoch: [ 4] [   2/ 202] time: 6553.2592, d_loss: 1.29928470, g_loss: 0.50259590
Epoch: [ 4] [   3/ 202] time: 6561.1720, d_loss: 1.35788810, g_loss: 0.66876006
Epoch: [ 4] [   4/ 202] time: 6569.0523, d_loss: 2.54028463, g_loss: 0.24909493
Epoch: [ 4] [   5/ 202] time: 6576.9582, d_loss: 2.50209188, g_loss: 1.41127038
Epoch: [ 4] [   6/ 202] time: 6584.8976, d_loss: 1.99795461, g_loss: 0.43057165
Epoch: [ 4] [   7/ 202] time: 6592.7923, d_loss: 1.99102128, g_loss: 0.41837054
Epoch: [ 4] [   8/ 202] time: 6600.7284, d_loss: 0.66201574, g_loss: 1.48369503
Epoch: [ 4] [   9/ 202] time: 6608.6945, d_loss: 1.18757582, g_loss: 0.95382500
Epoch: [ 4] [  10/ 202] time: 6616.6712, d_loss: 1.67620289, g_loss: 0.42740822
Epoch: [ 4] [  11/ 202] time: 6624.5734, d_loss: 1.90364575, g_loss: 0.31491610
Epoch: [ 4] [  12/ 202] time: 6632.4912, d_loss: 1.64203155, g_loss: 0.54625821
Epoch: [ 4] [  13/ 202] time: 6640.4170, d_loss: 1.53323245, g_loss: 0.95630646
Epoch: [ 4] [  14/ 202] time: 6648.3715, d_loss: 1.60801625, g_loss: 0.67875481
Epoch: [ 4] [  15/ 202] time: 6656.2474, d_loss: 1.63852727, g_loss: 0.48688388
Epoch: [ 4] [  16/ 202] time: 6664.1718, d_loss: 1.56270552, g_loss: 0.60268903
Epoch: [ 4] [  17/ 202] time: 6672.0523, d_loss: 1.44977438, g_loss: 0.55312896
Epoch: [ 4] [  18/ 202] time: 6679.9913, d_loss: 1.91005254, g_loss: 0.42005610
Epoch: [ 4] [  19/ 202] time: 6687.8915, d_loss: 1.65096986, g_loss: 0.42510238
Epoch: [ 4] [  20/ 202] time: 6695.7993, d_loss: 1.87098026, g_loss: 0.30418649
Epoch: [ 4] [  21/ 202] time: 6703.7024, d_loss: 1.79086208, g_loss: 0.70861506
Epoch: [ 4] [  22/ 202] time: 6711.5679, d_loss: 1.87568724, g_loss: 0.44738412
Epoch: [ 4] [  23/ 202] time: 6719.5041, d_loss: 1.60498190, g_loss: 0.47993967
Epoch: [ 4] [  24/ 202] time: 6727.3780, d_loss: 1.87169909, g_loss: 0.46199018
Epoch: [ 4] [  25/ 202] time: 6735.2819, d_loss: 2.14528370, g_loss: 0.45562756
Epoch: [ 4] [  26/ 202] time: 6743.2695, d_loss: 2.05589008, g_loss: 0.42055562
Epoch: [ 4] [  27/ 202] time: 6751.1679, d_loss: 2.34190893, g_loss: 0.39252779
Epoch: [ 4] [  28/ 202] time: 6759.1147, d_loss: 1.90602541, g_loss: 0.40742981
Epoch: [ 4] [  29/ 202] time: 6767.0704, d_loss: 1.28247857, g_loss: 0.77787060
Epoch: [ 4] [  30/ 202] time: 6775.0496, d_loss: 1.64645684, g_loss: 0.63181579
Epoch: [ 4] [  31/ 202] time: 6782.9854, d_loss: 1.45202100, g_loss: 0.47504002
Epoch: [ 4] [  32/ 202] time: 6790.8570, d_loss: 2.01206589, g_loss: 0.41630924
Epoch: [ 4] [  33/ 202] time: 6798.8346, d_loss: 1.36723208, g_loss: 0.68699080
Epoch: [ 4] [  34/ 202] time: 6806.7818, d_loss: 1.56663823, g_loss: 0.45609024
Epoch: [ 4] [  35/ 202] time: 6814.7166, d_loss: 1.50792921, g_loss: 0.55937052
Epoch: [ 4] [  36/ 202] time: 6822.6038, d_loss: 1.23177552, g_loss: 0.86177427
Epoch: [ 4] [  37/ 202] time: 6830.4619, d_loss: 1.12644684, g_loss: 0.79604113
Epoch: [ 4] [  38/ 202] time: 6838.4316, d_loss: 2.41660500, g_loss: 0.48313367
Epoch: [ 4] [  39/ 202] time: 6846.3671, d_loss: 1.65897131, g_loss: 0.56611449
Epoch: [ 4] [  40/ 202] time: 6854.2964, d_loss: 0.81882089, g_loss: 1.48869467
Epoch: [ 4] [  41/ 202] time: 6862.1892, d_loss: 1.55574727, g_loss: 0.50540644
Epoch: [ 4] [  42/ 202] time: 6870.1340, d_loss: 1.35311961, g_loss: 0.57920188
Epoch: [ 4] [  43/ 202] time: 6878.0858, d_loss: 1.04961991, g_loss: 1.05383313
Epoch: [ 4] [  44/ 202] time: 6885.9735, d_loss: 1.88023043, g_loss: 0.36826214
Epoch: [ 4] [  45/ 202] time: 6893.9572, d_loss: 2.54516053, g_loss: 0.21843198
Epoch: [ 4] [  46/ 202] time: 6901.9581, d_loss: 2.31089187, g_loss: 0.57927740
Epoch: [ 4] [  47/ 202] time: 6909.8767, d_loss: 2.60178423, g_loss: 0.31974298
Epoch: [ 4] [  48/ 202] time: 6917.7965, d_loss: 2.44632959, g_loss: 0.40134788
Epoch: [ 4] [  49/ 202] time: 6925.6789, d_loss: 2.59544683, g_loss: 0.35320517
Epoch: [ 4] [  50/ 202] time: 6933.5635, d_loss: 2.33189392, g_loss: 0.60862422
Epoch: [ 4] [  51/ 202] time: 6941.4441, d_loss: 2.24013710, g_loss: 0.33766413
Epoch: [ 4] [  52/ 202] time: 6949.3530, d_loss: 2.14946651, g_loss: 0.41744292
Epoch: [ 4] [  53/ 202] time: 6957.2527, d_loss: 1.74876094, g_loss: 0.78459370
Epoch: [ 4] [  54/ 202] time: 6965.2427, d_loss: 2.14133453, g_loss: 0.40003151
Epoch: [ 4] [  55/ 202] time: 6973.1421, d_loss: 1.86771572, g_loss: 0.73179162
Epoch: [ 4] [  56/ 202] time: 6981.0509, d_loss: 1.88567555, g_loss: 0.48551777
Epoch: [ 4] [  57/ 202] time: 6988.9567, d_loss: 1.94810438, g_loss: 0.70560765
Epoch: [ 4] [  58/ 202] time: 6996.8712, d_loss: 1.51263130, g_loss: 0.58084226
Epoch: [ 4] [  59/ 202] time: 7004.7592, d_loss: 1.45581627, g_loss: 0.60095876
Epoch: [ 4] [  60/ 202] time: 7012.7557, d_loss: 1.92249417, g_loss: 0.34028912
Epoch: [ 4] [  61/ 202] time: 7020.7220, d_loss: 1.73617029, g_loss: 0.68173182
Epoch: [ 4] [  62/ 202] time: 7028.6590, d_loss: 1.62375176, g_loss: 0.64336580
Epoch: [ 4] [  63/ 202] time: 7036.6204, d_loss: 1.92038131, g_loss: 0.26484972
Epoch: [ 4] [  64/ 202] time: 7044.5452, d_loss: 1.62754679, g_loss: 0.69014788
Epoch: [ 4] [  65/ 202] time: 7052.5495, d_loss: 1.48189878, g_loss: 0.65746319
Epoch: [ 4] [  66/ 202] time: 7060.5180, d_loss: 2.00130916, g_loss: 0.32904232
Epoch: [ 4] [  67/ 202] time: 7068.4408, d_loss: 1.94282317, g_loss: 0.63357460
Epoch: [ 4] [  68/ 202] time: 7076.4095, d_loss: 2.26515150, g_loss: 0.42810017
Epoch: [ 4] [  69/ 202] time: 7084.2755, d_loss: 2.48829365, g_loss: 0.31469190
Epoch: [ 4] [  70/ 202] time: 7092.2069, d_loss: 2.35367060, g_loss: 0.51090968
Epoch: [ 4] [  71/ 202] time: 7100.0894, d_loss: 1.79463291, g_loss: 0.63099486
Epoch: [ 4] [  72/ 202] time: 7108.0021, d_loss: 1.76828361, g_loss: 0.44423169
Epoch: [ 4] [  73/ 202] time: 7115.9334, d_loss: 2.39804602, g_loss: 0.21957132
Epoch: [ 4] [  74/ 202] time: 7123.8458, d_loss: 2.03203678, g_loss: 0.57187134
Epoch: [ 4] [  75/ 202] time: 7131.7317, d_loss: 1.39450073, g_loss: 0.95094609
Epoch: [ 4] [  76/ 202] time: 7139.6904, d_loss: 2.22717047, g_loss: 0.32413742
Epoch: [ 4] [  77/ 202] time: 7147.6436, d_loss: 3.00561976, g_loss: 0.12931561
Epoch: [ 4] [  78/ 202] time: 7155.6073, d_loss: 1.79535842, g_loss: 0.83842665
Epoch: [ 4] [  79/ 202] time: 7163.5237, d_loss: 1.69828725, g_loss: 0.67134726
Epoch: [ 4] [  80/ 202] time: 7171.4238, d_loss: 2.43770313, g_loss: 0.29900518
Epoch: [ 4] [  81/ 202] time: 7179.4073, d_loss: 2.25722599, g_loss: 0.55116367
Epoch: [ 4] [  82/ 202] time: 7187.3211, d_loss: 1.95691240, g_loss: 0.37098864
Epoch: [ 4] [  83/ 202] time: 7195.2386, d_loss: 1.64987564, g_loss: 0.41681588
Epoch: [ 4] [  84/ 202] time: 7203.2382, d_loss: 1.84709096, g_loss: 0.58778656
Epoch: [ 4] [  85/ 202] time: 7211.1492, d_loss: 2.01650000, g_loss: 0.33707330
Epoch: [ 4] [  86/ 202] time: 7219.1146, d_loss: 1.54433036, g_loss: 0.75338399
Epoch: [ 4] [  87/ 202] time: 7227.0345, d_loss: 1.44187784, g_loss: 0.72194344
Epoch: [ 4] [  88/ 202] time: 7234.9768, d_loss: 1.78039289, g_loss: 0.33364671
Epoch: [ 4] [  89/ 202] time: 7242.9515, d_loss: 1.36300778, g_loss: 0.71231651
Epoch: [ 4] [  90/ 202] time: 7250.8624, d_loss: 1.74218225, g_loss: 0.50234544
[Sample] d_loss: 0.95409048, g_loss: 0.95648003
Epoch: [ 4] [  91/ 202] time: 7260.5704, d_loss: 1.27620029, g_loss: 0.84464455
Epoch: [ 4] [  92/ 202] time: 7268.4922, d_loss: 1.90362608, g_loss: 0.52270681
Epoch: [ 4] [  93/ 202] time: 7276.4479, d_loss: 2.03960323, g_loss: 0.42781055
Epoch: [ 4] [  94/ 202] time: 7284.4122, d_loss: 1.65501165, g_loss: 0.53062439
Epoch: [ 4] [  95/ 202] time: 7292.3294, d_loss: 1.39840817, g_loss: 0.95260525
Epoch: [ 4] [  96/ 202] time: 7300.2402, d_loss: 1.28474164, g_loss: 0.51362234
Epoch: [ 4] [  97/ 202] time: 7308.2098, d_loss: 1.17591178, g_loss: 0.79701895
Epoch: [ 4] [  98/ 202] time: 7316.0892, d_loss: 1.37907517, g_loss: 0.67875588
Epoch: [ 4] [  99/ 202] time: 7323.9882, d_loss: 1.26943111, g_loss: 0.81314331
Epoch: [ 4] [ 100/ 202] time: 7331.9339, d_loss: 1.32039499, g_loss: 0.50944811
Epoch: [ 4] [ 101/ 202] time: 7339.9265, d_loss: 1.49468529, g_loss: 0.68024170
Epoch: [ 4] [ 102/ 202] time: 7347.8094, d_loss: 1.20577025, g_loss: 0.88540447
Epoch: [ 4] [ 103/ 202] time: 7355.6684, d_loss: 1.90787578, g_loss: 0.25608262
Epoch: [ 4] [ 104/ 202] time: 7363.5718, d_loss: 1.43916345, g_loss: 0.70179909
Epoch: [ 4] [ 105/ 202] time: 7371.4490, d_loss: 2.00625658, g_loss: 0.37258482
Epoch: [ 4] [ 106/ 202] time: 7379.3103, d_loss: 1.78308010, g_loss: 0.50346917
Epoch: [ 4] [ 107/ 202] time: 7387.2079, d_loss: 1.58772397, g_loss: 0.73382300
Epoch: [ 4] [ 108/ 202] time: 7395.1098, d_loss: 1.65023398, g_loss: 0.53205836
Epoch: [ 4] [ 109/ 202] time: 7403.1283, d_loss: 2.08377123, g_loss: 0.36500815
Epoch: [ 4] [ 110/ 202] time: 7411.1040, d_loss: 1.73807716, g_loss: 0.48790103
Epoch: [ 4] [ 111/ 202] time: 7419.0813, d_loss: 2.28408337, g_loss: 0.38792962
Epoch: [ 4] [ 112/ 202] time: 7427.0303, d_loss: 1.90934801, g_loss: 0.43937016
Epoch: [ 4] [ 113/ 202] time: 7434.9891, d_loss: 1.53497696, g_loss: 0.71284366
Epoch: [ 4] [ 114/ 202] time: 7442.8902, d_loss: 1.60325730, g_loss: 0.56486571
Epoch: [ 4] [ 115/ 202] time: 7450.7595, d_loss: 1.71709287, g_loss: 0.38379049
Epoch: [ 4] [ 116/ 202] time: 7458.7195, d_loss: 1.53116918, g_loss: 0.98909736
Epoch: [ 4] [ 117/ 202] time: 7466.6533, d_loss: 2.03229189, g_loss: 0.45296234
Epoch: [ 4] [ 118/ 202] time: 7474.6107, d_loss: 1.34413791, g_loss: 0.55291450
Epoch: [ 4] [ 119/ 202] time: 7482.5133, d_loss: 1.37397802, g_loss: 0.69010913
Epoch: [ 4] [ 120/ 202] time: 7490.4509, d_loss: 1.88271928, g_loss: 0.38260382
Epoch: [ 4] [ 121/ 202] time: 7498.3347, d_loss: 1.92895675, g_loss: 0.62447929
Epoch: [ 4] [ 122/ 202] time: 7506.2387, d_loss: 1.48545790, g_loss: 0.57699728
Epoch: [ 4] [ 123/ 202] time: 7514.1439, d_loss: 1.35388649, g_loss: 0.69468397
Epoch: [ 4] [ 124/ 202] time: 7522.0326, d_loss: 1.35830665, g_loss: 0.71483713
Epoch: [ 4] [ 125/ 202] time: 7529.9933, d_loss: 1.62913847, g_loss: 0.53810537
Epoch: [ 4] [ 126/ 202] time: 7537.8890, d_loss: 1.23270917, g_loss: 0.65867180
Epoch: [ 4] [ 127/ 202] time: 7545.8147, d_loss: 1.25083685, g_loss: 0.90150452
Epoch: [ 4] [ 128/ 202] time: 7553.7214, d_loss: 1.76403844, g_loss: 0.40855548
Epoch: [ 4] [ 129/ 202] time: 7561.5787, d_loss: 1.91879225, g_loss: 0.44745684
Epoch: [ 4] [ 130/ 202] time: 7569.5074, d_loss: 1.35017216, g_loss: 0.99664342
Epoch: [ 4] [ 131/ 202] time: 7577.4079, d_loss: 1.35671163, g_loss: 0.75587887
Epoch: [ 4] [ 132/ 202] time: 7585.3118, d_loss: 1.95929456, g_loss: 0.32111478
Epoch: [ 4] [ 133/ 202] time: 7593.2591, d_loss: 2.00601172, g_loss: 0.32262659
Epoch: [ 4] [ 134/ 202] time: 7601.1448, d_loss: 1.92404819, g_loss: 0.55720294
Epoch: [ 4] [ 135/ 202] time: 7609.0377, d_loss: 1.88352156, g_loss: 0.59676623
Epoch: [ 4] [ 136/ 202] time: 7616.9925, d_loss: 1.83633757, g_loss: 0.46760333
Epoch: [ 4] [ 137/ 202] time: 7624.9219, d_loss: 1.56503403, g_loss: 0.79869854
Epoch: [ 4] [ 138/ 202] time: 7632.8008, d_loss: 1.56267846, g_loss: 0.59338796
Epoch: [ 4] [ 139/ 202] time: 7640.6969, d_loss: 0.97697562, g_loss: 0.94453621
Epoch: [ 4] [ 140/ 202] time: 7648.6189, d_loss: 1.23624873, g_loss: 0.89176881
Epoch: [ 4] [ 141/ 202] time: 7656.6048, d_loss: 2.02847314, g_loss: 0.27261868
Epoch: [ 4] [ 142/ 202] time: 7664.5714, d_loss: 1.49378777, g_loss: 0.58740872
Epoch: [ 4] [ 143/ 202] time: 7672.4745, d_loss: 1.88991821, g_loss: 0.62810546
Epoch: [ 4] [ 144/ 202] time: 7680.3700, d_loss: 1.70298409, g_loss: 0.58822191
Epoch: [ 4] [ 145/ 202] time: 7688.2748, d_loss: 1.87720680, g_loss: 0.41352740
Epoch: [ 4] [ 146/ 202] time: 7696.1615, d_loss: 1.54384422, g_loss: 0.42195314
Epoch: [ 4] [ 147/ 202] time: 7704.0349, d_loss: 1.18966091, g_loss: 0.85982955
Epoch: [ 4] [ 148/ 202] time: 7711.9965, d_loss: 1.62876046, g_loss: 0.67574340
Epoch: [ 4] [ 149/ 202] time: 7719.8777, d_loss: 2.22353911, g_loss: 0.37942499
Epoch: [ 4] [ 150/ 202] time: 7727.7955, d_loss: 1.45573783, g_loss: 0.95697033
Epoch: [ 4] [ 151/ 202] time: 7735.7095, d_loss: 1.32431507, g_loss: 0.73109877
Epoch: [ 4] [ 152/ 202] time: 7743.5994, d_loss: 1.28475916, g_loss: 0.66568822
Epoch: [ 4] [ 153/ 202] time: 7751.4935, d_loss: 1.75132298, g_loss: 0.62029380
Epoch: [ 4] [ 154/ 202] time: 7759.4063, d_loss: 1.53363085, g_loss: 0.48076808
Epoch: [ 4] [ 155/ 202] time: 7767.2877, d_loss: 1.39267588, g_loss: 0.78926498
Epoch: [ 4] [ 156/ 202] time: 7775.2453, d_loss: 1.70095992, g_loss: 0.52963376
Epoch: [ 4] [ 157/ 202] time: 7783.1719, d_loss: 1.43640995, g_loss: 0.67050517
Epoch: [ 4] [ 158/ 202] time: 7791.0701, d_loss: 1.87811637, g_loss: 0.40288255
Epoch: [ 4] [ 159/ 202] time: 7799.0458, d_loss: 1.61098456, g_loss: 1.00539446
Epoch: [ 4] [ 160/ 202] time: 7806.9860, d_loss: 1.61232281, g_loss: 0.43924016
Epoch: [ 4] [ 161/ 202] time: 7814.9189, d_loss: 1.68388140, g_loss: 0.48508781
Epoch: [ 4] [ 162/ 202] time: 7822.8243, d_loss: 1.70138645, g_loss: 0.66740620
Epoch: [ 4] [ 163/ 202] time: 7830.7271, d_loss: 1.81416023, g_loss: 0.40967214
Epoch: [ 4] [ 164/ 202] time: 7838.7027, d_loss: 1.69877505, g_loss: 0.50304323
Epoch: [ 4] [ 165/ 202] time: 7846.6624, d_loss: 1.80310082, g_loss: 0.46808872
Epoch: [ 4] [ 166/ 202] time: 7854.5977, d_loss: 1.87809181, g_loss: 0.35706139
Epoch: [ 4] [ 167/ 202] time: 7862.5156, d_loss: 1.68139446, g_loss: 0.53028023
Epoch: [ 4] [ 168/ 202] time: 7870.4375, d_loss: 1.90279245, g_loss: 0.53263986
Epoch: [ 4] [ 169/ 202] time: 7878.3942, d_loss: 2.24987507, g_loss: 0.39654404
Epoch: [ 4] [ 170/ 202] time: 7886.3143, d_loss: 1.89165878, g_loss: 0.49481621
Epoch: [ 4] [ 171/ 202] time: 7894.2576, d_loss: 2.04823065, g_loss: 0.39470798
Epoch: [ 4] [ 172/ 202] time: 7902.1679, d_loss: 2.03834772, g_loss: 0.46690258
Epoch: [ 4] [ 173/ 202] time: 7910.0853, d_loss: 1.80257761, g_loss: 0.52037710
Epoch: [ 4] [ 174/ 202] time: 7917.9661, d_loss: 1.69492483, g_loss: 0.54303718
Epoch: [ 4] [ 175/ 202] time: 7925.8970, d_loss: 1.48753536, g_loss: 0.73158628
Epoch: [ 4] [ 176/ 202] time: 7933.8472, d_loss: 1.61345506, g_loss: 0.59868169
Epoch: [ 4] [ 177/ 202] time: 7941.7724, d_loss: 1.57274210, g_loss: 0.40226945
Epoch: [ 4] [ 178/ 202] time: 7949.6923, d_loss: 1.37044597, g_loss: 0.61464155
Epoch: [ 4] [ 179/ 202] time: 7957.6061, d_loss: 1.35387897, g_loss: 0.75333756
Epoch: [ 4] [ 180/ 202] time: 7965.5768, d_loss: 1.50701308, g_loss: 0.55752420
Epoch: [ 4] [ 181/ 202] time: 7973.5765, d_loss: 1.11869407, g_loss: 0.95696950
Epoch: [ 4] [ 182/ 202] time: 7981.5122, d_loss: 1.65789270, g_loss: 0.39425594
Epoch: [ 4] [ 183/ 202] time: 7989.4296, d_loss: 1.87556195, g_loss: 0.36744970
Epoch: [ 4] [ 184/ 202] time: 7997.3305, d_loss: 1.74677217, g_loss: 1.19642699
Epoch: [ 4] [ 185/ 202] time: 8005.2273, d_loss: 1.97881603, g_loss: 0.39929059
Epoch: [ 4] [ 186/ 202] time: 8013.1521, d_loss: 1.64744020, g_loss: 0.73185384
Epoch: [ 4] [ 187/ 202] time: 8021.0596, d_loss: 1.58056724, g_loss: 0.58548951
Epoch: [ 4] [ 188/ 202] time: 8028.9584, d_loss: 1.42782760, g_loss: 0.52173722
Epoch: [ 4] [ 189/ 202] time: 8036.8896, d_loss: 1.46173716, g_loss: 0.59496182
Epoch: [ 4] [ 190/ 202] time: 8044.7846, d_loss: 1.33468914, g_loss: 0.63906860
[Sample] d_loss: 0.96081632, g_loss: 0.97235113
Epoch: [ 4] [ 191/ 202] time: 8054.4616, d_loss: 1.52382946, g_loss: 0.36579603
Epoch: [ 4] [ 192/ 202] time: 8062.8892, d_loss: 1.63399053, g_loss: 0.61977446
Epoch: [ 4] [ 193/ 202] time: 8070.8344, d_loss: 1.53915584, g_loss: 0.69017410
Epoch: [ 4] [ 194/ 202] time: 8078.7030, d_loss: 1.88243437, g_loss: 0.35550961
Epoch: [ 4] [ 195/ 202] time: 8086.6628, d_loss: 1.53426862, g_loss: 0.66803312
Epoch: [ 4] [ 196/ 202] time: 8094.5390, d_loss: 1.88303411, g_loss: 0.53777921
Epoch: [ 4] [ 197/ 202] time: 8102.4189, d_loss: 1.67576981, g_loss: 0.51371598
Epoch: [ 4] [ 198/ 202] time: 8110.2755, d_loss: 1.50027359, g_loss: 0.72093475
Epoch: [ 4] [ 199/ 202] time: 8118.2432, d_loss: 1.72024632, g_loss: 0.46911022
Epoch: [ 4] [ 200/ 202] time: 8126.2957, d_loss: 1.53954172, g_loss: 0.92442513
Epoch: [ 4] [ 201/ 202] time: 8134.2205, d_loss: 1.47029006, g_loss: 0.54100239
Epoch: [ 5] [   0/ 202] time: 8142.2083, d_loss: 1.69372261, g_loss: 0.41275176
Epoch: [ 5] [   1/ 202] time: 8150.1654, d_loss: 1.76565146, g_loss: 0.64402843
Epoch: [ 5] [   2/ 202] time: 8158.0660, d_loss: 1.44401968, g_loss: 0.57343256
Epoch: [ 5] [   3/ 202] time: 8165.9456, d_loss: 1.28005385, g_loss: 0.63453132
Epoch: [ 5] [   4/ 202] time: 8173.8849, d_loss: 1.46053076, g_loss: 0.71101022
Epoch: [ 5] [   5/ 202] time: 8181.8480, d_loss: 1.91710901, g_loss: 0.45457277
Epoch: [ 5] [   6/ 202] time: 8189.7828, d_loss: 1.61679077, g_loss: 0.51969475
Epoch: [ 5] [   7/ 202] time: 8197.6771, d_loss: 1.64791846, g_loss: 0.55791998
Epoch: [ 5] [   8/ 202] time: 8205.5849, d_loss: 1.36324978, g_loss: 0.80983126
Epoch: [ 5] [   9/ 202] time: 8213.5036, d_loss: 1.80650568, g_loss: 0.41928142
Epoch: [ 5] [  10/ 202] time: 8221.4327, d_loss: 1.88217735, g_loss: 0.26021504
Epoch: [ 5] [  11/ 202] time: 8229.3431, d_loss: 1.71247339, g_loss: 0.60179985
Epoch: [ 5] [  12/ 202] time: 8237.2619, d_loss: 1.93655598, g_loss: 0.23894134
Epoch: [ 5] [  13/ 202] time: 8245.1589, d_loss: 1.74591255, g_loss: 0.65380651
Epoch: [ 5] [  14/ 202] time: 8253.1166, d_loss: 2.43846178, g_loss: 0.33416611
Epoch: [ 5] [  15/ 202] time: 8261.0713, d_loss: 1.77842081, g_loss: 0.52287543
Epoch: [ 5] [  16/ 202] time: 8268.9518, d_loss: 1.25890994, g_loss: 0.76765478
Epoch: [ 5] [  17/ 202] time: 8276.8736, d_loss: 1.05781364, g_loss: 0.81520069
Epoch: [ 5] [  18/ 202] time: 8284.7506, d_loss: 1.36608994, g_loss: 0.64867681
Epoch: [ 5] [  19/ 202] time: 8292.6564, d_loss: 1.75432920, g_loss: 0.34677225
Epoch: [ 5] [  20/ 202] time: 8300.5226, d_loss: 2.46571541, g_loss: 0.21367654
Epoch: [ 5] [  21/ 202] time: 8308.4221, d_loss: 1.91159737, g_loss: 0.49696484
Epoch: [ 5] [  22/ 202] time: 8316.3336, d_loss: 2.40537882, g_loss: 0.44412071
Epoch: [ 5] [  23/ 202] time: 8324.2554, d_loss: 2.18421698, g_loss: 0.34976512
Epoch: [ 5] [  24/ 202] time: 8332.1462, d_loss: 1.75670528, g_loss: 0.60421973
Epoch: [ 5] [  25/ 202] time: 8340.0544, d_loss: 1.80522299, g_loss: 0.56762290
Epoch: [ 5] [  26/ 202] time: 8347.9630, d_loss: 1.49589276, g_loss: 0.63781804
Epoch: [ 5] [  27/ 202] time: 8355.8273, d_loss: 1.45998764, g_loss: 0.79882681
Epoch: [ 5] [  28/ 202] time: 8363.7115, d_loss: 1.21281278, g_loss: 0.68945265
Epoch: [ 5] [  29/ 202] time: 8371.6546, d_loss: 0.97474003, g_loss: 0.83421695
Epoch: [ 5] [  30/ 202] time: 8379.6125, d_loss: 1.18768299, g_loss: 0.78293782
Epoch: [ 5] [  31/ 202] time: 8387.5373, d_loss: 1.13485610, g_loss: 0.75645345
Epoch: [ 5] [  32/ 202] time: 8395.4715, d_loss: 1.54160261, g_loss: 0.49362472
Epoch: [ 5] [  33/ 202] time: 8403.4441, d_loss: 1.88711071, g_loss: 0.42814994
Epoch: [ 5] [  34/ 202] time: 8411.3756, d_loss: 1.36696172, g_loss: 1.06614089
Epoch: [ 5] [  35/ 202] time: 8419.3333, d_loss: 1.34666550, g_loss: 0.57320356
Epoch: [ 5] [  36/ 202] time: 8427.2279, d_loss: 1.74168491, g_loss: 0.50308144
Epoch: [ 5] [  37/ 202] time: 8435.1120, d_loss: 1.61638904, g_loss: 0.54751569
Epoch: [ 5] [  38/ 202] time: 8443.0096, d_loss: 1.46589208, g_loss: 0.89531755
Epoch: [ 5] [  39/ 202] time: 8450.8705, d_loss: 1.30609322, g_loss: 0.64678359
Epoch: [ 5] [  40/ 202] time: 8458.7835, d_loss: 1.54457569, g_loss: 0.47384053
Epoch: [ 5] [  41/ 202] time: 8466.6833, d_loss: 1.53066826, g_loss: 0.60126275
Epoch: [ 5] [  42/ 202] time: 8474.6032, d_loss: 1.43763816, g_loss: 0.77553153
Epoch: [ 5] [  43/ 202] time: 8482.4787, d_loss: 1.22621524, g_loss: 0.61240399
Epoch: [ 5] [  44/ 202] time: 8490.3257, d_loss: 2.08659053, g_loss: 0.25586733
Epoch: [ 5] [  45/ 202] time: 8498.3224, d_loss: 1.98516464, g_loss: 0.42219490
Epoch: [ 5] [  46/ 202] time: 8506.2211, d_loss: 1.59371495, g_loss: 0.73089379
Epoch: [ 5] [  47/ 202] time: 8514.1388, d_loss: 2.02615237, g_loss: 0.27555174
Epoch: [ 5] [  48/ 202] time: 8522.0283, d_loss: 1.96599388, g_loss: 0.34604207
Epoch: [ 5] [  49/ 202] time: 8530.0134, d_loss: 1.60816455, g_loss: 0.80297458
Epoch: [ 5] [  50/ 202] time: 8537.9431, d_loss: 1.56066489, g_loss: 0.56008661
Epoch: [ 5] [  51/ 202] time: 8545.8301, d_loss: 1.92989957, g_loss: 0.34894705
Epoch: [ 5] [  52/ 202] time: 8553.7706, d_loss: 2.16593957, g_loss: 0.40887278
Epoch: [ 5] [  53/ 202] time: 8561.7022, d_loss: 1.84331822, g_loss: 0.71575212
Epoch: [ 5] [  54/ 202] time: 8569.6128, d_loss: 1.99895883, g_loss: 0.48992366
Epoch: [ 5] [  55/ 202] time: 8577.5158, d_loss: 1.75503552, g_loss: 0.53910881
Epoch: [ 5] [  56/ 202] time: 8585.4114, d_loss: 1.54880607, g_loss: 0.61298585
Epoch: [ 5] [  57/ 202] time: 8593.3073, d_loss: 1.54124331, g_loss: 0.68335438
Epoch: [ 5] [  58/ 202] time: 8601.2722, d_loss: 1.49811566, g_loss: 0.44729602
Epoch: [ 5] [  59/ 202] time: 8609.1513, d_loss: 1.47793996, g_loss: 0.64693081
Epoch: [ 5] [  60/ 202] time: 8617.1691, d_loss: 1.35753286, g_loss: 0.63343662
Epoch: [ 5] [  61/ 202] time: 8625.2143, d_loss: 1.42805362, g_loss: 0.71806705
Epoch: [ 5] [  62/ 202] time: 8633.1864, d_loss: 1.70495367, g_loss: 0.66200900
Epoch: [ 5] [  63/ 202] time: 8641.0975, d_loss: 1.33301497, g_loss: 0.51708937
Epoch: [ 5] [  64/ 202] time: 8649.0981, d_loss: 2.13598990, g_loss: 0.38392779
Epoch: [ 5] [  65/ 202] time: 8657.2900, d_loss: 1.73720670, g_loss: 0.54456544
Epoch: [ 5] [  66/ 202] time: 8665.3198, d_loss: 1.52982438, g_loss: 0.56500632
Epoch: [ 5] [  67/ 202] time: 8673.3028, d_loss: 1.84472692, g_loss: 0.43791994
Epoch: [ 5] [  68/ 202] time: 8681.2628, d_loss: 1.77637446, g_loss: 0.52626359
Epoch: [ 5] [  69/ 202] time: 8689.2295, d_loss: 2.04704833, g_loss: 0.29679096
Epoch: [ 5] [  70/ 202] time: 8697.2131, d_loss: 2.34371448, g_loss: 0.34107924
Epoch: [ 5] [  71/ 202] time: 8705.1612, d_loss: 1.90515304, g_loss: 0.40023524
Epoch: [ 5] [  72/ 202] time: 8713.1997, d_loss: 2.61103415, g_loss: 0.20402321
Epoch: [ 5] [  73/ 202] time: 8721.2921, d_loss: 2.57734394, g_loss: 0.60097873
Epoch: [ 5] [  74/ 202] time: 8729.2384, d_loss: 2.47026825, g_loss: 0.17597389
Epoch: [ 5] [  75/ 202] time: 8737.1362, d_loss: 2.09082365, g_loss: 0.59068656
Epoch: [ 5] [  76/ 202] time: 8745.0890, d_loss: 2.85565186, g_loss: 0.42472941
Epoch: [ 5] [  77/ 202] time: 8753.1047, d_loss: 1.36978126, g_loss: 0.76495010
Epoch: [ 5] [  78/ 202] time: 8761.0236, d_loss: 1.33074522, g_loss: 0.89282072
Epoch: [ 5] [  79/ 202] time: 8769.2074, d_loss: 1.36493051, g_loss: 0.75489205
Epoch: [ 5] [  80/ 202] time: 8777.1177, d_loss: 1.92385876, g_loss: 0.49148029
Epoch: [ 5] [  81/ 202] time: 8785.2968, d_loss: 1.88775396, g_loss: 0.56241435
Epoch: [ 5] [  82/ 202] time: 8793.2082, d_loss: 2.31478477, g_loss: 0.46187568
Epoch: [ 5] [  83/ 202] time: 8801.0899, d_loss: 2.63358951, g_loss: 0.43514138
Epoch: [ 5] [  84/ 202] time: 8809.0496, d_loss: 2.77225637, g_loss: 0.41845277
Epoch: [ 5] [  85/ 202] time: 8817.0083, d_loss: 1.76593411, g_loss: 0.60318375
Epoch: [ 5] [  86/ 202] time: 8824.9530, d_loss: 1.57518780, g_loss: 0.54526383
Epoch: [ 5] [  87/ 202] time: 8832.8828, d_loss: 2.26161194, g_loss: 0.38285643
Epoch: [ 5] [  88/ 202] time: 8840.8455, d_loss: 1.84805715, g_loss: 0.54156780
[Sample] d_loss: 1.62639952, g_loss: 0.77341515
Epoch: [ 5] [  89/ 202] time: 8850.8060, d_loss: 1.77252853, g_loss: 0.55433446
Epoch: [ 5] [  90/ 202] time: 8859.1357, d_loss: 1.65025222, g_loss: 0.50852919
Epoch: [ 5] [  91/ 202] time: 8867.1074, d_loss: 1.35726547, g_loss: 0.74933827
Epoch: [ 5] [  92/ 202] time: 8875.0805, d_loss: 1.72237933, g_loss: 0.56633359
Epoch: [ 5] [  93/ 202] time: 8883.0581, d_loss: 1.72849894, g_loss: 0.45184547
Epoch: [ 5] [  94/ 202] time: 8890.9859, d_loss: 2.20628428, g_loss: 0.25162131
Epoch: [ 5] [  95/ 202] time: 8898.9013, d_loss: 1.83223891, g_loss: 0.56466800
Epoch: [ 5] [  96/ 202] time: 8906.8635, d_loss: 1.52425301, g_loss: 0.72681952
Epoch: [ 5] [  97/ 202] time: 8914.8358, d_loss: 1.63926458, g_loss: 0.55692494
Epoch: [ 5] [  98/ 202] time: 8922.7399, d_loss: 1.42954338, g_loss: 0.59009755
Epoch: [ 5] [  99/ 202] time: 8930.8077, d_loss: 1.10636449, g_loss: 1.01456380
Epoch: [ 5] [ 100/ 202] time: 8938.8053, d_loss: 1.18938470, g_loss: 0.64687634
Epoch: [ 5] [ 101/ 202] time: 8946.7803, d_loss: 1.64655733, g_loss: 0.47209531
Epoch: [ 5] [ 102/ 202] time: 8954.7604, d_loss: 1.39335418, g_loss: 0.89951062
Epoch: [ 5] [ 103/ 202] time: 8962.6631, d_loss: 1.42977595, g_loss: 0.56540966
Epoch: [ 5] [ 104/ 202] time: 8970.5827, d_loss: 1.64349318, g_loss: 0.49972680
Epoch: [ 5] [ 105/ 202] time: 8978.5661, d_loss: 2.12966967, g_loss: 0.29859394
Epoch: [ 5] [ 106/ 202] time: 8986.4882, d_loss: 1.55726314, g_loss: 0.64948070
Epoch: [ 5] [ 107/ 202] time: 8994.4075, d_loss: 1.34330404, g_loss: 1.04983974
Epoch: [ 5] [ 108/ 202] time: 9002.2811, d_loss: 1.50938916, g_loss: 0.63743734
Epoch: [ 5] [ 109/ 202] time: 9010.2384, d_loss: 2.08863068, g_loss: 0.27272376
Epoch: [ 5] [ 110/ 202] time: 9018.2942, d_loss: 1.44416344, g_loss: 0.76324248
Epoch: [ 5] [ 111/ 202] time: 9026.2595, d_loss: 1.55313182, g_loss: 0.84402549
Epoch: [ 5] [ 112/ 202] time: 9034.3633, d_loss: 1.66398573, g_loss: 0.51089954
Epoch: [ 5] [ 113/ 202] time: 9042.4009, d_loss: 1.59221923, g_loss: 0.49150547
Epoch: [ 5] [ 114/ 202] time: 9050.3566, d_loss: 1.41113305, g_loss: 0.58755410
Epoch: [ 5] [ 115/ 202] time: 9058.2681, d_loss: 1.39224672, g_loss: 0.68199575
Epoch: [ 5] [ 116/ 202] time: 9066.2300, d_loss: 1.72918642, g_loss: 0.41265684
Epoch: [ 5] [ 117/ 202] time: 9074.1244, d_loss: 1.79565811, g_loss: 0.62587589
Epoch: [ 5] [ 118/ 202] time: 9082.1579, d_loss: 1.50549579, g_loss: 0.62082416
Epoch: [ 5] [ 119/ 202] time: 9090.0708, d_loss: 1.50801063, g_loss: 0.59665442
Epoch: [ 5] [ 120/ 202] time: 9098.0573, d_loss: 1.69236112, g_loss: 0.42915875
Epoch: [ 5] [ 121/ 202] time: 9106.0204, d_loss: 2.04228687, g_loss: 0.60988724
Epoch: [ 5] [ 122/ 202] time: 9113.9080, d_loss: 1.78399038, g_loss: 0.66840690
Epoch: [ 5] [ 123/ 202] time: 9121.8436, d_loss: 1.43301368, g_loss: 0.58300757
Epoch: [ 5] [ 124/ 202] time: 9129.7554, d_loss: 1.40059292, g_loss: 0.56585395
Epoch: [ 5] [ 125/ 202] time: 9137.7453, d_loss: 2.15519714, g_loss: 0.41446894
Epoch: [ 5] [ 126/ 202] time: 9145.6577, d_loss: 1.89392591, g_loss: 0.43386480
Epoch: [ 5] [ 127/ 202] time: 9153.6168, d_loss: 1.46889663, g_loss: 1.10909510
Epoch: [ 5] [ 128/ 202] time: 9161.5923, d_loss: 1.27692974, g_loss: 0.67135692
Epoch: [ 5] [ 129/ 202] time: 9169.6631, d_loss: 2.01749754, g_loss: 0.30345875
Epoch: [ 5] [ 130/ 202] time: 9177.6472, d_loss: 1.81706142, g_loss: 0.70009923
Epoch: [ 5] [ 131/ 202] time: 9185.6078, d_loss: 1.73664927, g_loss: 0.61305964
Epoch: [ 5] [ 132/ 202] time: 9194.2825, d_loss: 1.81897712, g_loss: 0.34017876
Epoch: [ 5] [ 133/ 202] time: 9202.2327, d_loss: 1.57915616, g_loss: 0.43805820
Epoch: [ 5] [ 134/ 202] time: 9210.2346, d_loss: 1.26085734, g_loss: 0.94611204
Epoch: [ 5] [ 135/ 202] time: 9218.2559, d_loss: 1.44872677, g_loss: 0.81259304
Epoch: [ 5] [ 136/ 202] time: 9226.1857, d_loss: 1.58302844, g_loss: 0.49335203
Epoch: [ 5] [ 137/ 202] time: 9234.1207, d_loss: 1.64878941, g_loss: 0.48873156
Epoch: [ 5] [ 138/ 202] time: 9242.0529, d_loss: 1.52426076, g_loss: 0.61362088
Epoch: [ 5] [ 139/ 202] time: 9250.1259, d_loss: 0.91537970, g_loss: 1.16464663
Epoch: [ 5] [ 140/ 202] time: 9258.2819, d_loss: 1.72587097, g_loss: 0.38552159
Epoch: [ 5] [ 141/ 202] time: 9266.2620, d_loss: 1.74857581, g_loss: 0.42444554
Epoch: [ 5] [ 142/ 202] time: 9274.1822, d_loss: 1.52435684, g_loss: 0.79840839
Epoch: [ 5] [ 143/ 202] time: 9282.1103, d_loss: 1.40542495, g_loss: 0.77770954
Epoch: [ 5] [ 144/ 202] time: 9290.1221, d_loss: 1.41149950, g_loss: 0.51001287
Epoch: [ 5] [ 145/ 202] time: 9298.1303, d_loss: 1.69450140, g_loss: 0.54959428
Epoch: [ 5] [ 146/ 202] time: 9306.0340, d_loss: 1.64696527, g_loss: 0.45026696
Epoch: [ 5] [ 147/ 202] time: 9314.0234, d_loss: 1.54297352, g_loss: 1.04549563
Epoch: [ 5] [ 148/ 202] time: 9321.9877, d_loss: 1.60534918, g_loss: 0.44405293
Epoch: [ 5] [ 149/ 202] time: 9329.9127, d_loss: 1.72896338, g_loss: 0.47126251
Epoch: [ 5] [ 150/ 202] time: 9337.8156, d_loss: 1.80486596, g_loss: 0.46793741
Epoch: [ 5] [ 151/ 202] time: 9345.7033, d_loss: 1.61613750, g_loss: 0.65005904
Epoch: [ 5] [ 152/ 202] time: 9353.6560, d_loss: 1.54660821, g_loss: 0.58274865
Epoch: [ 5] [ 153/ 202] time: 9361.5505, d_loss: 1.24610806, g_loss: 0.75110650
Epoch: [ 5] [ 154/ 202] time: 9369.4235, d_loss: 1.12923229, g_loss: 0.58016384
Epoch: [ 5] [ 155/ 202] time: 9377.3500, d_loss: 1.34891391, g_loss: 0.68473148
Epoch: [ 5] [ 156/ 202] time: 9385.3539, d_loss: 1.40970397, g_loss: 0.63894022
Epoch: [ 5] [ 157/ 202] time: 9393.2991, d_loss: 1.39491510, g_loss: 0.68085003
Epoch: [ 5] [ 158/ 202] time: 9401.2188, d_loss: 1.58528662, g_loss: 0.47050557
Epoch: [ 5] [ 159/ 202] time: 9409.1713, d_loss: 1.37880135, g_loss: 0.62688625
Epoch: [ 5] [ 160/ 202] time: 9417.0924, d_loss: 1.46943557, g_loss: 0.67687303
Epoch: [ 5] [ 161/ 202] time: 9425.0168, d_loss: 1.24970114, g_loss: 0.78369331
Epoch: [ 5] [ 162/ 202] time: 9432.9257, d_loss: 1.33220315, g_loss: 0.74916238
Epoch: [ 5] [ 163/ 202] time: 9440.8510, d_loss: 1.25661135, g_loss: 0.64210624
Epoch: [ 5] [ 164/ 202] time: 9448.8311, d_loss: 1.25077868, g_loss: 0.78428364
Epoch: [ 5] [ 165/ 202] time: 9456.8394, d_loss: 1.34654117, g_loss: 0.60130417
Epoch: [ 5] [ 166/ 202] time: 9464.7453, d_loss: 1.36632085, g_loss: 0.58378184
Epoch: [ 5] [ 167/ 202] time: 9472.6487, d_loss: 1.74853444, g_loss: 0.73147655
Epoch: [ 5] [ 168/ 202] time: 9480.5468, d_loss: 1.75112200, g_loss: 0.51021194
Epoch: [ 5] [ 169/ 202] time: 9488.5090, d_loss: 1.75214291, g_loss: 0.36388886
Epoch: [ 5] [ 170/ 202] time: 9496.4755, d_loss: 1.34199953, g_loss: 0.99785459
Epoch: [ 5] [ 171/ 202] time: 9504.3750, d_loss: 1.66544533, g_loss: 0.42983016
Epoch: [ 5] [ 172/ 202] time: 9512.3398, d_loss: 2.21646738, g_loss: 0.27691618
Epoch: [ 5] [ 173/ 202] time: 9520.2468, d_loss: 1.88474178, g_loss: 0.82040447
Epoch: [ 5] [ 174/ 202] time: 9528.1221, d_loss: 1.73598456, g_loss: 0.44633532
Epoch: [ 5] [ 175/ 202] time: 9536.0600, d_loss: 1.52198684, g_loss: 0.45055562
Epoch: [ 5] [ 176/ 202] time: 9544.0032, d_loss: 1.35480869, g_loss: 0.74620605
Epoch: [ 5] [ 177/ 202] time: 9551.9304, d_loss: 1.36790395, g_loss: 0.55492342
Epoch: [ 5] [ 178/ 202] time: 9559.8405, d_loss: 1.42287362, g_loss: 0.53994799
Epoch: [ 5] [ 179/ 202] time: 9567.8364, d_loss: 1.58432662, g_loss: 0.87755191
Epoch: [ 5] [ 180/ 202] time: 9575.8431, d_loss: 1.64086986, g_loss: 0.49152559
Epoch: [ 5] [ 181/ 202] time: 9583.8093, d_loss: 1.55292320, g_loss: 0.50392711
Epoch: [ 5] [ 182/ 202] time: 9591.6776, d_loss: 2.23564649, g_loss: 0.35734487
Epoch: [ 5] [ 183/ 202] time: 9599.5481, d_loss: 1.90441990, g_loss: 0.57629097
Epoch: [ 5] [ 184/ 202] time: 9607.4773, d_loss: 1.80765676, g_loss: 0.56583643
Epoch: [ 5] [ 185/ 202] time: 9615.4071, d_loss: 1.50478578, g_loss: 0.46671149
Epoch: [ 5] [ 186/ 202] time: 9623.3943, d_loss: 1.03032184, g_loss: 0.79637933
Epoch: [ 5] [ 187/ 202] time: 9631.3248, d_loss: 1.13124430, g_loss: 0.79545271
Epoch: [ 5] [ 188/ 202] time: 9639.3131, d_loss: 1.27716446, g_loss: 0.66976148
[Sample] d_loss: 0.96623731, g_loss: 1.03202283
Epoch: [ 5] [ 189/ 202] time: 9649.0112, d_loss: 1.50531173, g_loss: 0.57940620
Epoch: [ 5] [ 190/ 202] time: 9656.9555, d_loss: 1.61638260, g_loss: 0.62297326
Epoch: [ 5] [ 191/ 202] time: 9664.9105, d_loss: 1.59302962, g_loss: 0.42300463
Epoch: [ 5] [ 192/ 202] time: 9672.8768, d_loss: 1.37770987, g_loss: 0.61460245
Epoch: [ 5] [ 193/ 202] time: 9680.8099, d_loss: 1.36368597, g_loss: 0.77011424
Epoch: [ 5] [ 194/ 202] time: 9688.7417, d_loss: 1.61793351, g_loss: 0.70850575
Epoch: [ 5] [ 195/ 202] time: 9696.6696, d_loss: 1.31861567, g_loss: 0.60710686
Epoch: [ 5] [ 196/ 202] time: 9704.6254, d_loss: 1.47188592, g_loss: 0.57521021
Epoch: [ 5] [ 197/ 202] time: 9712.5899, d_loss: 1.32090664, g_loss: 0.69475752
Epoch: [ 5] [ 198/ 202] time: 9720.4737, d_loss: 1.48099899, g_loss: 0.57463408
Epoch: [ 5] [ 199/ 202] time: 9728.4202, d_loss: 1.22548246, g_loss: 0.95118678
Epoch: [ 5] [ 200/ 202] time: 9736.3966, d_loss: 1.69804347, g_loss: 0.44952020
Epoch: [ 5] [ 201/ 202] time: 9744.3099, d_loss: 1.81014276, g_loss: 0.52573478
Epoch: [ 6] [   0/ 202] time: 9752.3973, d_loss: 1.62532842, g_loss: 0.58475590
Epoch: [ 6] [   1/ 202] time: 9760.3513, d_loss: 1.58817840, g_loss: 0.50414824
Epoch: [ 6] [   2/ 202] time: 9768.3153, d_loss: 1.47994065, g_loss: 0.52954745
Epoch: [ 6] [   3/ 202] time: 9776.2995, d_loss: 1.54512382, g_loss: 0.68096524
Epoch: [ 6] [   4/ 202] time: 9784.2416, d_loss: 1.45049930, g_loss: 0.69605595
Epoch: [ 6] [   5/ 202] time: 9792.1270, d_loss: 1.68517733, g_loss: 0.53331000
Epoch: [ 6] [   6/ 202] time: 9800.0119, d_loss: 1.42037225, g_loss: 0.55759197
Epoch: [ 6] [   7/ 202] time: 9808.1075, d_loss: 1.42317677, g_loss: 0.93058234
Epoch: [ 6] [   8/ 202] time: 9816.3594, d_loss: 1.25292420, g_loss: 0.77029592
Epoch: [ 6] [   9/ 202] time: 9824.3107, d_loss: 1.79498541, g_loss: 0.43819830
Epoch: [ 6] [  10/ 202] time: 9832.3046, d_loss: 1.56633556, g_loss: 0.52311420
Epoch: [ 6] [  11/ 202] time: 9840.3006, d_loss: 1.55866385, g_loss: 0.46167576
Epoch: [ 6] [  12/ 202] time: 9848.2942, d_loss: 1.52732348, g_loss: 0.47593245
Epoch: [ 6] [  13/ 202] time: 9856.2484, d_loss: 1.51145470, g_loss: 0.66184193
Epoch: [ 6] [  14/ 202] time: 9864.2578, d_loss: 1.73533154, g_loss: 0.53625751
Epoch: [ 6] [  15/ 202] time: 9872.1987, d_loss: 1.70512676, g_loss: 0.54212523
Epoch: [ 6] [  16/ 202] time: 9880.0921, d_loss: 1.61325622, g_loss: 0.49010542
Epoch: [ 6] [  17/ 202] time: 9888.1115, d_loss: 1.60883069, g_loss: 0.44504082
Epoch: [ 6] [  18/ 202] time: 9896.0708, d_loss: 1.64293790, g_loss: 0.71855795
Epoch: [ 6] [  19/ 202] time: 9903.9930, d_loss: 1.54221034, g_loss: 0.44615513
Epoch: [ 6] [  20/ 202] time: 9911.9379, d_loss: 1.65513682, g_loss: 0.41867182
Epoch: [ 6] [  21/ 202] time: 9919.9089, d_loss: 2.47441316, g_loss: 0.25225812
Epoch: [ 6] [  22/ 202] time: 9927.9095, d_loss: 2.35591674, g_loss: 0.42296243
Epoch: [ 6] [  23/ 202] time: 9935.8806, d_loss: 1.78566563, g_loss: 0.42408469
Epoch: [ 6] [  24/ 202] time: 9943.8879, d_loss: 2.30041456, g_loss: 0.34270826
Epoch: [ 6] [  25/ 202] time: 9951.8978, d_loss: 2.07550693, g_loss: 1.39579105
Epoch: [ 6] [  26/ 202] time: 9959.8763, d_loss: 1.54886591, g_loss: 0.41466370
Epoch: [ 6] [  27/ 202] time: 9967.7221, d_loss: 1.74127054, g_loss: 0.35793701
Epoch: [ 6] [  28/ 202] time: 9975.6671, d_loss: 1.31475282, g_loss: 0.94785410
Epoch: [ 6] [  29/ 202] time: 9983.6566, d_loss: 1.00956035, g_loss: 1.16389823
Epoch: [ 6] [  30/ 202] time: 9991.5651, d_loss: 1.68552899, g_loss: 0.46303856
Epoch: [ 6] [  31/ 202] time: 9999.5813, d_loss: 1.10934138, g_loss: 0.84611344
Epoch: [ 6] [  32/ 202] time: 10007.5082, d_loss: 1.09334016, g_loss: 0.89202297
Epoch: [ 6] [  33/ 202] time: 10015.3911, d_loss: 1.58793211, g_loss: 0.51230121
Epoch: [ 6] [  34/ 202] time: 10023.3867, d_loss: 1.00343668, g_loss: 0.83842015
Epoch: [ 6] [  35/ 202] time: 10031.2631, d_loss: 0.86753261, g_loss: 1.17816496
Epoch: [ 6] [  36/ 202] time: 10039.2003, d_loss: 1.21622157, g_loss: 0.68037951
Epoch: [ 6] [  37/ 202] time: 10047.1723, d_loss: 1.64713335, g_loss: 0.43267894
Epoch: [ 6] [  38/ 202] time: 10055.0840, d_loss: 2.19336748, g_loss: 0.46263635
Epoch: [ 6] [  39/ 202] time: 10063.0597, d_loss: 1.72299480, g_loss: 0.58721828
Epoch: [ 6] [  40/ 202] time: 10070.9758, d_loss: 1.08649540, g_loss: 1.20006824
Epoch: [ 6] [  41/ 202] time: 10078.9655, d_loss: 1.45538878, g_loss: 0.45086586
Epoch: [ 6] [  42/ 202] time: 10086.9847, d_loss: 1.41929185, g_loss: 0.58216858
Epoch: [ 6] [  43/ 202] time: 10094.8795, d_loss: 1.31757951, g_loss: 0.86017346
Epoch: [ 6] [  44/ 202] time: 10102.8350, d_loss: 1.60788560, g_loss: 0.34785318
Epoch: [ 6] [  45/ 202] time: 10110.8626, d_loss: 1.20051181, g_loss: 0.79270256
Epoch: [ 6] [  46/ 202] time: 10118.8582, d_loss: 1.02023721, g_loss: 0.97486866
Epoch: [ 6] [  47/ 202] time: 10126.7959, d_loss: 1.51151299, g_loss: 0.37971759
Epoch: [ 6] [  48/ 202] time: 10134.6962, d_loss: 1.63260555, g_loss: 0.50574768
Epoch: [ 6] [  49/ 202] time: 10142.6274, d_loss: 1.52475917, g_loss: 0.91716707
Epoch: [ 6] [  50/ 202] time: 10150.5764, d_loss: 1.67756641, g_loss: 0.45055234
Epoch: [ 6] [  51/ 202] time: 10158.5113, d_loss: 1.71880531, g_loss: 0.47419062
Epoch: [ 6] [  52/ 202] time: 10166.4684, d_loss: 1.54467010, g_loss: 0.93817806
Epoch: [ 6] [  53/ 202] time: 10174.4691, d_loss: 1.63687372, g_loss: 0.63743472
Epoch: [ 6] [  54/ 202] time: 10182.4577, d_loss: 1.54824793, g_loss: 0.39577907
Epoch: [ 6] [  55/ 202] time: 10190.3599, d_loss: 1.37395561, g_loss: 0.79030794
Epoch: [ 6] [  56/ 202] time: 10198.2633, d_loss: 1.26310945, g_loss: 0.62682378
Epoch: [ 6] [  57/ 202] time: 10206.2487, d_loss: 1.89550138, g_loss: 0.36934876
Epoch: [ 6] [  58/ 202] time: 10214.1731, d_loss: 1.39336526, g_loss: 0.65890115
Epoch: [ 6] [  59/ 202] time: 10222.1448, d_loss: 1.30312753, g_loss: 0.63157058
Epoch: [ 6] [  60/ 202] time: 10230.1497, d_loss: 1.20646584, g_loss: 0.60327899
Epoch: [ 6] [  61/ 202] time: 10238.1004, d_loss: 1.25577927, g_loss: 0.74213982
Epoch: [ 6] [  62/ 202] time: 10246.0117, d_loss: 1.88393629, g_loss: 0.50842857
Epoch: [ 6] [  63/ 202] time: 10253.9475, d_loss: 1.97237539, g_loss: 0.35209805
Epoch: [ 6] [  64/ 202] time: 10261.8716, d_loss: 1.17309248, g_loss: 1.38221383
Epoch: [ 6] [  65/ 202] time: 10269.8557, d_loss: 3.13595009, g_loss: 0.11396439
Epoch: [ 6] [  66/ 202] time: 10277.7604, d_loss: 3.29609919, g_loss: 2.65439892
Epoch: [ 6] [  67/ 202] time: 10285.7412, d_loss: 2.08081341, g_loss: 0.29146707
Epoch: [ 6] [  68/ 202] time: 10293.6774, d_loss: 1.88086045, g_loss: 0.31818762
Epoch: [ 6] [  69/ 202] time: 10301.6826, d_loss: 1.72049403, g_loss: 0.75861132
Epoch: [ 6] [  70/ 202] time: 10309.6121, d_loss: 1.82220674, g_loss: 0.64787102
Epoch: [ 6] [  71/ 202] time: 10317.5493, d_loss: 1.68766594, g_loss: 0.37520361
Epoch: [ 6] [  72/ 202] time: 10325.4960, d_loss: 1.32890987, g_loss: 0.56698990
Epoch: [ 6] [  73/ 202] time: 10333.4993, d_loss: 1.59801328, g_loss: 0.88356042
Epoch: [ 6] [  74/ 202] time: 10341.6749, d_loss: 1.56343865, g_loss: 0.51013708
Epoch: [ 6] [  75/ 202] time: 10349.6082, d_loss: 1.48471689, g_loss: 0.58179486
Epoch: [ 6] [  76/ 202] time: 10357.5764, d_loss: 2.16454506, g_loss: 0.45666352
Epoch: [ 6] [  77/ 202] time: 10365.6329, d_loss: 1.95220709, g_loss: 0.44276798
Epoch: [ 6] [  78/ 202] time: 10373.6275, d_loss: 1.71243227, g_loss: 0.78367382
Epoch: [ 6] [  79/ 202] time: 10381.5516, d_loss: 1.98619163, g_loss: 0.31059748
Epoch: [ 6] [  80/ 202] time: 10389.4374, d_loss: 1.35581207, g_loss: 0.84958631
Epoch: [ 6] [  81/ 202] time: 10397.3582, d_loss: 1.77661967, g_loss: 0.30964130
Epoch: [ 6] [  82/ 202] time: 10405.3566, d_loss: 1.24985075, g_loss: 0.80538607
Epoch: [ 6] [  83/ 202] time: 10413.3095, d_loss: 1.39088559, g_loss: 0.78960705
Epoch: [ 6] [  84/ 202] time: 10421.2683, d_loss: 1.43278337, g_loss: 0.60656500
Epoch: [ 6] [  85/ 202] time: 10429.3418, d_loss: 1.69801831, g_loss: 0.44935477
Epoch: [ 6] [  86/ 202] time: 10437.2584, d_loss: 1.72991562, g_loss: 0.66727948
[Sample] d_loss: 2.64076090, g_loss: 1.26982164
Epoch: [ 6] [  87/ 202] time: 10446.8649, d_loss: 1.99172115, g_loss: 0.50012434
Epoch: [ 6] [  88/ 202] time: 10454.7636, d_loss: 1.88539255, g_loss: 0.33788720
Epoch: [ 6] [  89/ 202] time: 10462.6631, d_loss: 1.21339393, g_loss: 1.08768976
Epoch: [ 6] [  90/ 202] time: 10470.6161, d_loss: 1.44751263, g_loss: 0.53400207
Epoch: [ 6] [  91/ 202] time: 10478.5345, d_loss: 1.27476788, g_loss: 0.75957036
Epoch: [ 6] [  92/ 202] time: 10486.4965, d_loss: 1.31358516, g_loss: 0.79927623
Epoch: [ 6] [  93/ 202] time: 10494.4183, d_loss: 1.57298100, g_loss: 0.46035016
Epoch: [ 6] [  94/ 202] time: 10502.3730, d_loss: 1.67904806, g_loss: 0.59418267
Epoch: [ 6] [  95/ 202] time: 10510.2621, d_loss: 1.87270534, g_loss: 0.55725837
Epoch: [ 6] [  96/ 202] time: 10518.2228, d_loss: 1.35493922, g_loss: 0.83146775
Epoch: [ 6] [  97/ 202] time: 10526.1032, d_loss: 1.34401965, g_loss: 0.69761765
Epoch: [ 6] [  98/ 202] time: 10534.0042, d_loss: 1.31763208, g_loss: 0.64269847
Epoch: [ 6] [  99/ 202] time: 10541.9388, d_loss: 1.46632254, g_loss: 0.66796815
Epoch: [ 6] [ 100/ 202] time: 10549.8712, d_loss: 1.32608330, g_loss: 0.69661635
Epoch: [ 6] [ 101/ 202] time: 10557.8728, d_loss: 1.59823644, g_loss: 0.48929343
Epoch: [ 6] [ 102/ 202] time: 10565.8971, d_loss: 1.49156094, g_loss: 0.66863072
Epoch: [ 6] [ 103/ 202] time: 10573.9396, d_loss: 1.13775480, g_loss: 0.89365661
Epoch: [ 6] [ 104/ 202] time: 10582.0295, d_loss: 1.61102009, g_loss: 0.45269817
Epoch: [ 6] [ 105/ 202] time: 10589.9378, d_loss: 2.28790498, g_loss: 0.23313417
Epoch: [ 6] [ 106/ 202] time: 10598.1418, d_loss: 1.47394454, g_loss: 1.25340366
Epoch: [ 6] [ 107/ 202] time: 10606.0977, d_loss: 1.47216773, g_loss: 0.68731457
Epoch: [ 6] [ 108/ 202] time: 10614.0913, d_loss: 1.65506697, g_loss: 0.67561853
Epoch: [ 6] [ 109/ 202] time: 10622.0421, d_loss: 1.79865575, g_loss: 0.51634103
Epoch: [ 6] [ 110/ 202] time: 10630.0089, d_loss: 1.36138082, g_loss: 0.61789268
Epoch: [ 6] [ 111/ 202] time: 10637.9188, d_loss: 1.42312253, g_loss: 0.79288828
Epoch: [ 6] [ 112/ 202] time: 10645.8416, d_loss: 1.61198986, g_loss: 0.60017949
Epoch: [ 6] [ 113/ 202] time: 10653.8195, d_loss: 1.29020154, g_loss: 0.65460920
Epoch: [ 6] [ 114/ 202] time: 10661.8014, d_loss: 1.71936285, g_loss: 0.38042215
Epoch: [ 6] [ 115/ 202] time: 10669.7245, d_loss: 1.66477489, g_loss: 0.49515930
Epoch: [ 6] [ 116/ 202] time: 10677.6466, d_loss: 1.39155626, g_loss: 0.75102270
Epoch: [ 6] [ 117/ 202] time: 10685.5824, d_loss: 1.74042618, g_loss: 0.38434088
Epoch: [ 6] [ 118/ 202] time: 10693.4965, d_loss: 1.58995473, g_loss: 0.41459084
Epoch: [ 6] [ 119/ 202] time: 10701.3547, d_loss: 1.03574085, g_loss: 0.95268118
Epoch: [ 6] [ 120/ 202] time: 10709.2791, d_loss: 1.40711784, g_loss: 0.64090788
Epoch: [ 6] [ 121/ 202] time: 10717.2800, d_loss: 1.85193014, g_loss: 0.46550167
Epoch: [ 6] [ 122/ 202] time: 10725.2619, d_loss: 1.60003161, g_loss: 0.49342585
Epoch: [ 6] [ 123/ 202] time: 10733.2057, d_loss: 1.28961110, g_loss: 0.80693245
Epoch: [ 6] [ 124/ 202] time: 10741.1371, d_loss: 1.32056856, g_loss: 0.62414229
Epoch: [ 6] [ 125/ 202] time: 10749.1386, d_loss: 1.89577365, g_loss: 0.43812227
Epoch: [ 6] [ 126/ 202] time: 10757.0109, d_loss: 1.38179469, g_loss: 0.90983427
Epoch: [ 6] [ 127/ 202] time: 10764.9510, d_loss: 1.33146715, g_loss: 0.63320386
Epoch: [ 6] [ 128/ 202] time: 10772.9004, d_loss: 1.74035072, g_loss: 0.34774441
Epoch: [ 6] [ 129/ 202] time: 10780.8278, d_loss: 1.78008008, g_loss: 0.58234638
Epoch: [ 6] [ 130/ 202] time: 10788.7906, d_loss: 1.60182250, g_loss: 0.72223020
Epoch: [ 6] [ 131/ 202] time: 10796.6916, d_loss: 1.41109252, g_loss: 0.56470764
Epoch: [ 6] [ 132/ 202] time: 10804.5863, d_loss: 1.33403540, g_loss: 0.53333825
Epoch: [ 6] [ 133/ 202] time: 10812.4931, d_loss: 1.03764105, g_loss: 0.79582500
Epoch: [ 6] [ 134/ 202] time: 10820.3770, d_loss: 1.14201188, g_loss: 0.79630595
Epoch: [ 6] [ 135/ 202] time: 10828.2883, d_loss: 1.31105542, g_loss: 0.70016348
Epoch: [ 6] [ 136/ 202] time: 10836.1229, d_loss: 1.65641546, g_loss: 0.53226048
Epoch: [ 6] [ 137/ 202] time: 10844.0090, d_loss: 1.62423396, g_loss: 0.63432229
Epoch: [ 6] [ 138/ 202] time: 10851.9887, d_loss: 1.67110777, g_loss: 0.52750754
Epoch: [ 6] [ 139/ 202] time: 10859.9662, d_loss: 1.57544518, g_loss: 0.69921529
Epoch: [ 6] [ 140/ 202] time: 10867.9126, d_loss: 1.36577559, g_loss: 0.61753368
Epoch: [ 6] [ 141/ 202] time: 10875.8192, d_loss: 1.30238020, g_loss: 0.70058912
Epoch: [ 6] [ 142/ 202] time: 10883.7390, d_loss: 1.34322309, g_loss: 0.58091336
Epoch: [ 6] [ 143/ 202] time: 10891.6813, d_loss: 1.68542504, g_loss: 0.52888066
Epoch: [ 6] [ 144/ 202] time: 10899.5961, d_loss: 1.48246670, g_loss: 0.63127416
Epoch: [ 6] [ 145/ 202] time: 10907.5088, d_loss: 1.60293770, g_loss: 0.41910204
Epoch: [ 6] [ 146/ 202] time: 10915.4078, d_loss: 1.60436225, g_loss: 1.00304484
Epoch: [ 6] [ 147/ 202] time: 10923.3176, d_loss: 1.48786831, g_loss: 0.34760058
Epoch: [ 6] [ 148/ 202] time: 10931.2512, d_loss: 1.48175359, g_loss: 0.97258854
Epoch: [ 6] [ 149/ 202] time: 10939.1821, d_loss: 1.63151097, g_loss: 0.52210188
Epoch: [ 6] [ 150/ 202] time: 10947.0830, d_loss: 1.78582144, g_loss: 0.29338619
Epoch: [ 6] [ 151/ 202] time: 10955.0667, d_loss: 1.89793789, g_loss: 0.94849962
Epoch: [ 6] [ 152/ 202] time: 10963.1257, d_loss: 1.27269542, g_loss: 0.75988019
Epoch: [ 6] [ 153/ 202] time: 10971.0584, d_loss: 2.40705276, g_loss: 0.19915035
Epoch: [ 6] [ 154/ 202] time: 10979.0853, d_loss: 1.18544006, g_loss: 0.92838717
Epoch: [ 6] [ 155/ 202] time: 10987.0378, d_loss: 1.54216337, g_loss: 0.73959410
Epoch: [ 6] [ 156/ 202] time: 10994.9327, d_loss: 1.67140532, g_loss: 0.53027809
Epoch: [ 6] [ 157/ 202] time: 11002.8845, d_loss: 1.48656142, g_loss: 0.63000464
Epoch: [ 6] [ 158/ 202] time: 11010.7853, d_loss: 1.07015109, g_loss: 1.06089854
Epoch: [ 6] [ 159/ 202] time: 11018.8378, d_loss: 1.27906203, g_loss: 0.56565362
Epoch: [ 6] [ 160/ 202] time: 11026.7953, d_loss: 1.45485020, g_loss: 0.54301918
Epoch: [ 6] [ 161/ 202] time: 11034.6981, d_loss: 1.62024403, g_loss: 0.70923942
Epoch: [ 6] [ 162/ 202] time: 11042.6061, d_loss: 1.46807480, g_loss: 0.66313666
Epoch: [ 6] [ 163/ 202] time: 11050.4918, d_loss: 1.93535781, g_loss: 0.28956980
Epoch: [ 6] [ 164/ 202] time: 11058.4784, d_loss: 1.64558828, g_loss: 0.82424998
Epoch: [ 6] [ 165/ 202] time: 11066.4259, d_loss: 1.23167610, g_loss: 0.78360271
Epoch: [ 6] [ 166/ 202] time: 11074.2925, d_loss: 1.49725997, g_loss: 0.54733527
Epoch: [ 6] [ 167/ 202] time: 11082.2315, d_loss: 1.50710654, g_loss: 0.65981936
Epoch: [ 6] [ 168/ 202] time: 11090.1451, d_loss: 1.51925528, g_loss: 0.76584250
Epoch: [ 6] [ 169/ 202] time: 11098.0194, d_loss: 1.72291565, g_loss: 0.40374446
Epoch: [ 6] [ 170/ 202] time: 11105.9856, d_loss: 1.38126326, g_loss: 0.60511404
Epoch: [ 6] [ 171/ 202] time: 11113.9402, d_loss: 1.52192855, g_loss: 0.56333351
Epoch: [ 6] [ 172/ 202] time: 11121.9783, d_loss: 1.65269208, g_loss: 0.53550428
Epoch: [ 6] [ 173/ 202] time: 11129.8971, d_loss: 1.56135106, g_loss: 0.69161940
Epoch: [ 6] [ 174/ 202] time: 11137.8283, d_loss: 1.48565960, g_loss: 0.59019923
Epoch: [ 6] [ 175/ 202] time: 11145.7441, d_loss: 1.44867694, g_loss: 0.47820008
Epoch: [ 6] [ 176/ 202] time: 11153.7316, d_loss: 1.56376362, g_loss: 0.91945577
Epoch: [ 6] [ 177/ 202] time: 11161.6807, d_loss: 1.47978044, g_loss: 0.43207562
Epoch: [ 6] [ 178/ 202] time: 11169.5720, d_loss: 1.78672123, g_loss: 0.35115969
Epoch: [ 6] [ 179/ 202] time: 11177.5028, d_loss: 1.54322529, g_loss: 1.00581503
Epoch: [ 6] [ 180/ 202] time: 11185.4780, d_loss: 1.40036082, g_loss: 0.65740943
Epoch: [ 6] [ 181/ 202] time: 11193.4268, d_loss: 1.31168377, g_loss: 0.51122677
Epoch: [ 6] [ 182/ 202] time: 11201.3698, d_loss: 1.44925213, g_loss: 0.56993175
Epoch: [ 6] [ 183/ 202] time: 11209.2808, d_loss: 1.63461566, g_loss: 0.68657225
Epoch: [ 6] [ 184/ 202] time: 11217.3165, d_loss: 1.36973727, g_loss: 0.66116297
Epoch: [ 6] [ 185/ 202] time: 11225.1923, d_loss: 1.85285592, g_loss: 0.39782315
Epoch: [ 6] [ 186/ 202] time: 11233.0746, d_loss: 1.44103646, g_loss: 0.70979238
[Sample] d_loss: 1.51085651, g_loss: 1.07764435
Epoch: [ 6] [ 187/ 202] time: 11242.8537, d_loss: 1.79864609, g_loss: 0.61712027
Epoch: [ 6] [ 188/ 202] time: 11250.8415, d_loss: 1.37017107, g_loss: 0.70105642
Epoch: [ 6] [ 189/ 202] time: 11258.7685, d_loss: 1.63949966, g_loss: 0.48475948
Epoch: [ 6] [ 190/ 202] time: 11266.6893, d_loss: 1.18032598, g_loss: 0.71683562
Epoch: [ 6] [ 191/ 202] time: 11274.6537, d_loss: 1.10889959, g_loss: 0.90493113
Epoch: [ 6] [ 192/ 202] time: 11282.5913, d_loss: 1.16766930, g_loss: 0.52797580
Epoch: [ 6] [ 193/ 202] time: 11290.5153, d_loss: 1.74652195, g_loss: 0.51267356
Epoch: [ 6] [ 194/ 202] time: 11298.3938, d_loss: 2.16215229, g_loss: 0.67164117
Epoch: [ 6] [ 195/ 202] time: 11306.3018, d_loss: 1.69165730, g_loss: 0.40497413
Epoch: [ 6] [ 196/ 202] time: 11314.2653, d_loss: 1.85198855, g_loss: 0.80254471
Epoch: [ 6] [ 197/ 202] time: 11322.1701, d_loss: 1.84388685, g_loss: 0.47106415
Epoch: [ 6] [ 198/ 202] time: 11330.1158, d_loss: 1.50278735, g_loss: 0.76430678
Epoch: [ 6] [ 199/ 202] time: 11338.0555, d_loss: 1.72168422, g_loss: 0.57864761
Epoch: [ 6] [ 200/ 202] time: 11345.9903, d_loss: 1.36623788, g_loss: 0.64160937
Epoch: [ 6] [ 201/ 202] time: 11353.9480, d_loss: 1.31130254, g_loss: 0.70781630
Epoch: [ 7] [   0/ 202] time: 11362.0683, d_loss: 1.58222532, g_loss: 0.42559493
Epoch: [ 7] [   1/ 202] time: 11370.0859, d_loss: 1.45453691, g_loss: 0.58015823
Epoch: [ 7] [   2/ 202] time: 11377.9768, d_loss: 1.54490495, g_loss: 0.43982783
Epoch: [ 7] [   3/ 202] time: 11385.9513, d_loss: 1.26384878, g_loss: 0.83627445
Epoch: [ 7] [   4/ 202] time: 11393.8832, d_loss: 1.38332391, g_loss: 0.69618189
Epoch: [ 7] [   5/ 202] time: 11401.9524, d_loss: 1.72803986, g_loss: 0.48633167
Epoch: [ 7] [   6/ 202] time: 11409.9500, d_loss: 1.66018784, g_loss: 0.59246588
Epoch: [ 7] [   7/ 202] time: 11418.1640, d_loss: 1.48417521, g_loss: 0.59338045
Epoch: [ 7] [   8/ 202] time: 11426.1403, d_loss: 0.97089279, g_loss: 1.21964288
Epoch: [ 7] [   9/ 202] time: 11434.1930, d_loss: 1.56364763, g_loss: 0.48332036
Epoch: [ 7] [  10/ 202] time: 11442.2873, d_loss: 1.32048893, g_loss: 0.52554625
Epoch: [ 7] [  11/ 202] time: 11450.2291, d_loss: 1.60324264, g_loss: 0.55700409
Epoch: [ 7] [  12/ 202] time: 11458.1159, d_loss: 1.85731995, g_loss: 0.26386276
Epoch: [ 7] [  13/ 202] time: 11466.2330, d_loss: 1.72439075, g_loss: 0.99623978
Epoch: [ 7] [  14/ 202] time: 11474.1898, d_loss: 2.05803108, g_loss: 0.46956459
Epoch: [ 7] [  15/ 202] time: 11482.1954, d_loss: 1.41515040, g_loss: 0.63680184
Epoch: [ 7] [  16/ 202] time: 11490.0454, d_loss: 1.08813775, g_loss: 1.02361524
Epoch: [ 7] [  17/ 202] time: 11498.0333, d_loss: 0.84153569, g_loss: 1.11066175
Epoch: [ 7] [  18/ 202] time: 11505.9192, d_loss: 1.56219625, g_loss: 0.43561879
Epoch: [ 7] [  19/ 202] time: 11513.8336, d_loss: 1.36490798, g_loss: 0.50746751
Epoch: [ 7] [  20/ 202] time: 11521.7467, d_loss: 1.55706108, g_loss: 0.49597186
Epoch: [ 7] [  21/ 202] time: 11529.7473, d_loss: 1.45470309, g_loss: 0.62040150
Epoch: [ 7] [  22/ 202] time: 11537.7699, d_loss: 1.30966461, g_loss: 0.66342378
Epoch: [ 7] [  23/ 202] time: 11546.1445, d_loss: 1.31305671, g_loss: 0.69778299
Epoch: [ 7] [  24/ 202] time: 11554.0873, d_loss: 1.99287426, g_loss: 0.36868733
Epoch: [ 7] [  25/ 202] time: 11562.0512, d_loss: 2.18338633, g_loss: 0.37317783
Epoch: [ 7] [  26/ 202] time: 11570.1503, d_loss: 1.86470914, g_loss: 0.56611842
Epoch: [ 7] [  27/ 202] time: 11578.0962, d_loss: 1.89096546, g_loss: 0.55002880
Epoch: [ 7] [  28/ 202] time: 11586.1387, d_loss: 1.43050122, g_loss: 0.89941543
Epoch: [ 7] [  29/ 202] time: 11594.1672, d_loss: 1.26177788, g_loss: 0.55693620
Epoch: [ 7] [  30/ 202] time: 11602.1359, d_loss: 1.38626242, g_loss: 0.70641363
Epoch: [ 7] [  31/ 202] time: 11610.0817, d_loss: 0.94237041, g_loss: 1.11683202
Epoch: [ 7] [  32/ 202] time: 11617.9484, d_loss: 1.32017708, g_loss: 0.54337507
Epoch: [ 7] [  33/ 202] time: 11625.9639, d_loss: 2.32266545, g_loss: 0.23088530
Epoch: [ 7] [  34/ 202] time: 11634.0014, d_loss: 1.09760082, g_loss: 1.05368245
Epoch: [ 7] [  35/ 202] time: 11642.0199, d_loss: 1.12008822, g_loss: 0.78859890
Epoch: [ 7] [  36/ 202] time: 11649.8818, d_loss: 1.58236253, g_loss: 0.41925675
Epoch: [ 7] [  37/ 202] time: 11657.7900, d_loss: 1.41242349, g_loss: 0.66980088
Epoch: [ 7] [  38/ 202] time: 11665.7488, d_loss: 1.33783150, g_loss: 0.56361514
Epoch: [ 7] [  39/ 202] time: 11673.6656, d_loss: 1.46201026, g_loss: 0.87678909
Epoch: [ 7] [  40/ 202] time: 11681.6170, d_loss: 1.81767130, g_loss: 0.30115935
Epoch: [ 7] [  41/ 202] time: 11689.6479, d_loss: 1.62354255, g_loss: 0.77221239
Epoch: [ 7] [  42/ 202] time: 11697.5846, d_loss: 1.45060921, g_loss: 0.53385842
Epoch: [ 7] [  43/ 202] time: 11705.5442, d_loss: 1.19615698, g_loss: 0.83421171
Epoch: [ 7] [  44/ 202] time: 11713.4656, d_loss: 1.67114353, g_loss: 0.38255027
Epoch: [ 7] [  45/ 202] time: 11721.5041, d_loss: 2.10824037, g_loss: 0.25183815
Epoch: [ 7] [  46/ 202] time: 11729.4648, d_loss: 1.38888144, g_loss: 0.59206343
Epoch: [ 7] [  47/ 202] time: 11737.4176, d_loss: 1.77191544, g_loss: 0.30043617
Epoch: [ 7] [  48/ 202] time: 11745.3376, d_loss: 2.12157297, g_loss: 0.45516327
Epoch: [ 7] [  49/ 202] time: 11753.2178, d_loss: 1.95703363, g_loss: 0.43469644
Epoch: [ 7] [  50/ 202] time: 11761.1833, d_loss: 2.00927091, g_loss: 0.41992313
Epoch: [ 7] [  51/ 202] time: 11769.1355, d_loss: 1.43986702, g_loss: 0.46432582
Epoch: [ 7] [  52/ 202] time: 11777.0880, d_loss: 1.21512485, g_loss: 0.96219707
Epoch: [ 7] [  53/ 202] time: 11785.0457, d_loss: 1.43776131, g_loss: 0.73133695
Epoch: [ 7] [  54/ 202] time: 11793.0247, d_loss: 2.05106902, g_loss: 0.27114791
Epoch: [ 7] [  55/ 202] time: 11801.0577, d_loss: 1.63107407, g_loss: 1.04067540
Epoch: [ 7] [  56/ 202] time: 11808.9483, d_loss: 1.41222525, g_loss: 0.75850660
Epoch: [ 7] [  57/ 202] time: 11816.8757, d_loss: 1.65113759, g_loss: 0.53328276
Epoch: [ 7] [  58/ 202] time: 11824.9660, d_loss: 1.61040699, g_loss: 0.59407210
Epoch: [ 7] [  59/ 202] time: 11832.9686, d_loss: 2.01987100, g_loss: 0.28078228
Epoch: [ 7] [  60/ 202] time: 11840.8596, d_loss: 1.70378399, g_loss: 0.64359891
Epoch: [ 7] [  61/ 202] time: 11849.0048, d_loss: 1.43970156, g_loss: 0.64815867
Epoch: [ 7] [  62/ 202] time: 11856.9709, d_loss: 1.87630057, g_loss: 0.37247658
Epoch: [ 7] [  63/ 202] time: 11864.8914, d_loss: 1.39321768, g_loss: 0.84080619
Epoch: [ 7] [  64/ 202] time: 11872.7963, d_loss: 2.07542539, g_loss: 0.31840074
Epoch: [ 7] [  65/ 202] time: 11880.7057, d_loss: 1.61743784, g_loss: 0.55703163
Epoch: [ 7] [  66/ 202] time: 11888.6295, d_loss: 1.78831089, g_loss: 0.43779030
Epoch: [ 7] [  67/ 202] time: 11896.6269, d_loss: 1.63307393, g_loss: 0.73401737
Epoch: [ 7] [  68/ 202] time: 11904.5269, d_loss: 1.73538828, g_loss: 0.44130075
Epoch: [ 7] [  69/ 202] time: 11912.4447, d_loss: 2.86951852, g_loss: 0.20614073
Epoch: [ 7] [  70/ 202] time: 11920.4333, d_loss: 2.20353651, g_loss: 0.83014953
Epoch: [ 7] [  71/ 202] time: 11928.3237, d_loss: 2.58315635, g_loss: 0.17891210
Epoch: [ 7] [  72/ 202] time: 11936.2891, d_loss: 2.21286440, g_loss: 0.45006278
Epoch: [ 7] [  73/ 202] time: 11944.2204, d_loss: 1.80104136, g_loss: 1.21983981
Epoch: [ 7] [  74/ 202] time: 11952.1252, d_loss: 1.87741911, g_loss: 0.24031408
Epoch: [ 7] [  75/ 202] time: 11960.0423, d_loss: 1.24759054, g_loss: 0.70472515
Epoch: [ 7] [  76/ 202] time: 11967.9303, d_loss: 1.73715639, g_loss: 0.56155962
Epoch: [ 7] [  77/ 202] time: 11975.8019, d_loss: 1.91116905, g_loss: 0.31460330
Epoch: [ 7] [  78/ 202] time: 11983.7143, d_loss: 1.31377101, g_loss: 0.80772555
Epoch: [ 7] [  79/ 202] time: 11991.6095, d_loss: 2.02310777, g_loss: 0.36108342
Epoch: [ 7] [  80/ 202] time: 11999.5387, d_loss: 1.67827106, g_loss: 0.48606616
Epoch: [ 7] [  81/ 202] time: 12007.5645, d_loss: 2.15271139, g_loss: 0.23792437
Epoch: [ 7] [  82/ 202] time: 12015.5192, d_loss: 1.97443163, g_loss: 1.06105781
Epoch: [ 7] [  83/ 202] time: 12023.5218, d_loss: 2.07696724, g_loss: 0.26511320
Epoch: [ 7] [  84/ 202] time: 12031.5024, d_loss: 1.56159258, g_loss: 0.62151223
[Sample] d_loss: 1.87243748, g_loss: 0.91393018
Epoch: [ 7] [  85/ 202] time: 12041.3652, d_loss: 1.63622415, g_loss: 0.57154918
Epoch: [ 7] [  86/ 202] time: 12049.7794, d_loss: 1.43545043, g_loss: 0.74389696
Epoch: [ 7] [  87/ 202] time: 12057.7916, d_loss: 1.91517258, g_loss: 0.35765985
Epoch: [ 7] [  88/ 202] time: 12065.8080, d_loss: 1.72075844, g_loss: 0.41224870
Epoch: [ 7] [  89/ 202] time: 12073.8545, d_loss: 1.31016934, g_loss: 0.90186119
Epoch: [ 7] [  90/ 202] time: 12081.7946, d_loss: 1.85632348, g_loss: 0.33435974
Epoch: [ 7] [  91/ 202] time: 12089.8072, d_loss: 0.98398137, g_loss: 1.26700735
Epoch: [ 7] [  92/ 202] time: 12097.7253, d_loss: 1.26219308, g_loss: 0.76542574
Epoch: [ 7] [  93/ 202] time: 12105.5983, d_loss: 1.38641572, g_loss: 0.58446503
Epoch: [ 7] [  94/ 202] time: 12113.5269, d_loss: 1.43724179, g_loss: 0.57400101
Epoch: [ 7] [  95/ 202] time: 12121.4472, d_loss: 1.41799116, g_loss: 0.82466620
Epoch: [ 7] [  96/ 202] time: 12129.3423, d_loss: 0.94417983, g_loss: 0.93246937
Epoch: [ 7] [  97/ 202] time: 12137.3054, d_loss: 1.40124679, g_loss: 0.50691414
Epoch: [ 7] [  98/ 202] time: 12145.1847, d_loss: 1.38087559, g_loss: 0.81504130
Epoch: [ 7] [  99/ 202] time: 12153.1347, d_loss: 1.10578299, g_loss: 0.90457702
Epoch: [ 7] [ 100/ 202] time: 12161.1148, d_loss: 1.57660747, g_loss: 0.35706908
Epoch: [ 7] [ 101/ 202] time: 12169.0776, d_loss: 1.53818679, g_loss: 0.63066173
Epoch: [ 7] [ 102/ 202] time: 12176.9390, d_loss: 1.72078085, g_loss: 0.52633870
Epoch: [ 7] [ 103/ 202] time: 12184.8323, d_loss: 1.64808965, g_loss: 0.42465138
Epoch: [ 7] [ 104/ 202] time: 12192.7998, d_loss: 1.65675008, g_loss: 0.68165970
Epoch: [ 7] [ 105/ 202] time: 12200.7846, d_loss: 1.85057080, g_loss: 0.37356651
Epoch: [ 7] [ 106/ 202] time: 12208.7147, d_loss: 1.93214166, g_loss: 0.39212030
Epoch: [ 7] [ 107/ 202] time: 12216.6780, d_loss: 2.02850485, g_loss: 0.49242529
Epoch: [ 7] [ 108/ 202] time: 12224.8751, d_loss: 2.03596735, g_loss: 0.33276057
Epoch: [ 7] [ 109/ 202] time: 12232.7901, d_loss: 1.56695843, g_loss: 0.55963075
Epoch: [ 7] [ 110/ 202] time: 12240.7074, d_loss: 1.11124790, g_loss: 1.02860248
Epoch: [ 7] [ 111/ 202] time: 12248.6029, d_loss: 1.76182437, g_loss: 0.48724306
Epoch: [ 7] [ 112/ 202] time: 12256.5784, d_loss: 1.52658749, g_loss: 0.56316185
Epoch: [ 7] [ 113/ 202] time: 12264.7812, d_loss: 1.64561415, g_loss: 0.47187072
Epoch: [ 7] [ 114/ 202] time: 12272.7562, d_loss: 1.39523339, g_loss: 0.82033902
Epoch: [ 7] [ 115/ 202] time: 12280.6802, d_loss: 1.56002951, g_loss: 0.55213296
Epoch: [ 7] [ 116/ 202] time: 12288.6114, d_loss: 1.43143630, g_loss: 0.59868944
Epoch: [ 7] [ 117/ 202] time: 12296.5707, d_loss: 1.53685701, g_loss: 1.00263524
Epoch: [ 7] [ 118/ 202] time: 12304.5592, d_loss: 1.52669835, g_loss: 0.37317914
Epoch: [ 7] [ 119/ 202] time: 12312.4682, d_loss: 1.69192278, g_loss: 0.51644313
Epoch: [ 7] [ 120/ 202] time: 12320.4415, d_loss: 3.04588461, g_loss: 0.16870597
Epoch: [ 7] [ 121/ 202] time: 12328.5598, d_loss: 1.89214754, g_loss: 1.21162808
Epoch: [ 7] [ 122/ 202] time: 12336.4805, d_loss: 1.64564443, g_loss: 0.35879534
Epoch: [ 7] [ 123/ 202] time: 12344.3801, d_loss: 1.16962790, g_loss: 0.92143238
Epoch: [ 7] [ 124/ 202] time: 12352.3142, d_loss: 0.96687484, g_loss: 0.98803788
Epoch: [ 7] [ 125/ 202] time: 12360.5231, d_loss: 1.76083755, g_loss: 0.40574509
Epoch: [ 7] [ 126/ 202] time: 12368.5266, d_loss: 1.21563733, g_loss: 0.73425806
Epoch: [ 7] [ 127/ 202] time: 12376.4614, d_loss: 1.09450066, g_loss: 1.04262173
Epoch: [ 7] [ 128/ 202] time: 12384.4660, d_loss: 1.19143009, g_loss: 0.57683659
Epoch: [ 7] [ 129/ 202] time: 12392.5569, d_loss: 1.36681771, g_loss: 0.76942623
Epoch: [ 7] [ 130/ 202] time: 12400.6154, d_loss: 1.08751166, g_loss: 0.88431513
Epoch: [ 7] [ 131/ 202] time: 12408.5751, d_loss: 1.34011579, g_loss: 0.60282058
Epoch: [ 7] [ 132/ 202] time: 12416.5643, d_loss: 1.27885437, g_loss: 0.69252521
Epoch: [ 7] [ 133/ 202] time: 12424.5523, d_loss: 1.47272694, g_loss: 0.47862148
Epoch: [ 7] [ 134/ 202] time: 12432.4132, d_loss: 1.52428651, g_loss: 0.72929424
Epoch: [ 7] [ 135/ 202] time: 12440.2717, d_loss: 1.65252054, g_loss: 0.63176811
Epoch: [ 7] [ 136/ 202] time: 12448.1661, d_loss: 1.81078362, g_loss: 0.32216612
Epoch: [ 7] [ 137/ 202] time: 12456.0883, d_loss: 1.22319925, g_loss: 0.88291210
Epoch: [ 7] [ 138/ 202] time: 12464.0590, d_loss: 1.29725301, g_loss: 0.73899245
Epoch: [ 7] [ 139/ 202] time: 12472.0174, d_loss: 1.38381588, g_loss: 0.45394409
Epoch: [ 7] [ 140/ 202] time: 12479.9873, d_loss: 1.29560089, g_loss: 0.74022543
Epoch: [ 7] [ 141/ 202] time: 12487.8734, d_loss: 1.66821206, g_loss: 0.40898493
Epoch: [ 7] [ 142/ 202] time: 12495.9228, d_loss: 1.13674676, g_loss: 0.79633582
Epoch: [ 7] [ 143/ 202] time: 12503.8925, d_loss: 1.40708518, g_loss: 0.67279482
Epoch: [ 7] [ 144/ 202] time: 12511.8979, d_loss: 1.48201585, g_loss: 0.48173442
Epoch: [ 7] [ 145/ 202] time: 12519.7573, d_loss: 1.73722267, g_loss: 0.47328466
Epoch: [ 7] [ 146/ 202] time: 12527.6163, d_loss: 1.44681716, g_loss: 0.60883427
Epoch: [ 7] [ 147/ 202] time: 12535.5513, d_loss: 1.42993116, g_loss: 0.56626427
Epoch: [ 7] [ 148/ 202] time: 12543.5449, d_loss: 1.82676721, g_loss: 0.35565540
Epoch: [ 7] [ 149/ 202] time: 12551.4874, d_loss: 1.77096534, g_loss: 0.65162361
Epoch: [ 7] [ 150/ 202] time: 12559.3853, d_loss: 1.31885648, g_loss: 0.65332073
Epoch: [ 7] [ 151/ 202] time: 12567.3512, d_loss: 1.52676308, g_loss: 0.62052369
Epoch: [ 7] [ 152/ 202] time: 12575.2488, d_loss: 1.44406354, g_loss: 0.50837642
Epoch: [ 7] [ 153/ 202] time: 12583.1526, d_loss: 1.50069857, g_loss: 1.01024008
Epoch: [ 7] [ 154/ 202] time: 12591.0634, d_loss: 2.19350219, g_loss: 0.18499537
Epoch: [ 7] [ 155/ 202] time: 12599.0295, d_loss: 1.94073212, g_loss: 2.12320900
Epoch: [ 7] [ 156/ 202] time: 12606.9483, d_loss: 1.98678410, g_loss: 0.29867065
Epoch: [ 7] [ 157/ 202] time: 12614.9525, d_loss: 1.81819689, g_loss: 0.46596020
Epoch: [ 7] [ 158/ 202] time: 12622.8248, d_loss: 1.07387865, g_loss: 0.92553592
Epoch: [ 7] [ 159/ 202] time: 12630.7846, d_loss: 1.31767750, g_loss: 0.87402505
Epoch: [ 7] [ 160/ 202] time: 12638.6615, d_loss: 1.52024353, g_loss: 0.40618342
Epoch: [ 7] [ 161/ 202] time: 12646.6433, d_loss: 1.07886052, g_loss: 0.84114552
Epoch: [ 7] [ 162/ 202] time: 12654.5340, d_loss: 0.82039905, g_loss: 1.37458408
Epoch: [ 7] [ 163/ 202] time: 12662.4414, d_loss: 2.02441406, g_loss: 0.24446821
Epoch: [ 7] [ 164/ 202] time: 12670.3641, d_loss: 1.66896820, g_loss: 0.75119781
Epoch: [ 7] [ 165/ 202] time: 12678.3558, d_loss: 1.53165817, g_loss: 0.89360559
Epoch: [ 7] [ 166/ 202] time: 12686.2691, d_loss: 1.16202199, g_loss: 0.79813457
Epoch: [ 7] [ 167/ 202] time: 12694.2391, d_loss: 1.49378705, g_loss: 0.42830002
Epoch: [ 7] [ 168/ 202] time: 12702.2367, d_loss: 1.49891567, g_loss: 0.58416665
Epoch: [ 7] [ 169/ 202] time: 12710.1675, d_loss: 1.31649542, g_loss: 0.91704619
Epoch: [ 7] [ 170/ 202] time: 12718.0724, d_loss: 1.51623571, g_loss: 0.49479124
Epoch: [ 7] [ 171/ 202] time: 12726.0730, d_loss: 1.49080515, g_loss: 0.65091538
Epoch: [ 7] [ 172/ 202] time: 12734.2212, d_loss: 2.59231830, g_loss: 0.20118894
Epoch: [ 7] [ 173/ 202] time: 12742.1891, d_loss: 1.70924425, g_loss: 0.82660043
Epoch: [ 7] [ 174/ 202] time: 12750.1319, d_loss: 1.39640439, g_loss: 0.62945813
Epoch: [ 7] [ 175/ 202] time: 12758.0387, d_loss: 1.60520542, g_loss: 0.46067822
Epoch: [ 7] [ 176/ 202] time: 12766.0119, d_loss: 2.18828535, g_loss: 0.43507501
Epoch: [ 7] [ 177/ 202] time: 12773.9552, d_loss: 1.96173322, g_loss: 0.40295130
Epoch: [ 7] [ 178/ 202] time: 12781.8324, d_loss: 1.71944177, g_loss: 0.45527309
Epoch: [ 7] [ 179/ 202] time: 12789.7263, d_loss: 1.35178685, g_loss: 1.13901055
Epoch: [ 7] [ 180/ 202] time: 12797.6342, d_loss: 1.45081294, g_loss: 0.51982409
Epoch: [ 7] [ 181/ 202] time: 12805.4799, d_loss: 1.94700313, g_loss: 0.31051207
Epoch: [ 7] [ 182/ 202] time: 12813.4723, d_loss: 1.40474319, g_loss: 0.68443024
Epoch: [ 7] [ 183/ 202] time: 12821.5453, d_loss: 1.00421643, g_loss: 1.22349751
Epoch: [ 7] [ 184/ 202] time: 12829.4588, d_loss: 1.61577034, g_loss: 0.44983697
[Sample] d_loss: 1.21002269, g_loss: 0.78457153
Epoch: [ 7] [ 185/ 202] time: 12839.1812, d_loss: 1.63768065, g_loss: 0.50344700
Epoch: [ 7] [ 186/ 202] time: 12847.0478, d_loss: 1.48449755, g_loss: 0.76014614
Epoch: [ 7] [ 187/ 202] time: 12855.0140, d_loss: 1.41820943, g_loss: 0.68348008
Epoch: [ 7] [ 188/ 202] time: 12862.9810, d_loss: 1.11576247, g_loss: 0.86118776
Epoch: [ 7] [ 189/ 202] time: 12870.8987, d_loss: 1.46452355, g_loss: 0.46350965
Epoch: [ 7] [ 190/ 202] time: 12878.7759, d_loss: 0.92425054, g_loss: 0.76863837
Epoch: [ 7] [ 191/ 202] time: 12886.7192, d_loss: 1.07073092, g_loss: 0.67856824
Epoch: [ 7] [ 192/ 202] time: 12894.6396, d_loss: 1.22550464, g_loss: 0.61035800
Epoch: [ 7] [ 193/ 202] time: 12902.6283, d_loss: 2.59081554, g_loss: 0.20475642
Epoch: [ 7] [ 194/ 202] time: 12910.7545, d_loss: 2.29091954, g_loss: 0.84335923
Epoch: [ 7] [ 195/ 202] time: 12918.8718, d_loss: 1.87400246, g_loss: 0.32753855
Epoch: [ 7] [ 196/ 202] time: 12926.9233, d_loss: 1.84688032, g_loss: 0.84384865
Epoch: [ 7] [ 197/ 202] time: 12934.8357, d_loss: 1.76688385, g_loss: 0.42174178
Epoch: [ 7] [ 198/ 202] time: 12942.7585, d_loss: 1.42741442, g_loss: 0.76475406
Epoch: [ 7] [ 199/ 202] time: 12950.7315, d_loss: 1.63345504, g_loss: 0.48855415
Epoch: [ 7] [ 200/ 202] time: 12958.6623, d_loss: 1.13095188, g_loss: 1.12183142
Epoch: [ 7] [ 201/ 202] time: 12966.6050, d_loss: 1.53961468, g_loss: 0.45217076
Epoch: [ 8] [   0/ 202] time: 12974.6400, d_loss: 1.44751632, g_loss: 0.68279487
Epoch: [ 8] [   1/ 202] time: 12982.6027, d_loss: 1.32496500, g_loss: 0.74231720
Epoch: [ 8] [   2/ 202] time: 12990.6202, d_loss: 1.91515720, g_loss: 0.23307855
Epoch: [ 8] [   3/ 202] time: 12998.5902, d_loss: 1.36380386, g_loss: 1.23582125
Epoch: [ 8] [   4/ 202] time: 13006.5219, d_loss: 1.39080644, g_loss: 0.57576668
Epoch: [ 8] [   5/ 202] time: 13014.5185, d_loss: 1.42949986, g_loss: 0.52012151
Epoch: [ 8] [   6/ 202] time: 13022.5681, d_loss: 1.15796566, g_loss: 0.87393177
Epoch: [ 8] [   7/ 202] time: 13030.4642, d_loss: 1.68213832, g_loss: 0.44265532
Epoch: [ 8] [   8/ 202] time: 13038.3850, d_loss: 1.38805437, g_loss: 0.92682225
Epoch: [ 8] [   9/ 202] time: 13046.3184, d_loss: 1.90672195, g_loss: 0.48790628
Epoch: [ 8] [  10/ 202] time: 13054.3340, d_loss: 1.60734308, g_loss: 0.59095657
Epoch: [ 8] [  11/ 202] time: 13062.2473, d_loss: 1.69365537, g_loss: 0.31698763
Epoch: [ 8] [  12/ 202] time: 13070.1611, d_loss: 1.35571325, g_loss: 0.87932467
Epoch: [ 8] [  13/ 202] time: 13078.1187, d_loss: 2.08918548, g_loss: 0.29449672
Epoch: [ 8] [  14/ 202] time: 13086.0321, d_loss: 1.84435415, g_loss: 0.51112771
Epoch: [ 8] [  15/ 202] time: 13093.9425, d_loss: 2.13661194, g_loss: 0.53464246
Epoch: [ 8] [  16/ 202] time: 13101.9342, d_loss: 1.77812648, g_loss: 0.61946845
Epoch: [ 8] [  17/ 202] time: 13109.9219, d_loss: 1.48673534, g_loss: 0.42068243
Epoch: [ 8] [  18/ 202] time: 13118.1588, d_loss: 1.79521251, g_loss: 0.46139085
Epoch: [ 8] [  19/ 202] time: 13126.2153, d_loss: 1.78928185, g_loss: 0.31553286
Epoch: [ 8] [  20/ 202] time: 13134.1291, d_loss: 2.35207272, g_loss: 0.24138248
Epoch: [ 8] [  21/ 202] time: 13142.2167, d_loss: 2.05185127, g_loss: 0.47491932
Epoch: [ 8] [  22/ 202] time: 13150.1886, d_loss: 1.40009737, g_loss: 0.65833437
Epoch: [ 8] [  23/ 202] time: 13158.1293, d_loss: 1.30017805, g_loss: 0.64374328
Epoch: [ 8] [  24/ 202] time: 13166.0820, d_loss: 2.65872622, g_loss: 0.15739810
Epoch: [ 8] [  25/ 202] time: 13174.1324, d_loss: 2.12203169, g_loss: 1.13383436
Epoch: [ 8] [  26/ 202] time: 13182.0324, d_loss: 2.48539495, g_loss: 0.25307250
Epoch: [ 8] [  27/ 202] time: 13189.9514, d_loss: 2.53179312, g_loss: 0.51345599
Epoch: [ 8] [  28/ 202] time: 13197.8924, d_loss: 1.39379048, g_loss: 1.64761353
Epoch: [ 8] [  29/ 202] time: 13205.9495, d_loss: 1.24242616, g_loss: 0.53703666
Epoch: [ 8] [  30/ 202] time: 13214.0658, d_loss: 1.75033939, g_loss: 0.46821821
Epoch: [ 8] [  31/ 202] time: 13222.0136, d_loss: 1.37689579, g_loss: 1.00242913
Epoch: [ 8] [  32/ 202] time: 13229.9396, d_loss: 1.93823481, g_loss: 0.40027851
Epoch: [ 8] [  33/ 202] time: 13237.8891, d_loss: 2.17909765, g_loss: 0.30462110
Epoch: [ 8] [  34/ 202] time: 13245.8952, d_loss: 1.40839171, g_loss: 0.61873150
Epoch: [ 8] [  35/ 202] time: 13253.7836, d_loss: 1.44139218, g_loss: 0.57540178
Epoch: [ 8] [  36/ 202] time: 13261.7167, d_loss: 1.44783258, g_loss: 0.46219048
Epoch: [ 8] [  37/ 202] time: 13269.6882, d_loss: 1.00019979, g_loss: 1.17936265
Epoch: [ 8] [  38/ 202] time: 13277.6923, d_loss: 1.56555724, g_loss: 0.38535574
Epoch: [ 8] [  39/ 202] time: 13285.6848, d_loss: 1.16495705, g_loss: 0.91987586
Epoch: [ 8] [  40/ 202] time: 13293.6844, d_loss: 1.14423084, g_loss: 0.94056833
Epoch: [ 8] [  41/ 202] time: 13301.6251, d_loss: 1.62731445, g_loss: 0.38255265
Epoch: [ 8] [  42/ 202] time: 13309.6678, d_loss: 1.23012948, g_loss: 0.91669387
Epoch: [ 8] [  43/ 202] time: 13317.5771, d_loss: 1.87516832, g_loss: 0.57903135
Epoch: [ 8] [  44/ 202] time: 13325.5711, d_loss: 1.80342472, g_loss: 0.38963246
Epoch: [ 8] [  45/ 202] time: 13333.5885, d_loss: 1.77990234, g_loss: 0.27043405
Epoch: [ 8] [  46/ 202] time: 13341.7152, d_loss: 0.88927084, g_loss: 0.94147646
Epoch: [ 8] [  47/ 202] time: 13349.6371, d_loss: 0.93944132, g_loss: 0.84889102
Epoch: [ 8] [  48/ 202] time: 13357.5832, d_loss: 1.06868637, g_loss: 0.85906255
Epoch: [ 8] [  49/ 202] time: 13365.5547, d_loss: 1.05053890, g_loss: 0.88850951
Epoch: [ 8] [  50/ 202] time: 13373.4649, d_loss: 1.91120028, g_loss: 0.31873226
Epoch: [ 8] [  51/ 202] time: 13381.3656, d_loss: 1.64229488, g_loss: 0.51765627
Epoch: [ 8] [  52/ 202] time: 13389.3327, d_loss: 2.08543348, g_loss: 0.40191329
Epoch: [ 8] [  53/ 202] time: 13397.2948, d_loss: 1.53176045, g_loss: 1.03790998
Epoch: [ 8] [  54/ 202] time: 13405.3106, d_loss: 1.79482388, g_loss: 0.33316904
Epoch: [ 8] [  55/ 202] time: 13413.2751, d_loss: 1.86718333, g_loss: 0.51709223
Epoch: [ 8] [  56/ 202] time: 13421.2101, d_loss: 1.59202945, g_loss: 0.55949998
Epoch: [ 8] [  57/ 202] time: 13429.2580, d_loss: 1.60910630, g_loss: 0.56343323
Epoch: [ 8] [  58/ 202] time: 13437.2682, d_loss: 1.21443200, g_loss: 0.76927376
Epoch: [ 8] [  59/ 202] time: 13445.2096, d_loss: 1.49278975, g_loss: 0.59835160
Epoch: [ 8] [  60/ 202] time: 13453.1369, d_loss: 1.82946694, g_loss: 0.33361322
Epoch: [ 8] [  61/ 202] time: 13461.1686, d_loss: 2.25019979, g_loss: 0.64676446
Epoch: [ 8] [  62/ 202] time: 13469.1122, d_loss: 2.89910460, g_loss: 0.26611978
Epoch: [ 8] [  63/ 202] time: 13477.0055, d_loss: 1.85350013, g_loss: 0.42467356
Epoch: [ 8] [  64/ 202] time: 13484.9682, d_loss: 1.83366847, g_loss: 0.58880925
Epoch: [ 8] [  65/ 202] time: 13492.9551, d_loss: 1.37525201, g_loss: 0.78908098
Epoch: [ 8] [  66/ 202] time: 13500.8717, d_loss: 1.72517192, g_loss: 0.51067203
Epoch: [ 8] [  67/ 202] time: 13508.8534, d_loss: 1.47495866, g_loss: 0.81586087
Epoch: [ 8] [  68/ 202] time: 13516.8563, d_loss: 1.26327133, g_loss: 0.76531810
Epoch: [ 8] [  69/ 202] time: 13524.8716, d_loss: 2.84755754, g_loss: 0.21948206
Epoch: [ 8] [  70/ 202] time: 13532.8959, d_loss: 2.72977018, g_loss: 0.34654337
Epoch: [ 8] [  71/ 202] time: 13540.7605, d_loss: 2.31647635, g_loss: 0.83319902
Epoch: [ 8] [  72/ 202] time: 13548.7161, d_loss: 2.70743132, g_loss: 0.38956714
Epoch: [ 8] [  73/ 202] time: 13556.6808, d_loss: 2.07572317, g_loss: 0.34671259
Epoch: [ 8] [  74/ 202] time: 13564.5594, d_loss: 2.28249693, g_loss: 0.59106630
Epoch: [ 8] [  75/ 202] time: 13572.4893, d_loss: 1.67743921, g_loss: 0.65197355
Epoch: [ 8] [  76/ 202] time: 13580.4192, d_loss: 2.12773466, g_loss: 0.47864658
Epoch: [ 8] [  77/ 202] time: 13588.3755, d_loss: 1.15664899, g_loss: 0.74922669
Epoch: [ 8] [  78/ 202] time: 13596.3667, d_loss: 1.12878501, g_loss: 1.14791214
Epoch: [ 8] [  79/ 202] time: 13604.2949, d_loss: 1.30588889, g_loss: 0.57730830
Epoch: [ 8] [  80/ 202] time: 13612.1455, d_loss: 1.22810769, g_loss: 0.57529747
Epoch: [ 8] [  81/ 202] time: 13620.0601, d_loss: 1.53786683, g_loss: 0.74790817
Epoch: [ 8] [  82/ 202] time: 13627.9808, d_loss: 1.53952098, g_loss: 0.59027553
[Sample] d_loss: 1.16228330, g_loss: 0.89826179
Epoch: [ 8] [  83/ 202] time: 13637.6733, d_loss: 1.33538318, g_loss: 0.59785873
Epoch: [ 8] [  84/ 202] time: 13645.6068, d_loss: 1.18266106, g_loss: 0.84576845
Epoch: [ 8] [  85/ 202] time: 13653.4724, d_loss: 1.72000217, g_loss: 0.36113673
Epoch: [ 8] [  86/ 202] time: 13661.3460, d_loss: 1.31647646, g_loss: 0.89822316
Epoch: [ 8] [  87/ 202] time: 13669.2838, d_loss: 1.70670736, g_loss: 0.45623186
Epoch: [ 8] [  88/ 202] time: 13677.3772, d_loss: 1.57958615, g_loss: 0.46589917
Epoch: [ 8] [  89/ 202] time: 13685.3070, d_loss: 1.31111956, g_loss: 1.02093172
Epoch: [ 8] [  90/ 202] time: 13693.1946, d_loss: 1.76607406, g_loss: 0.27669245
Epoch: [ 8] [  91/ 202] time: 13701.1134, d_loss: 1.39676809, g_loss: 1.00411642
Epoch: [ 8] [  92/ 202] time: 13709.0850, d_loss: 1.39375949, g_loss: 0.68683076
Epoch: [ 8] [  93/ 202] time: 13716.9736, d_loss: 1.34589911, g_loss: 0.59985638
Epoch: [ 8] [  94/ 202] time: 13724.8532, d_loss: 1.66025758, g_loss: 0.53260344
Epoch: [ 8] [  95/ 202] time: 13732.7474, d_loss: 1.82264721, g_loss: 0.56336892
Epoch: [ 8] [  96/ 202] time: 13740.7429, d_loss: 1.40038252, g_loss: 0.76713216
Epoch: [ 8] [  97/ 202] time: 13748.6357, d_loss: 1.48268402, g_loss: 0.49544853
Epoch: [ 8] [  98/ 202] time: 13756.5379, d_loss: 1.36154473, g_loss: 0.67026401
Epoch: [ 8] [  99/ 202] time: 13764.4385, d_loss: 1.16906810, g_loss: 0.76499939
Epoch: [ 8] [ 100/ 202] time: 13772.3595, d_loss: 1.28492641, g_loss: 0.61466175
Epoch: [ 8] [ 101/ 202] time: 13780.3173, d_loss: 1.26320302, g_loss: 0.76683050
Epoch: [ 8] [ 102/ 202] time: 13788.1844, d_loss: 1.08165574, g_loss: 0.89945960
Epoch: [ 8] [ 103/ 202] time: 13796.1309, d_loss: 1.27192867, g_loss: 0.50780952
Epoch: [ 8] [ 104/ 202] time: 13804.0334, d_loss: 1.21470118, g_loss: 0.83606207
Epoch: [ 8] [ 105/ 202] time: 13811.9487, d_loss: 1.60129929, g_loss: 0.48945707
Epoch: [ 8] [ 106/ 202] time: 13819.8228, d_loss: 1.58516097, g_loss: 0.52985179
Epoch: [ 8] [ 107/ 202] time: 13827.7297, d_loss: 1.53933764, g_loss: 0.62755483
Epoch: [ 8] [ 108/ 202] time: 13835.6117, d_loss: 1.61110997, g_loss: 0.63857168
Epoch: [ 8] [ 109/ 202] time: 13843.5455, d_loss: 1.96862853, g_loss: 0.28711313
Epoch: [ 8] [ 110/ 202] time: 13851.4583, d_loss: 1.39764547, g_loss: 0.83880240
Epoch: [ 8] [ 111/ 202] time: 13859.3751, d_loss: 1.58100522, g_loss: 0.51031971
Epoch: [ 8] [ 112/ 202] time: 13867.2874, d_loss: 1.27475595, g_loss: 0.67592013
Epoch: [ 8] [ 113/ 202] time: 13875.2303, d_loss: 1.69556546, g_loss: 0.33101612
Epoch: [ 8] [ 114/ 202] time: 13883.0953, d_loss: 1.24685097, g_loss: 1.10630226
Epoch: [ 8] [ 115/ 202] time: 13891.0179, d_loss: 1.31662583, g_loss: 0.63644850
Epoch: [ 8] [ 116/ 202] time: 13898.9261, d_loss: 1.61054647, g_loss: 0.55005431
Epoch: [ 8] [ 117/ 202] time: 13906.8898, d_loss: 1.73473573, g_loss: 0.39126265
Epoch: [ 8] [ 118/ 202] time: 13914.8475, d_loss: 1.04222000, g_loss: 0.96769333
Epoch: [ 8] [ 119/ 202] time: 13922.8289, d_loss: 1.54359245, g_loss: 0.44437268
Epoch: [ 8] [ 120/ 202] time: 13930.8220, d_loss: 1.42689252, g_loss: 0.48541802
Epoch: [ 8] [ 121/ 202] time: 13938.7011, d_loss: 1.83864486, g_loss: 0.66408288
Epoch: [ 8] [ 122/ 202] time: 13946.6493, d_loss: 1.94989371, g_loss: 0.38273001
Epoch: [ 8] [ 123/ 202] time: 13954.5496, d_loss: 1.60083807, g_loss: 0.72455382
Epoch: [ 8] [ 124/ 202] time: 13962.4482, d_loss: 1.37400055, g_loss: 0.72649229
Epoch: [ 8] [ 125/ 202] time: 13970.4438, d_loss: 1.50956821, g_loss: 0.55045420
Epoch: [ 8] [ 126/ 202] time: 13978.3671, d_loss: 1.37604284, g_loss: 0.49173516
Epoch: [ 8] [ 127/ 202] time: 13986.3114, d_loss: 1.29921412, g_loss: 0.75011039
Epoch: [ 8] [ 128/ 202] time: 13994.1458, d_loss: 1.30581856, g_loss: 0.66701305
Epoch: [ 8] [ 129/ 202] time: 14002.1088, d_loss: 1.48100865, g_loss: 0.58861339
Epoch: [ 8] [ 130/ 202] time: 14010.0077, d_loss: 1.57930374, g_loss: 0.52102524
Epoch: [ 8] [ 131/ 202] time: 14017.9267, d_loss: 1.55792618, g_loss: 0.83069885
Epoch: [ 8] [ 132/ 202] time: 14025.8483, d_loss: 1.93124235, g_loss: 0.29978991
Epoch: [ 8] [ 133/ 202] time: 14033.7890, d_loss: 1.01495051, g_loss: 0.81589359
Epoch: [ 8] [ 134/ 202] time: 14041.7034, d_loss: 1.12581587, g_loss: 0.73926908
Epoch: [ 8] [ 135/ 202] time: 14049.6604, d_loss: 1.46502018, g_loss: 0.53832614
Epoch: [ 8] [ 136/ 202] time: 14057.5351, d_loss: 1.76221275, g_loss: 0.47969252
Epoch: [ 8] [ 137/ 202] time: 14065.4944, d_loss: 1.92929769, g_loss: 0.43185818
Epoch: [ 8] [ 138/ 202] time: 14073.3519, d_loss: 1.61149085, g_loss: 0.49636048
Epoch: [ 8] [ 139/ 202] time: 14081.2090, d_loss: 1.13579619, g_loss: 1.21712613
Epoch: [ 8] [ 140/ 202] time: 14089.1236, d_loss: 1.55799568, g_loss: 0.46427864
Epoch: [ 8] [ 141/ 202] time: 14097.1088, d_loss: 2.03706384, g_loss: 0.21668103
Epoch: [ 8] [ 142/ 202] time: 14104.9795, d_loss: 1.33395791, g_loss: 0.98133528
Epoch: [ 8] [ 143/ 202] time: 14112.9004, d_loss: 1.83181405, g_loss: 0.47757471
Epoch: [ 8] [ 144/ 202] time: 14120.8331, d_loss: 1.65283310, g_loss: 0.50946826
Epoch: [ 8] [ 145/ 202] time: 14128.7771, d_loss: 1.32262838, g_loss: 0.75927055
Epoch: [ 8] [ 146/ 202] time: 14136.6710, d_loss: 1.69367826, g_loss: 0.39327687
Epoch: [ 8] [ 147/ 202] time: 14144.6172, d_loss: 1.39184594, g_loss: 0.79703379
Epoch: [ 8] [ 148/ 202] time: 14152.5369, d_loss: 1.87377310, g_loss: 0.32331818
Epoch: [ 8] [ 149/ 202] time: 14160.5217, d_loss: 1.40224171, g_loss: 0.81261104
Epoch: [ 8] [ 150/ 202] time: 14168.4135, d_loss: 1.48534513, g_loss: 0.43096697
Epoch: [ 8] [ 151/ 202] time: 14176.3494, d_loss: 1.99249649, g_loss: 0.33993012
Epoch: [ 8] [ 152/ 202] time: 14184.2964, d_loss: 1.50806379, g_loss: 0.97498232
Epoch: [ 8] [ 153/ 202] time: 14192.2624, d_loss: 1.93520617, g_loss: 0.39552271
Epoch: [ 8] [ 154/ 202] time: 14200.1732, d_loss: 1.20721209, g_loss: 0.61643910
Epoch: [ 8] [ 155/ 202] time: 14208.0603, d_loss: 1.42177415, g_loss: 0.59723550
Epoch: [ 8] [ 156/ 202] time: 14216.0012, d_loss: 1.42602062, g_loss: 0.59167957
Epoch: [ 8] [ 157/ 202] time: 14223.8917, d_loss: 1.51353168, g_loss: 0.72759128
Epoch: [ 8] [ 158/ 202] time: 14231.8321, d_loss: 1.88922012, g_loss: 0.35890210
Epoch: [ 8] [ 159/ 202] time: 14239.7529, d_loss: 1.37255335, g_loss: 0.67508268
Epoch: [ 8] [ 160/ 202] time: 14247.7166, d_loss: 1.38351691, g_loss: 0.70761275
Epoch: [ 8] [ 161/ 202] time: 14255.6506, d_loss: 1.33778799, g_loss: 0.62349892
Epoch: [ 8] [ 162/ 202] time: 14263.5234, d_loss: 1.18520963, g_loss: 0.75536895
Epoch: [ 8] [ 163/ 202] time: 14271.4130, d_loss: 1.57294536, g_loss: 0.52628446
Epoch: [ 8] [ 164/ 202] time: 14279.2812, d_loss: 1.43205833, g_loss: 0.76533616
Epoch: [ 8] [ 165/ 202] time: 14287.1954, d_loss: 1.41225362, g_loss: 0.49404916
Epoch: [ 8] [ 166/ 202] time: 14295.0880, d_loss: 1.76128602, g_loss: 0.35002786
Epoch: [ 8] [ 167/ 202] time: 14302.9972, d_loss: 1.73073065, g_loss: 1.34016073
Epoch: [ 8] [ 168/ 202] time: 14310.9842, d_loss: 1.90037930, g_loss: 0.41311455
Epoch: [ 8] [ 169/ 202] time: 14318.9476, d_loss: 1.88273132, g_loss: 0.36237663
Epoch: [ 8] [ 170/ 202] time: 14326.8376, d_loss: 1.49822760, g_loss: 0.79852551
Epoch: [ 8] [ 171/ 202] time: 14334.7521, d_loss: 1.43505466, g_loss: 0.40786889
Epoch: [ 8] [ 172/ 202] time: 14342.6733, d_loss: 1.36019480, g_loss: 0.56509095
Epoch: [ 8] [ 173/ 202] time: 14350.5453, d_loss: 1.39608872, g_loss: 0.62278861
Epoch: [ 8] [ 174/ 202] time: 14358.4669, d_loss: 1.79280531, g_loss: 0.43121040
Epoch: [ 8] [ 175/ 202] time: 14366.3861, d_loss: 1.35280848, g_loss: 1.05114114
Epoch: [ 8] [ 176/ 202] time: 14374.3410, d_loss: 1.35310018, g_loss: 0.70392954
Epoch: [ 8] [ 177/ 202] time: 14382.3471, d_loss: 1.19933486, g_loss: 0.46260616
Epoch: [ 8] [ 178/ 202] time: 14390.2813, d_loss: 1.06962681, g_loss: 1.17005515
Epoch: [ 8] [ 179/ 202] time: 14398.1751, d_loss: 1.70669913, g_loss: 0.36882162
Epoch: [ 8] [ 180/ 202] time: 14406.0741, d_loss: 1.78064251, g_loss: 0.37606248
Epoch: [ 8] [ 181/ 202] time: 14413.9859, d_loss: 1.21243989, g_loss: 1.37199545
Epoch: [ 8] [ 182/ 202] time: 14421.8516, d_loss: 1.66607022, g_loss: 0.41070697
[Sample] d_loss: 1.26659954, g_loss: 0.60516703
Epoch: [ 8] [ 183/ 202] time: 14431.5732, d_loss: 2.51958179, g_loss: 0.15816393
Epoch: [ 8] [ 184/ 202] time: 14439.5379, d_loss: 2.02519178, g_loss: 0.77578890
Epoch: [ 8] [ 185/ 202] time: 14447.4056, d_loss: 2.10016346, g_loss: 0.38436624
Epoch: [ 8] [ 186/ 202] time: 14455.2785, d_loss: 1.76705205, g_loss: 0.46253139
Epoch: [ 8] [ 187/ 202] time: 14463.2014, d_loss: 1.75466824, g_loss: 0.58460081
Epoch: [ 8] [ 188/ 202] time: 14471.1650, d_loss: 1.33343673, g_loss: 0.77811414
Epoch: [ 8] [ 189/ 202] time: 14479.0139, d_loss: 1.93099713, g_loss: 0.37028927
Epoch: [ 8] [ 190/ 202] time: 14486.9185, d_loss: 1.66027761, g_loss: 0.66981179
Epoch: [ 8] [ 191/ 202] time: 14494.8789, d_loss: 1.24798286, g_loss: 0.79168952
Epoch: [ 8] [ 192/ 202] time: 14502.7623, d_loss: 1.52425468, g_loss: 0.46608156
Epoch: [ 8] [ 193/ 202] time: 14510.6442, d_loss: 1.37327802, g_loss: 0.46490002
Epoch: [ 8] [ 194/ 202] time: 14518.5030, d_loss: 1.42796755, g_loss: 1.06144392
Epoch: [ 8] [ 195/ 202] time: 14526.4743, d_loss: 1.25244248, g_loss: 0.85080987
Epoch: [ 8] [ 196/ 202] time: 14534.3506, d_loss: 2.15199184, g_loss: 0.33178884
Epoch: [ 8] [ 197/ 202] time: 14542.2616, d_loss: 1.94989491, g_loss: 0.69720697
Epoch: [ 8] [ 198/ 202] time: 14550.1949, d_loss: 1.57837415, g_loss: 0.56861186
Epoch: [ 8] [ 199/ 202] time: 14558.1592, d_loss: 1.50081444, g_loss: 0.48152894
Epoch: [ 8] [ 200/ 202] time: 14566.1446, d_loss: 1.38821387, g_loss: 0.89115870
Epoch: [ 8] [ 201/ 202] time: 14573.9798, d_loss: 1.48983622, g_loss: 0.40725297
Epoch: [ 9] [   0/ 202] time: 14582.0128, d_loss: 1.59566128, g_loss: 0.53766882
Epoch: [ 9] [   1/ 202] time: 14589.9539, d_loss: 2.20021057, g_loss: 0.42640567
Epoch: [ 9] [   2/ 202] time: 14597.8731, d_loss: 1.47477734, g_loss: 0.46560603
Epoch: [ 9] [   3/ 202] time: 14605.7562, d_loss: 1.32319403, g_loss: 0.68617666
Epoch: [ 9] [   4/ 202] time: 14613.6580, d_loss: 1.42945409, g_loss: 0.49258441
Epoch: [ 9] [   5/ 202] time: 14621.5727, d_loss: 1.67935038, g_loss: 0.65901405
Epoch: [ 9] [   6/ 202] time: 14629.5169, d_loss: 1.39535260, g_loss: 0.79030418
Epoch: [ 9] [   7/ 202] time: 14637.3670, d_loss: 1.59135437, g_loss: 0.38587618
Epoch: [ 9] [   8/ 202] time: 14645.2755, d_loss: 0.85893452, g_loss: 1.28732729
Epoch: [ 9] [   9/ 202] time: 14653.1713, d_loss: 1.63399935, g_loss: 0.56576222
Epoch: [ 9] [  10/ 202] time: 14661.1646, d_loss: 1.51010776, g_loss: 0.42826939
Epoch: [ 9] [  11/ 202] time: 14669.0799, d_loss: 1.79840386, g_loss: 0.45278287
Epoch: [ 9] [  12/ 202] time: 14676.9509, d_loss: 1.46454704, g_loss: 0.60651577
Epoch: [ 9] [  13/ 202] time: 14684.8495, d_loss: 1.79668736, g_loss: 0.32931757
Epoch: [ 9] [  14/ 202] time: 14692.7456, d_loss: 1.74304998, g_loss: 0.54105031
Epoch: [ 9] [  15/ 202] time: 14700.6832, d_loss: 1.63532686, g_loss: 0.85698628
Epoch: [ 9] [  16/ 202] time: 14708.5580, d_loss: 1.57068801, g_loss: 0.60305309
Epoch: [ 9] [  17/ 202] time: 14716.4604, d_loss: 1.03602588, g_loss: 0.80641633
Epoch: [ 9] [  18/ 202] time: 14724.3643, d_loss: 1.82722926, g_loss: 0.39591885
Epoch: [ 9] [  19/ 202] time: 14732.2612, d_loss: 1.33538556, g_loss: 0.52955282
Epoch: [ 9] [  20/ 202] time: 14740.1770, d_loss: 1.87359834, g_loss: 0.40963668
Epoch: [ 9] [  21/ 202] time: 14748.1444, d_loss: 1.41158986, g_loss: 0.54334497
Epoch: [ 9] [  22/ 202] time: 14756.0465, d_loss: 1.30364704, g_loss: 0.68137622
Epoch: [ 9] [  23/ 202] time: 14763.9616, d_loss: 2.03088784, g_loss: 0.37812620
Epoch: [ 9] [  24/ 202] time: 14771.8920, d_loss: 3.35087204, g_loss: 0.15877764
Epoch: [ 9] [  25/ 202] time: 14779.8561, d_loss: 2.37001300, g_loss: 1.68734264
Epoch: [ 9] [  26/ 202] time: 14787.8083, d_loss: 2.20055485, g_loss: 0.18476447
Epoch: [ 9] [  27/ 202] time: 14795.6821, d_loss: 1.56672215, g_loss: 0.57725561
Epoch: [ 9] [  28/ 202] time: 14803.5775, d_loss: 1.08060384, g_loss: 1.13876939
Epoch: [ 9] [  29/ 202] time: 14811.4963, d_loss: 1.38491678, g_loss: 0.56275010
Epoch: [ 9] [  30/ 202] time: 14819.4129, d_loss: 1.89610028, g_loss: 0.43214664
Epoch: [ 9] [  31/ 202] time: 14827.3081, d_loss: 1.54032719, g_loss: 1.27043152
Epoch: [ 9] [  32/ 202] time: 14835.1874, d_loss: 1.98246956, g_loss: 0.33769929
Epoch: [ 9] [  33/ 202] time: 14843.1172, d_loss: 2.27136040, g_loss: 0.30875275
Epoch: [ 9] [  34/ 202] time: 14851.0382, d_loss: 1.37870741, g_loss: 1.07914007
Epoch: [ 9] [  35/ 202] time: 14858.9535, d_loss: 1.38779938, g_loss: 0.56116426
Epoch: [ 9] [  36/ 202] time: 14866.8928, d_loss: 1.27473223, g_loss: 0.57995224
Epoch: [ 9] [  37/ 202] time: 14874.9662, d_loss: 1.37345147, g_loss: 0.74384654
Epoch: [ 9] [  38/ 202] time: 14882.8657, d_loss: 1.77043390, g_loss: 0.32212648
Epoch: [ 9] [  39/ 202] time: 14890.7497, d_loss: 1.35192251, g_loss: 0.85912251
Epoch: [ 9] [  40/ 202] time: 14898.6406, d_loss: 2.08592939, g_loss: 0.34529144
Epoch: [ 9] [  41/ 202] time: 14906.6370, d_loss: 2.05621624, g_loss: 0.31967384
Epoch: [ 9] [  42/ 202] time: 14914.5391, d_loss: 1.66731513, g_loss: 0.67289257
Epoch: [ 9] [  43/ 202] time: 14922.4467, d_loss: 1.62748146, g_loss: 0.50623631
Epoch: [ 9] [  44/ 202] time: 14930.3358, d_loss: 1.96035707, g_loss: 0.31513375
Epoch: [ 9] [  45/ 202] time: 14938.2129, d_loss: 1.79661977, g_loss: 0.38454258
Epoch: [ 9] [  46/ 202] time: 14946.1447, d_loss: 1.40692472, g_loss: 0.70154357
Epoch: [ 9] [  47/ 202] time: 14954.0699, d_loss: 1.79563498, g_loss: 0.34768686
Epoch: [ 9] [  48/ 202] time: 14961.9323, d_loss: 2.04203701, g_loss: 0.36655176
Epoch: [ 9] [  49/ 202] time: 14969.8636, d_loss: 2.17612386, g_loss: 0.33708531
Epoch: [ 9] [  50/ 202] time: 14977.7383, d_loss: 1.74753129, g_loss: 0.48121765
Epoch: [ 9] [  51/ 202] time: 14985.6581, d_loss: 1.48032784, g_loss: 0.59421527
Epoch: [ 9] [  52/ 202] time: 14993.5711, d_loss: 1.52557087, g_loss: 0.68728828
Epoch: [ 9] [  53/ 202] time: 15001.5227, d_loss: 1.42162037, g_loss: 0.92008638
Epoch: [ 9] [  54/ 202] time: 15009.4385, d_loss: 2.12500191, g_loss: 0.37232882
Epoch: [ 9] [  55/ 202] time: 15017.3559, d_loss: 1.85195112, g_loss: 0.60375535
Epoch: [ 9] [  56/ 202] time: 15025.2407, d_loss: 1.89232373, g_loss: 0.61970395
Epoch: [ 9] [  57/ 202] time: 15033.2107, d_loss: 1.63863242, g_loss: 0.42559770
Epoch: [ 9] [  58/ 202] time: 15041.1292, d_loss: 1.19858551, g_loss: 0.69934219
Epoch: [ 9] [  59/ 202] time: 15049.0311, d_loss: 1.41684270, g_loss: 0.76430118
Epoch: [ 9] [  60/ 202] time: 15056.9594, d_loss: 1.74644375, g_loss: 0.31221473
Epoch: [ 9] [  61/ 202] time: 15064.9144, d_loss: 1.86339664, g_loss: 0.51433504
Epoch: [ 9] [  62/ 202] time: 15072.8268, d_loss: 1.83465600, g_loss: 0.42435578
Epoch: [ 9] [  63/ 202] time: 15080.7267, d_loss: 1.81471050, g_loss: 0.30782300
Epoch: [ 9] [  64/ 202] time: 15088.5786, d_loss: 1.76127064, g_loss: 1.09123790
Epoch: [ 9] [  65/ 202] time: 15096.5323, d_loss: 2.31205320, g_loss: 0.18223792
Epoch: [ 9] [  66/ 202] time: 15104.5031, d_loss: 1.87258601, g_loss: 0.46855530
Epoch: [ 9] [  67/ 202] time: 15112.4015, d_loss: 1.38671935, g_loss: 0.86927748
Epoch: [ 9] [  68/ 202] time: 15120.3191, d_loss: 1.48616123, g_loss: 0.50647151
Epoch: [ 9] [  69/ 202] time: 15128.2193, d_loss: 1.88352907, g_loss: 0.34056330
Epoch: [ 9] [  70/ 202] time: 15136.1256, d_loss: 1.88339448, g_loss: 0.61175495
Epoch: [ 9] [  71/ 202] time: 15144.0099, d_loss: 1.69800520, g_loss: 0.48603296
Epoch: [ 9] [  72/ 202] time: 15151.9586, d_loss: 1.65250456, g_loss: 0.46344280
Epoch: [ 9] [  73/ 202] time: 15159.9024, d_loss: 1.29001832, g_loss: 0.82520759
Epoch: [ 9] [  74/ 202] time: 15167.8002, d_loss: 1.40143406, g_loss: 0.43587002
Epoch: [ 9] [  75/ 202] time: 15175.7120, d_loss: 1.24367011, g_loss: 0.89774215
Epoch: [ 9] [  76/ 202] time: 15183.6284, d_loss: 1.52209592, g_loss: 0.61326218
Epoch: [ 9] [  77/ 202] time: 15191.5302, d_loss: 1.30625451, g_loss: 0.54732120
Epoch: [ 9] [  78/ 202] time: 15199.4669, d_loss: 1.68212080, g_loss: 0.51118863
Epoch: [ 9] [  79/ 202] time: 15207.4019, d_loss: 1.78031242, g_loss: 0.58226001
Epoch: [ 9] [  80/ 202] time: 15215.3119, d_loss: 1.75862217, g_loss: 0.54190683
[Sample] d_loss: 1.27140069, g_loss: 0.96544850
Epoch: [ 9] [  81/ 202] time: 15224.9928, d_loss: 1.98083413, g_loss: 0.32379708
Epoch: [ 9] [  82/ 202] time: 15232.8989, d_loss: 1.71079159, g_loss: 0.50780368
Epoch: [ 9] [  83/ 202] time: 15240.8290, d_loss: 2.22565842, g_loss: 0.34972817
Epoch: [ 9] [  84/ 202] time: 15248.7475, d_loss: 1.77913761, g_loss: 0.64920986
Epoch: [ 9] [  85/ 202] time: 15256.7058, d_loss: 1.54171610, g_loss: 0.52239805
Epoch: [ 9] [  86/ 202] time: 15264.5736, d_loss: 1.50640333, g_loss: 0.73909974
Epoch: [ 9] [  87/ 202] time: 15272.4449, d_loss: 1.53845108, g_loss: 0.65492702
Epoch: [ 9] [  88/ 202] time: 15280.3829, d_loss: 1.38057077, g_loss: 0.47538200
Epoch: [ 9] [  89/ 202] time: 15288.2857, d_loss: 1.27264380, g_loss: 0.78805113
Epoch: [ 9] [  90/ 202] time: 15296.2670, d_loss: 1.46117330, g_loss: 0.50674397
Epoch: [ 9] [  91/ 202] time: 15304.2013, d_loss: 1.26944590, g_loss: 0.73696828
Epoch: [ 9] [  92/ 202] time: 15312.0992, d_loss: 1.36414790, g_loss: 0.65360779
Epoch: [ 9] [  93/ 202] time: 15320.1018, d_loss: 1.18107212, g_loss: 0.63204503
Epoch: [ 9] [  94/ 202] time: 15327.9462, d_loss: 1.26278102, g_loss: 0.67665577
Epoch: [ 9] [  95/ 202] time: 15335.8318, d_loss: 1.63715661, g_loss: 0.51540124
Epoch: [ 9] [  96/ 202] time: 15343.6994, d_loss: 1.17272282, g_loss: 1.01850700
Epoch: [ 9] [  97/ 202] time: 15351.6009, d_loss: 1.96269321, g_loss: 0.36038947
Epoch: [ 9] [  98/ 202] time: 15359.5018, d_loss: 1.67436969, g_loss: 0.51601726
Epoch: [ 9] [  99/ 202] time: 15367.4156, d_loss: 1.76484334, g_loss: 0.69247532
Epoch: [ 9] [ 100/ 202] time: 15375.3113, d_loss: 1.95548439, g_loss: 0.32254672
Epoch: [ 9] [ 101/ 202] time: 15383.2001, d_loss: 1.65021586, g_loss: 0.60793769
Epoch: [ 9] [ 102/ 202] time: 15391.1292, d_loss: 1.29033387, g_loss: 0.74852204
Epoch: [ 9] [ 103/ 202] time: 15399.0334, d_loss: 1.14264619, g_loss: 0.64480817
Epoch: [ 9] [ 104/ 202] time: 15406.9513, d_loss: 2.00757504, g_loss: 0.33655319
Epoch: [ 9] [ 105/ 202] time: 15414.9066, d_loss: 1.80012310, g_loss: 0.56574404
Epoch: [ 9] [ 106/ 202] time: 15422.8494, d_loss: 1.55709553, g_loss: 0.95492953
Epoch: [ 9] [ 107/ 202] time: 15430.7712, d_loss: 1.25534534, g_loss: 0.79808152
Epoch: [ 9] [ 108/ 202] time: 15438.7038, d_loss: 1.47707510, g_loss: 0.63311690
Epoch: [ 9] [ 109/ 202] time: 15446.5575, d_loss: 1.85528207, g_loss: 0.33496696
Epoch: [ 9] [ 110/ 202] time: 15454.4725, d_loss: 1.39334667, g_loss: 0.95446569
Epoch: [ 9] [ 111/ 202] time: 15462.4682, d_loss: 1.98644686, g_loss: 0.35358232
Epoch: [ 9] [ 112/ 202] time: 15470.3856, d_loss: 1.25854516, g_loss: 1.13715589
Epoch: [ 9] [ 113/ 202] time: 15478.3415, d_loss: 2.09146905, g_loss: 0.30996627
Epoch: [ 9] [ 114/ 202] time: 15486.2028, d_loss: 2.17298198, g_loss: 0.46526140
Epoch: [ 9] [ 115/ 202] time: 15494.1647, d_loss: 2.26357985, g_loss: 0.48874015
Epoch: [ 9] [ 116/ 202] time: 15502.0870, d_loss: 2.02154779, g_loss: 0.53320909
Epoch: [ 9] [ 117/ 202] time: 15510.0408, d_loss: 1.87161279, g_loss: 0.43878126
Epoch: [ 9] [ 118/ 202] time: 15518.0177, d_loss: 1.25891817, g_loss: 0.63986683
Epoch: [ 9] [ 119/ 202] time: 15525.9181, d_loss: 1.00103796, g_loss: 1.03673029
Epoch: [ 9] [ 120/ 202] time: 15533.8462, d_loss: 1.64000928, g_loss: 0.39333147
Epoch: [ 9] [ 121/ 202] time: 15541.7646, d_loss: 1.84549141, g_loss: 0.46002215
Epoch: [ 9] [ 122/ 202] time: 15549.6603, d_loss: 1.60253286, g_loss: 0.62615150
Epoch: [ 9] [ 123/ 202] time: 15557.6320, d_loss: 1.59427726, g_loss: 0.79983425
Epoch: [ 9] [ 124/ 202] time: 15565.5586, d_loss: 1.66399622, g_loss: 0.55205768
Epoch: [ 9] [ 125/ 202] time: 15573.4586, d_loss: 2.06843472, g_loss: 0.35422406
Epoch: [ 9] [ 126/ 202] time: 15581.3148, d_loss: 1.62027359, g_loss: 0.41546547
Epoch: [ 9] [ 127/ 202] time: 15589.2127, d_loss: 1.13047504, g_loss: 1.24385524
Epoch: [ 9] [ 128/ 202] time: 15597.0791, d_loss: 1.38368225, g_loss: 0.42347109
Epoch: [ 9] [ 129/ 202] time: 15605.0747, d_loss: 1.55379021, g_loss: 0.68392706
Epoch: [ 9] [ 130/ 202] time: 15612.9965, d_loss: 1.37463892, g_loss: 0.77729726
Epoch: [ 9] [ 131/ 202] time: 15620.8585, d_loss: 1.70723283, g_loss: 0.43012446
Epoch: [ 9] [ 132/ 202] time: 15628.7803, d_loss: 1.57750726, g_loss: 0.58455563
Epoch: [ 9] [ 133/ 202] time: 15636.6277, d_loss: 1.61563754, g_loss: 0.44631445
Epoch: [ 9] [ 134/ 202] time: 15644.4962, d_loss: 1.32373512, g_loss: 0.72262716
Epoch: [ 9] [ 135/ 202] time: 15652.3861, d_loss: 1.41215229, g_loss: 0.55304867
Epoch: [ 9] [ 136/ 202] time: 15660.2782, d_loss: 2.47040081, g_loss: 0.22839180
Epoch: [ 9] [ 137/ 202] time: 15668.2228, d_loss: 2.61238909, g_loss: 0.80034429
Epoch: [ 9] [ 138/ 202] time: 15676.0706, d_loss: 2.03967547, g_loss: 0.32731587
Epoch: [ 9] [ 139/ 202] time: 15683.9246, d_loss: 1.28366303, g_loss: 0.73395073
Epoch: [ 9] [ 140/ 202] time: 15691.8205, d_loss: 1.33273506, g_loss: 0.74420094
Epoch: [ 9] [ 141/ 202] time: 15699.7270, d_loss: 1.20051694, g_loss: 0.71237087
Epoch: [ 9] [ 142/ 202] time: 15707.6293, d_loss: 1.82571101, g_loss: 0.29783979
Epoch: [ 9] [ 143/ 202] time: 15715.5473, d_loss: 2.11459064, g_loss: 0.49973875
Epoch: [ 9] [ 144/ 202] time: 15723.4624, d_loss: 1.73012304, g_loss: 0.65868127
Epoch: [ 9] [ 145/ 202] time: 15731.3832, d_loss: 1.40401471, g_loss: 0.48951703
Epoch: [ 9] [ 146/ 202] time: 15739.3254, d_loss: 1.22749031, g_loss: 0.81815767
Epoch: [ 9] [ 147/ 202] time: 15747.2014, d_loss: 1.38652325, g_loss: 0.61730325
Epoch: [ 9] [ 148/ 202] time: 15755.2081, d_loss: 1.23772514, g_loss: 0.69113481
Epoch: [ 9] [ 149/ 202] time: 15763.1060, d_loss: 1.45175076, g_loss: 0.80143857
Epoch: [ 9] [ 150/ 202] time: 15771.0947, d_loss: 1.55192065, g_loss: 0.39097109
Epoch: [ 9] [ 151/ 202] time: 15778.9836, d_loss: 1.47722375, g_loss: 0.72771347
Epoch: [ 9] [ 152/ 202] time: 15786.8969, d_loss: 1.33764231, g_loss: 0.85160595
Epoch: [ 9] [ 153/ 202] time: 15794.8592, d_loss: 1.71869409, g_loss: 0.47452036
Epoch: [ 9] [ 154/ 202] time: 15802.6936, d_loss: 1.61176491, g_loss: 0.36817461
Epoch: [ 9] [ 155/ 202] time: 15810.5910, d_loss: 1.94656062, g_loss: 0.44221440
Epoch: [ 9] [ 156/ 202] time: 15818.5617, d_loss: 1.74786460, g_loss: 0.66741264
Epoch: [ 9] [ 157/ 202] time: 15826.3760, d_loss: 1.51765990, g_loss: 0.57311416
Epoch: [ 9] [ 158/ 202] time: 15834.2335, d_loss: 1.28737426, g_loss: 0.59622920
Epoch: [ 9] [ 159/ 202] time: 15842.1215, d_loss: 1.23749185, g_loss: 0.74532294
Epoch: [ 9] [ 160/ 202] time: 15850.0337, d_loss: 1.22765613, g_loss: 0.68356180
Epoch: [ 9] [ 161/ 202] time: 15857.9611, d_loss: 1.22540236, g_loss: 0.58154452
Epoch: [ 9] [ 162/ 202] time: 15865.8312, d_loss: 1.39112759, g_loss: 0.60146129
Epoch: [ 9] [ 163/ 202] time: 15873.7391, d_loss: 1.81379533, g_loss: 0.36938605
Epoch: [ 9] [ 164/ 202] time: 15881.6808, d_loss: 1.60241175, g_loss: 0.98217726
Epoch: [ 9] [ 165/ 202] time: 15889.6026, d_loss: 1.36520934, g_loss: 0.53102028
Epoch: [ 9] [ 166/ 202] time: 15897.4790, d_loss: 2.04221988, g_loss: 0.26280552
Epoch: [ 9] [ 167/ 202] time: 15905.3881, d_loss: 1.51884079, g_loss: 1.02448916
Epoch: [ 9] [ 168/ 202] time: 15913.3446, d_loss: 1.46781611, g_loss: 0.68586046
Epoch: [ 9] [ 169/ 202] time: 15921.3016, d_loss: 1.62249446, g_loss: 0.44365990
Epoch: [ 9] [ 170/ 202] time: 15929.1786, d_loss: 1.30776811, g_loss: 0.81540239
Epoch: [ 9] [ 171/ 202] time: 15937.0699, d_loss: 1.72503638, g_loss: 0.32268560
Epoch: [ 9] [ 172/ 202] time: 15945.0246, d_loss: 1.74853873, g_loss: 0.62903941
Epoch: [ 9] [ 173/ 202] time: 15952.9535, d_loss: 1.35532939, g_loss: 0.83499742
Epoch: [ 9] [ 174/ 202] time: 15960.8958, d_loss: 1.36216390, g_loss: 0.60823357
Epoch: [ 9] [ 175/ 202] time: 15968.7470, d_loss: 1.36691833, g_loss: 0.69479316
Epoch: [ 9] [ 176/ 202] time: 15976.6672, d_loss: 1.32783270, g_loss: 0.83913302
Epoch: [ 9] [ 177/ 202] time: 15984.6252, d_loss: 1.24721444, g_loss: 0.49377105
Epoch: [ 9] [ 178/ 202] time: 15992.5210, d_loss: 1.02276540, g_loss: 0.67428255
Epoch: [ 9] [ 179/ 202] time: 16000.4154, d_loss: 1.19949627, g_loss: 0.82767195
Epoch: [ 9] [ 180/ 202] time: 16008.3540, d_loss: 1.52528870, g_loss: 0.43415356
[Sample] d_loss: 0.90032303, g_loss: 0.67797744
Epoch: [ 9] [ 181/ 202] time: 16018.2084, d_loss: 1.10528100, g_loss: 0.91431725
Epoch: [ 9] [ 182/ 202] time: 16026.5294, d_loss: 1.15522671, g_loss: 0.68836749
Epoch: [ 9] [ 183/ 202] time: 16034.3586, d_loss: 2.01555586, g_loss: 0.27538729
Epoch: [ 9] [ 184/ 202] time: 16042.2032, d_loss: 1.70931304, g_loss: 0.93468034
Epoch: [ 9] [ 185/ 202] time: 16050.1170, d_loss: 2.12563729, g_loss: 0.21298113
Epoch: [ 9] [ 186/ 202] time: 16057.9620, d_loss: 2.17324591, g_loss: 1.17285991
Epoch: [ 9] [ 187/ 202] time: 16065.9223, d_loss: 2.60380840, g_loss: 0.21621963
Epoch: [ 9] [ 188/ 202] time: 16073.8435, d_loss: 1.69763517, g_loss: 0.67050254
Epoch: [ 9] [ 189/ 202] time: 16081.7923, d_loss: 1.92144883, g_loss: 0.48414823
Epoch: [ 9] [ 190/ 202] time: 16089.6722, d_loss: 1.58536458, g_loss: 0.49739534
Epoch: [ 9] [ 191/ 202] time: 16097.5888, d_loss: 1.46004653, g_loss: 0.55173671
Epoch: [ 9] [ 192/ 202] time: 16105.4898, d_loss: 1.42535651, g_loss: 0.62045658
Epoch: [ 9] [ 193/ 202] time: 16113.4136, d_loss: 1.57470965, g_loss: 0.41706610
Epoch: [ 9] [ 194/ 202] time: 16121.3526, d_loss: 1.46898532, g_loss: 0.66612023
Epoch: [ 9] [ 195/ 202] time: 16129.3059, d_loss: 1.13603044, g_loss: 0.84969652
Epoch: [ 9] [ 196/ 202] time: 16137.1867, d_loss: 1.66026163, g_loss: 0.40586609
Epoch: [ 9] [ 197/ 202] time: 16145.1175, d_loss: 1.31146049, g_loss: 0.74429369
Epoch: [ 9] [ 198/ 202] time: 16152.9984, d_loss: 1.67831707, g_loss: 0.39632928
Epoch: [ 9] [ 199/ 202] time: 16160.9523, d_loss: 1.83263803, g_loss: 0.76877284
Epoch: [ 9] [ 200/ 202] time: 16168.8315, d_loss: 2.33668280, g_loss: 0.13461117
Epoch: [ 9] [ 201/ 202] time: 16176.8181, d_loss: 1.86223662, g_loss: 0.84486568
Epoch: [10] [   0/ 202] time: 16444.8375, d_loss: 1.75769210, g_loss: 0.40559226
Epoch: [10] [   1/ 202] time: 16452.8718, d_loss: 1.80916858, g_loss: 0.35566539
Epoch: [10] [   2/ 202] time: 16460.8654, d_loss: 1.33563578, g_loss: 0.80578482
Epoch: [10] [   3/ 202] time: 16468.7399, d_loss: 1.43910074, g_loss: 0.55258298
Epoch: [10] [   4/ 202] time: 16476.6485, d_loss: 1.71817136, g_loss: 0.60209835
Epoch: [10] [   5/ 202] time: 16484.5397, d_loss: 1.78154302, g_loss: 0.56076509
Epoch: [10] [   6/ 202] time: 16492.4342, d_loss: 1.49244535, g_loss: 0.55045462
Epoch: [10] [   7/ 202] time: 16500.3491, d_loss: 1.49606431, g_loss: 0.49981064
Epoch: [10] [   8/ 202] time: 16508.3234, d_loss: 1.24717450, g_loss: 1.11257005
Epoch: [10] [   9/ 202] time: 16516.3250, d_loss: 1.50183630, g_loss: 0.46003771
Epoch: [10] [  10/ 202] time: 16524.4224, d_loss: 1.52899981, g_loss: 0.40490621
Epoch: [10] [  11/ 202] time: 16532.3497, d_loss: 1.30798626, g_loss: 0.66134679
Epoch: [10] [  12/ 202] time: 16540.2524, d_loss: 1.52113497, g_loss: 0.46823934
Epoch: [10] [  13/ 202] time: 16548.2472, d_loss: 1.96514535, g_loss: 0.38328087
Epoch: [10] [  14/ 202] time: 16556.2970, d_loss: 2.33290100, g_loss: 0.35509831
Epoch: [10] [  15/ 202] time: 16564.2305, d_loss: 1.84074092, g_loss: 0.48662096
Epoch: [10] [  16/ 202] time: 16572.1927, d_loss: 1.71834803, g_loss: 0.53098035
Epoch: [10] [  17/ 202] time: 16580.1636, d_loss: 1.43898070, g_loss: 0.53046966
Epoch: [10] [  18/ 202] time: 16588.0583, d_loss: 2.18501043, g_loss: 0.42851037
Epoch: [10] [  19/ 202] time: 16595.9095, d_loss: 1.53603697, g_loss: 0.45560572
Epoch: [10] [  20/ 202] time: 16603.9465, d_loss: 1.40790653, g_loss: 0.51042807
Epoch: [10] [  21/ 202] time: 16611.9406, d_loss: 1.71279538, g_loss: 0.56921917
Epoch: [10] [  22/ 202] time: 16627.3223, d_loss: 1.70640755, g_loss: 0.62846857
Epoch: [10] [  23/ 202] time: 16635.1947, d_loss: 2.62458372, g_loss: 0.35537833
Epoch: [10] [  24/ 202] time: 16643.0815, d_loss: 2.03418970, g_loss: 0.67661023
Epoch: [10] [  25/ 202] time: 16651.0127, d_loss: 2.01383257, g_loss: 0.32916576
Epoch: [10] [  26/ 202] time: 16658.9952, d_loss: 1.24823439, g_loss: 1.07403684
Epoch: [10] [  27/ 202] time: 16666.9461, d_loss: 1.91271949, g_loss: 0.45482236
Epoch: [10] [  28/ 202] time: 16674.8165, d_loss: 1.17720234, g_loss: 0.64719069
Epoch: [10] [  29/ 202] time: 16682.7949, d_loss: 1.17834175, g_loss: 0.68893892
Epoch: [10] [  30/ 202] time: 16690.6928, d_loss: 1.79389131, g_loss: 0.47469938
Epoch: [10] [  31/ 202] time: 16698.6114, d_loss: 1.19923210, g_loss: 0.71392113
Epoch: [10] [  32/ 202] time: 16706.5282, d_loss: 1.58904970, g_loss: 0.69808614
Epoch: [10] [  33/ 202] time: 16714.4828, d_loss: 1.85130787, g_loss: 0.37571466
Epoch: [10] [  34/ 202] time: 16722.3352, d_loss: 1.84288442, g_loss: 0.49161357
Epoch: [10] [  35/ 202] time: 16730.2773, d_loss: 2.02634263, g_loss: 0.40170527
Epoch: [10] [  36/ 202] time: 16738.1895, d_loss: 1.82093239, g_loss: 0.49262917
Epoch: [10] [  37/ 202] time: 16746.1113, d_loss: 1.34001327, g_loss: 0.56468236
Epoch: [10] [  38/ 202] time: 16754.0245, d_loss: 1.67356861, g_loss: 0.46309835
Epoch: [10] [  39/ 202] time: 16761.9367, d_loss: 1.53596914, g_loss: 0.64560217
Epoch: [10] [  40/ 202] time: 16769.8612, d_loss: 1.55191851, g_loss: 0.59063864
Epoch: [10] [  41/ 202] time: 16777.7986, d_loss: 1.35454047, g_loss: 0.57360142
Epoch: [10] [  42/ 202] time: 16785.7373, d_loss: 1.22499132, g_loss: 0.72815043
Epoch: [10] [  43/ 202] time: 16793.6419, d_loss: 1.54422593, g_loss: 0.56281686
Epoch: [10] [  44/ 202] time: 16801.6049, d_loss: 1.62948108, g_loss: 0.49171171
Epoch: [10] [  45/ 202] time: 16809.5923, d_loss: 1.67352653, g_loss: 0.50843638
Epoch: [10] [  46/ 202] time: 16817.5448, d_loss: 1.21031260, g_loss: 0.64685333
Epoch: [10] [  47/ 202] time: 16825.5510, d_loss: 1.31154585, g_loss: 0.52892005
Epoch: [10] [  48/ 202] time: 16833.5113, d_loss: 1.49254119, g_loss: 0.57086205
Epoch: [10] [  49/ 202] time: 16841.5392, d_loss: 1.47600174, g_loss: 0.55528200
Epoch: [10] [  50/ 202] time: 16849.5144, d_loss: 1.99618232, g_loss: 0.44588840
Epoch: [10] [  51/ 202] time: 16857.4871, d_loss: 1.57183290, g_loss: 0.70996976
Epoch: [10] [  52/ 202] time: 16865.3826, d_loss: 1.94154048, g_loss: 0.50162393
Epoch: [10] [  53/ 202] time: 16873.3506, d_loss: 2.01114058, g_loss: 0.69006240
Epoch: [10] [  54/ 202] time: 16881.3594, d_loss: 1.62729847, g_loss: 0.48777616
Epoch: [10] [  55/ 202] time: 16889.3017, d_loss: 1.78142464, g_loss: 0.57075012
Epoch: [10] [  56/ 202] time: 16897.2544, d_loss: 1.63126397, g_loss: 0.51764524
Epoch: [10] [  57/ 202] time: 16905.2070, d_loss: 2.05394435, g_loss: 0.38996440
Epoch: [10] [  58/ 202] time: 16913.2613, d_loss: 1.82093966, g_loss: 0.41298202
Epoch: [10] [  59/ 202] time: 16921.3359, d_loss: 1.57216108, g_loss: 0.46423247
Epoch: [10] [  60/ 202] time: 16929.3259, d_loss: 1.43192673, g_loss: 0.43306479
Epoch: [10] [  61/ 202] time: 16937.2098, d_loss: 1.39322615, g_loss: 0.87414587
Epoch: [10] [  62/ 202] time: 16945.2047, d_loss: 1.79800236, g_loss: 0.31512669
Epoch: [10] [  63/ 202] time: 16953.2150, d_loss: 1.54218054, g_loss: 0.79013246
Epoch: [10] [  64/ 202] time: 16961.1428, d_loss: 1.94121051, g_loss: 0.26916653
Epoch: [10] [  65/ 202] time: 16969.0994, d_loss: 1.95605993, g_loss: 0.53136164
Epoch: [10] [  66/ 202] time: 16977.1755, d_loss: 2.01826644, g_loss: 0.37960416
Epoch: [10] [  67/ 202] time: 16985.0781, d_loss: 1.72440410, g_loss: 0.51158869
Epoch: [10] [  68/ 202] time: 16993.0247, d_loss: 1.34125519, g_loss: 0.60669172
Epoch: [10] [  69/ 202] time: 17000.9838, d_loss: 2.35314441, g_loss: 0.20732880
Epoch: [10] [  70/ 202] time: 17008.9904, d_loss: 1.98012805, g_loss: 0.56647694
Epoch: [10] [  71/ 202] time: 17016.8983, d_loss: 1.79894400, g_loss: 0.59336656
Epoch: [10] [  72/ 202] time: 17024.8795, d_loss: 2.00578928, g_loss: 0.41630238
Epoch: [10] [  73/ 202] time: 17032.8716, d_loss: 1.53689301, g_loss: 1.11021900
Epoch: [10] [  74/ 202] time: 17040.8550, d_loss: 1.99011064, g_loss: 0.26750976
Epoch: [10] [  75/ 202] time: 17048.8185, d_loss: 1.61932337, g_loss: 0.51959127
Epoch: [10] [  76/ 202] time: 17056.7582, d_loss: 2.51529694, g_loss: 0.56112945
Epoch: [10] [  77/ 202] time: 17064.7569, d_loss: 1.47202635, g_loss: 0.84440947
Epoch: [10] [  78/ 202] time: 17072.7984, d_loss: 2.37376738, g_loss: 0.16035953
[Sample] d_loss: 1.71265411, g_loss: 0.41639811
Epoch: [10] [  79/ 202] time: 17082.5149, d_loss: 1.47924519, g_loss: 1.06450367
Epoch: [10] [  80/ 202] time: 17090.5098, d_loss: 1.81538677, g_loss: 0.33785251
Epoch: [10] [  81/ 202] time: 17098.4906, d_loss: 1.82689834, g_loss: 0.38910973
Epoch: [10] [  82/ 202] time: 17106.3835, d_loss: 2.30146074, g_loss: 0.34774816
Epoch: [10] [  83/ 202] time: 17114.3557, d_loss: 1.88794923, g_loss: 0.66612601
Epoch: [10] [  84/ 202] time: 17122.4740, d_loss: 1.92600799, g_loss: 0.35081956
Epoch: [10] [  85/ 202] time: 17130.5504, d_loss: 1.40228653, g_loss: 0.51187444
Epoch: [10] [  86/ 202] time: 17138.5210, d_loss: 1.36077142, g_loss: 1.12180340
Epoch: [10] [  87/ 202] time: 17146.3882, d_loss: 1.64233065, g_loss: 0.57447577
Epoch: [10] [  88/ 202] time: 17154.3051, d_loss: 1.58582711, g_loss: 0.42357409
Epoch: [10] [  89/ 202] time: 17162.1957, d_loss: 1.48029506, g_loss: 0.70694339
Epoch: [10] [  90/ 202] time: 17170.1334, d_loss: 1.55277348, g_loss: 0.54923600
Epoch: [10] [  91/ 202] time: 17178.1497, d_loss: 1.63160634, g_loss: 0.46061268
Epoch: [10] [  92/ 202] time: 17186.5173, d_loss: 1.56239808, g_loss: 0.55189329
Epoch: [10] [  93/ 202] time: 17195.1923, d_loss: 1.53669131, g_loss: 0.69052076
Epoch: [10] [  94/ 202] time: 17203.4698, d_loss: 1.46226776, g_loss: 0.51044881
Epoch: [10] [  95/ 202] time: 17211.5717, d_loss: 1.66944289, g_loss: 0.55728567
Epoch: [10] [  96/ 202] time: 17219.6743, d_loss: 1.10479832, g_loss: 1.03324544
Epoch: [10] [  97/ 202] time: 17227.6804, d_loss: 1.58076036, g_loss: 0.57315409
Epoch: [10] [  98/ 202] time: 17235.6398, d_loss: 1.46307635, g_loss: 0.56405115
Epoch: [10] [  99/ 202] time: 17243.5592, d_loss: 1.45426154, g_loss: 0.81091177
Epoch: [10] [ 100/ 202] time: 17251.5101, d_loss: 1.61499119, g_loss: 0.47958452
Epoch: [10] [ 101/ 202] time: 17259.5252, d_loss: 1.50581288, g_loss: 0.51108611
Epoch: [10] [ 102/ 202] time: 17267.4592, d_loss: 1.55619657, g_loss: 0.69035900
Epoch: [10] [ 103/ 202] time: 17275.4953, d_loss: 1.23451328, g_loss: 0.60891885
Epoch: [10] [ 104/ 202] time: 17283.4830, d_loss: 1.75636160, g_loss: 0.46988696
Epoch: [10] [ 105/ 202] time: 17291.5730, d_loss: 2.09717464, g_loss: 0.47710800
Epoch: [10] [ 106/ 202] time: 17299.5274, d_loss: 1.62408531, g_loss: 0.51444870
Epoch: [10] [ 107/ 202] time: 17307.5598, d_loss: 1.40007210, g_loss: 0.68363971
Epoch: [10] [ 108/ 202] time: 17315.5744, d_loss: 1.63142049, g_loss: 0.56275010
Epoch: [10] [ 109/ 202] time: 17323.5871, d_loss: 1.84458876, g_loss: 0.38199878
Epoch: [10] [ 110/ 202] time: 17331.5484, d_loss: 1.43344605, g_loss: 0.55259931
Epoch: [10] [ 111/ 202] time: 17339.5106, d_loss: 1.64743328, g_loss: 0.61615050
Epoch: [10] [ 112/ 202] time: 17347.4774, d_loss: 1.39024472, g_loss: 0.61132652
Epoch: [10] [ 113/ 202] time: 17355.4717, d_loss: 1.43215561, g_loss: 0.86160189
Epoch: [10] [ 114/ 202] time: 17363.4092, d_loss: 1.72615290, g_loss: 0.52115941
Epoch: [10] [ 115/ 202] time: 17371.4411, d_loss: 1.44504261, g_loss: 0.67581230
Epoch: [10] [ 116/ 202] time: 17379.4607, d_loss: 1.92427182, g_loss: 0.35086787
Epoch: [10] [ 117/ 202] time: 17387.4246, d_loss: 2.30709863, g_loss: 0.35303324
Epoch: [10] [ 118/ 202] time: 17395.4313, d_loss: 1.90504575, g_loss: 0.47747806
Epoch: [10] [ 119/ 202] time: 17403.3513, d_loss: 2.09000635, g_loss: 0.38180169
Epoch: [10] [ 120/ 202] time: 17411.3517, d_loss: 1.77201724, g_loss: 0.48603511
Epoch: [10] [ 121/ 202] time: 17419.3617, d_loss: 1.86913109, g_loss: 0.33280131
Epoch: [10] [ 122/ 202] time: 17427.2964, d_loss: 1.20518255, g_loss: 1.15410161
Epoch: [10] [ 123/ 202] time: 17435.2304, d_loss: 1.59445977, g_loss: 0.47311354
Epoch: [10] [ 124/ 202] time: 17443.2966, d_loss: 1.83039284, g_loss: 0.35310206
Epoch: [10] [ 125/ 202] time: 17451.3654, d_loss: 1.83548665, g_loss: 0.89818788
Epoch: [10] [ 126/ 202] time: 17459.3561, d_loss: 1.53772831, g_loss: 0.42714757
Epoch: [10] [ 127/ 202] time: 17467.4331, d_loss: 1.53441381, g_loss: 0.51765573
Epoch: [10] [ 128/ 202] time: 17475.4630, d_loss: 1.57305670, g_loss: 0.66735041
Epoch: [10] [ 129/ 202] time: 17483.4414, d_loss: 2.12792587, g_loss: 0.26440293
Epoch: [10] [ 130/ 202] time: 17491.3896, d_loss: 1.73119736, g_loss: 0.64288294
Epoch: [10] [ 131/ 202] time: 17499.4363, d_loss: 1.61470795, g_loss: 0.49376917
Epoch: [10] [ 132/ 202] time: 17507.3862, d_loss: 1.46444154, g_loss: 0.40833843
Epoch: [10] [ 133/ 202] time: 17515.4480, d_loss: 1.25079834, g_loss: 0.68202060
Epoch: [10] [ 134/ 202] time: 17523.3771, d_loss: 2.06413722, g_loss: 0.49841458
Epoch: [10] [ 135/ 202] time: 17531.3436, d_loss: 1.79030573, g_loss: 0.98427188
Epoch: [10] [ 136/ 202] time: 17539.4657, d_loss: 1.92315686, g_loss: 0.37533003
Epoch: [10] [ 137/ 202] time: 17547.4225, d_loss: 1.46441543, g_loss: 0.54436457
Epoch: [10] [ 138/ 202] time: 17555.3590, d_loss: 1.48664129, g_loss: 0.56325388
Epoch: [10] [ 139/ 202] time: 17563.2795, d_loss: 0.87816906, g_loss: 1.13417602
Epoch: [10] [ 140/ 202] time: 17571.2945, d_loss: 1.65117240, g_loss: 0.40395290
Epoch: [10] [ 141/ 202] time: 17579.2343, d_loss: 1.93507624, g_loss: 0.35585600
Epoch: [10] [ 142/ 202] time: 17587.2057, d_loss: 1.65523171, g_loss: 0.69849408
Epoch: [10] [ 143/ 202] time: 17595.1884, d_loss: 1.71365023, g_loss: 0.47078517
Epoch: [10] [ 144/ 202] time: 17603.2338, d_loss: 1.48376930, g_loss: 0.42677832
Epoch: [10] [ 145/ 202] time: 17611.3363, d_loss: 1.46701980, g_loss: 0.65662956
Epoch: [10] [ 146/ 202] time: 17619.2742, d_loss: 1.64831734, g_loss: 0.43481457
Epoch: [10] [ 147/ 202] time: 17627.2490, d_loss: 1.39934039, g_loss: 0.54241431
Epoch: [10] [ 148/ 202] time: 17635.2566, d_loss: 1.32023394, g_loss: 0.63927376
Epoch: [10] [ 149/ 202] time: 17643.2271, d_loss: 1.54350269, g_loss: 0.69255030
Epoch: [10] [ 150/ 202] time: 17651.2094, d_loss: 1.73663974, g_loss: 0.36338079
Epoch: [10] [ 151/ 202] time: 17659.1821, d_loss: 1.90508330, g_loss: 0.44447231
Epoch: [10] [ 152/ 202] time: 17667.1841, d_loss: 1.79177928, g_loss: 0.56473398
Epoch: [10] [ 153/ 202] time: 17675.2191, d_loss: 1.79143584, g_loss: 0.54674733
Epoch: [10] [ 154/ 202] time: 17683.2026, d_loss: 1.45535874, g_loss: 0.48392117
Epoch: [10] [ 155/ 202] time: 17691.0747, d_loss: 1.75088179, g_loss: 0.67883188
Epoch: [10] [ 156/ 202] time: 17699.0609, d_loss: 1.42855597, g_loss: 0.58942884
Epoch: [10] [ 157/ 202] time: 17707.0027, d_loss: 1.41117108, g_loss: 0.68277806
Epoch: [10] [ 158/ 202] time: 17714.9417, d_loss: 1.08238411, g_loss: 1.07842278
Epoch: [10] [ 159/ 202] time: 17722.9006, d_loss: 1.27696586, g_loss: 0.51202971
Epoch: [10] [ 160/ 202] time: 17730.8916, d_loss: 1.26536155, g_loss: 0.57204735
Epoch: [10] [ 161/ 202] time: 17738.8425, d_loss: 1.55088723, g_loss: 1.27483034
Epoch: [10] [ 162/ 202] time: 17746.7111, d_loss: 1.35674512, g_loss: 0.47314405
Epoch: [10] [ 163/ 202] time: 17754.7054, d_loss: 2.11510468, g_loss: 0.28620881
Epoch: [10] [ 164/ 202] time: 17762.6559, d_loss: 1.91824889, g_loss: 0.89699578
Epoch: [10] [ 165/ 202] time: 17770.6293, d_loss: 1.62725830, g_loss: 0.43702036
Epoch: [10] [ 166/ 202] time: 17778.5542, d_loss: 1.45347714, g_loss: 0.66420430
Epoch: [10] [ 167/ 202] time: 17786.4768, d_loss: 1.55328012, g_loss: 0.68286204
Epoch: [10] [ 168/ 202] time: 17794.4782, d_loss: 1.50947046, g_loss: 0.50349867
Epoch: [10] [ 169/ 202] time: 17802.5262, d_loss: 1.65983462, g_loss: 0.35448194
Epoch: [10] [ 170/ 202] time: 17810.4753, d_loss: 1.36638975, g_loss: 0.63299990
Epoch: [10] [ 171/ 202] time: 17818.4305, d_loss: 1.70524025, g_loss: 0.57789171
Epoch: [10] [ 172/ 202] time: 17826.3983, d_loss: 1.66312051, g_loss: 0.51029855
Epoch: [10] [ 173/ 202] time: 17834.3891, d_loss: 1.19643557, g_loss: 0.72928262
Epoch: [10] [ 174/ 202] time: 17842.2958, d_loss: 1.58897460, g_loss: 0.48183376
Epoch: [10] [ 175/ 202] time: 17850.3270, d_loss: 1.58297396, g_loss: 0.44893771
Epoch: [10] [ 176/ 202] time: 17858.7103, d_loss: 2.15814638, g_loss: 0.36578870
Epoch: [10] [ 177/ 202] time: 17866.7949, d_loss: 1.73467755, g_loss: 0.54829931
Epoch: [10] [ 178/ 202] time: 17874.8584, d_loss: 1.57279074, g_loss: 0.56764579
[Sample] d_loss: 2.08125162, g_loss: 1.01322770
Epoch: [10] [ 179/ 202] time: 17884.9360, d_loss: 1.61779809, g_loss: 0.51074529
Epoch: [10] [ 180/ 202] time: 17892.9316, d_loss: 1.63846397, g_loss: 0.49336642
Epoch: [10] [ 181/ 202] time: 17900.9260, d_loss: 1.31938076, g_loss: 0.77917761
Epoch: [10] [ 182/ 202] time: 17908.9609, d_loss: 1.42813301, g_loss: 0.59892786
Epoch: [10] [ 183/ 202] time: 17916.9729, d_loss: 1.50949860, g_loss: 0.62710989
Epoch: [10] [ 184/ 202] time: 17925.0102, d_loss: 1.73497033, g_loss: 0.74835169
Epoch: [10] [ 185/ 202] time: 17933.0852, d_loss: 2.01886392, g_loss: 0.46079725
Epoch: [10] [ 186/ 202] time: 17941.1291, d_loss: 1.48569083, g_loss: 0.69304544
Epoch: [10] [ 187/ 202] time: 17949.1241, d_loss: 1.69005454, g_loss: 0.63594252
Epoch: [10] [ 188/ 202] time: 17957.2545, d_loss: 1.80596733, g_loss: 0.46477669
Epoch: [10] [ 189/ 202] time: 17965.2605, d_loss: 1.82551956, g_loss: 0.52553940
Epoch: [10] [ 190/ 202] time: 17973.2396, d_loss: 1.23814571, g_loss: 0.75971508
Epoch: [10] [ 191/ 202] time: 17981.3803, d_loss: 1.13063622, g_loss: 0.61861980
Epoch: [10] [ 192/ 202] time: 17989.3638, d_loss: 1.40561366, g_loss: 0.58678889
Epoch: [10] [ 193/ 202] time: 17997.3508, d_loss: 1.63020074, g_loss: 0.69168514
Epoch: [10] [ 194/ 202] time: 18005.3895, d_loss: 2.07779455, g_loss: 0.25537139
Epoch: [10] [ 195/ 202] time: 18013.7106, d_loss: 1.92662632, g_loss: 0.84358913
Epoch: [10] [ 196/ 202] time: 18021.8746, d_loss: 1.95299423, g_loss: 0.38389933
Epoch: [10] [ 197/ 202] time: 18029.9291, d_loss: 1.73498654, g_loss: 0.45238405
Epoch: [10] [ 198/ 202] time: 18037.9960, d_loss: 1.65793383, g_loss: 0.65650570
Epoch: [10] [ 199/ 202] time: 18046.0845, d_loss: 1.53296828, g_loss: 0.46722174
Epoch: [10] [ 200/ 202] time: 18054.1835, d_loss: 1.50282753, g_loss: 0.59232205
Epoch: [10] [ 201/ 202] time: 18062.2176, d_loss: 1.57807291, g_loss: 0.64162612
Epoch: [11] [   0/ 202] time: 18070.6403, d_loss: 1.86826324, g_loss: 0.26878262
Epoch: [11] [   1/ 202] time: 18078.7182, d_loss: 1.76208138, g_loss: 0.59341466
Epoch: [11] [   2/ 202] time: 18086.7895, d_loss: 1.88878036, g_loss: 0.29227796
Epoch: [11] [   3/ 202] time: 18095.0198, d_loss: 1.48875022, g_loss: 0.54205096
Epoch: [11] [   4/ 202] time: 18103.0901, d_loss: 1.27681994, g_loss: 0.59255421
Epoch: [11] [   5/ 202] time: 18111.2039, d_loss: 1.38103271, g_loss: 0.73185277
Epoch: [11] [   6/ 202] time: 18119.2451, d_loss: 1.33785725, g_loss: 0.53930742
Epoch: [11] [   7/ 202] time: 18127.2684, d_loss: 1.65068030, g_loss: 0.44446057
Epoch: [11] [   8/ 202] time: 18135.2267, d_loss: 1.41298497, g_loss: 0.87096608
Epoch: [11] [   9/ 202] time: 18143.2796, d_loss: 2.01683998, g_loss: 0.32362932
Epoch: [11] [  10/ 202] time: 18151.4056, d_loss: 1.87297750, g_loss: 0.31555471
Epoch: [11] [  11/ 202] time: 18159.4951, d_loss: 1.76409817, g_loss: 0.49463987
Epoch: [11] [  12/ 202] time: 18167.5543, d_loss: 1.49153566, g_loss: 0.37719321
Epoch: [11] [  13/ 202] time: 18175.6953, d_loss: 1.06518376, g_loss: 0.90794563
Epoch: [11] [  14/ 202] time: 18183.7929, d_loss: 1.68352270, g_loss: 0.64933717
Epoch: [11] [  15/ 202] time: 18191.8283, d_loss: 1.68348682, g_loss: 0.56815779
Epoch: [11] [  16/ 202] time: 18199.8839, d_loss: 1.78584242, g_loss: 0.45947590
Epoch: [11] [  17/ 202] time: 18207.9532, d_loss: 1.21285009, g_loss: 0.86409146
Epoch: [11] [  18/ 202] time: 18216.0294, d_loss: 1.52392268, g_loss: 0.74276674
Epoch: [11] [  19/ 202] time: 18224.0789, d_loss: 1.04889500, g_loss: 0.62183338
Epoch: [11] [  20/ 202] time: 18232.1457, d_loss: 1.31862271, g_loss: 0.56476843
Epoch: [11] [  21/ 202] time: 18240.1784, d_loss: 1.51457584, g_loss: 0.49216241
Epoch: [11] [  22/ 202] time: 18248.3207, d_loss: 1.63794720, g_loss: 0.56839001
Epoch: [11] [  23/ 202] time: 18256.3605, d_loss: 2.19614100, g_loss: 0.29863745
Epoch: [11] [  24/ 202] time: 18264.4324, d_loss: 2.03625011, g_loss: 1.09095168
Epoch: [11] [  25/ 202] time: 18272.5011, d_loss: 2.22677755, g_loss: 0.23542491
Epoch: [11] [  26/ 202] time: 18280.5952, d_loss: 1.59132767, g_loss: 0.80392349
Epoch: [11] [  27/ 202] time: 18288.6703, d_loss: 1.54763544, g_loss: 0.50176907
Epoch: [11] [  28/ 202] time: 18296.7323, d_loss: 1.30482149, g_loss: 0.65242279
Epoch: [11] [  29/ 202] time: 18304.8603, d_loss: 1.09396243, g_loss: 0.83603752
Epoch: [11] [  30/ 202] time: 18312.9825, d_loss: 1.45703149, g_loss: 0.45365757
Epoch: [11] [  31/ 202] time: 18321.0238, d_loss: 0.91612077, g_loss: 1.11748338
Epoch: [11] [  32/ 202] time: 18329.0816, d_loss: 1.71013582, g_loss: 0.40249497
Epoch: [11] [  33/ 202] time: 18337.1093, d_loss: 2.43023324, g_loss: 0.19128177
Epoch: [11] [  34/ 202] time: 18345.1806, d_loss: 1.83573604, g_loss: 1.09761143
Epoch: [11] [  35/ 202] time: 18353.1748, d_loss: 1.81964970, g_loss: 0.38854849
Epoch: [11] [  36/ 202] time: 18361.2427, d_loss: 2.27212620, g_loss: 0.33595163
Epoch: [11] [  37/ 202] time: 18369.2881, d_loss: 1.67594838, g_loss: 0.58866280
Epoch: [11] [  38/ 202] time: 18377.3998, d_loss: 1.77659678, g_loss: 0.34556520
Epoch: [11] [  39/ 202] time: 18385.3854, d_loss: 1.40004218, g_loss: 0.75193739
Epoch: [11] [  40/ 202] time: 18393.4314, d_loss: 1.75419486, g_loss: 0.45271552
Epoch: [11] [  41/ 202] time: 18401.4911, d_loss: 1.93688011, g_loss: 0.32511377
Epoch: [11] [  42/ 202] time: 18409.5640, d_loss: 1.63658333, g_loss: 0.67871952
Epoch: [11] [  43/ 202] time: 18417.5636, d_loss: 1.35437489, g_loss: 0.73228002
Epoch: [11] [  44/ 202] time: 18425.5787, d_loss: 1.63091803, g_loss: 0.35218608
Epoch: [11] [  45/ 202] time: 18433.6063, d_loss: 1.49176383, g_loss: 0.51368248
Epoch: [11] [  46/ 202] time: 18441.6753, d_loss: 1.21313739, g_loss: 0.75948048
Epoch: [11] [  47/ 202] time: 18449.7136, d_loss: 1.41726923, g_loss: 0.41053888
Epoch: [11] [  48/ 202] time: 18457.6610, d_loss: 1.57066548, g_loss: 0.61740780
Epoch: [11] [  49/ 202] time: 18465.7005, d_loss: 1.36841381, g_loss: 0.49586233
Epoch: [11] [  50/ 202] time: 18473.7201, d_loss: 1.89043379, g_loss: 0.40243560
Epoch: [11] [  51/ 202] time: 18481.7575, d_loss: 1.73972845, g_loss: 0.50230455
Epoch: [11] [  52/ 202] time: 18489.8204, d_loss: 2.04579759, g_loss: 0.40903714
Epoch: [11] [  53/ 202] time: 18497.8894, d_loss: 1.63399792, g_loss: 0.76431572
Epoch: [11] [  54/ 202] time: 18505.9729, d_loss: 1.76332390, g_loss: 0.48533034
Epoch: [11] [  55/ 202] time: 18514.0132, d_loss: 1.79677117, g_loss: 0.52419710
Epoch: [11] [  56/ 202] time: 18522.1250, d_loss: 1.67475653, g_loss: 0.45568183
Epoch: [11] [  57/ 202] time: 18530.1525, d_loss: 1.78952312, g_loss: 0.41096479
Epoch: [11] [  58/ 202] time: 18538.3620, d_loss: 1.50577497, g_loss: 0.54163039
Epoch: [11] [  59/ 202] time: 18546.4148, d_loss: 1.70632148, g_loss: 0.43820411
Epoch: [11] [  60/ 202] time: 18554.4665, d_loss: 2.03865886, g_loss: 0.27398625
Epoch: [11] [  61/ 202] time: 18562.4724, d_loss: 2.06425714, g_loss: 0.66581380
Epoch: [11] [  62/ 202] time: 18570.5651, d_loss: 1.92402124, g_loss: 0.41743332
Epoch: [11] [  63/ 202] time: 18578.6745, d_loss: 1.43903303, g_loss: 0.50329399
Epoch: [11] [  64/ 202] time: 18586.6951, d_loss: 1.71660590, g_loss: 0.40577334
Epoch: [11] [  65/ 202] time: 18594.7624, d_loss: 1.88137841, g_loss: 0.50925839
Epoch: [11] [  66/ 202] time: 18602.8227, d_loss: 1.69596732, g_loss: 0.49466723
Epoch: [11] [  67/ 202] time: 18610.8163, d_loss: 1.52685571, g_loss: 0.57012820
Epoch: [11] [  68/ 202] time: 18618.8498, d_loss: 1.52410102, g_loss: 0.53469026
Epoch: [11] [  69/ 202] time: 18626.9774, d_loss: 2.19163990, g_loss: 0.27700040
Epoch: [11] [  70/ 202] time: 18635.1352, d_loss: 2.77824020, g_loss: 0.25786424
Epoch: [11] [  71/ 202] time: 18643.1747, d_loss: 2.28904867, g_loss: 0.47063097
Epoch: [11] [  72/ 202] time: 18651.1959, d_loss: 1.58815002, g_loss: 0.70146549
Epoch: [11] [  73/ 202] time: 18659.3454, d_loss: 1.57830036, g_loss: 0.51395762
Epoch: [11] [  74/ 202] time: 18667.4366, d_loss: 1.59522188, g_loss: 0.60369426
Epoch: [11] [  75/ 202] time: 18675.4664, d_loss: 1.27316260, g_loss: 0.76735640
Epoch: [11] [  76/ 202] time: 18683.4962, d_loss: 1.64470339, g_loss: 0.63272989
[Sample] d_loss: 1.60207212, g_loss: 0.93157542
Epoch: [11] [  77/ 202] time: 18693.5010, d_loss: 1.30455470, g_loss: 0.64205539
Epoch: [11] [  78/ 202] time: 18701.6120, d_loss: 1.44548202, g_loss: 0.55212617
Epoch: [11] [  79/ 202] time: 18709.6340, d_loss: 1.47823727, g_loss: 0.56658065
Epoch: [11] [  80/ 202] time: 18717.7345, d_loss: 1.05228090, g_loss: 0.83368945
Epoch: [11] [  81/ 202] time: 18725.8537, d_loss: 1.42257833, g_loss: 0.43534675
Epoch: [11] [  82/ 202] time: 18733.9367, d_loss: 1.44701505, g_loss: 0.62837189
Epoch: [11] [  83/ 202] time: 18742.0338, d_loss: 1.65670490, g_loss: 0.48357525
Epoch: [11] [  84/ 202] time: 18750.0828, d_loss: 2.31178570, g_loss: 0.25369844
Epoch: [11] [  85/ 202] time: 18758.1253, d_loss: 1.85806656, g_loss: 0.93802351
Epoch: [11] [  86/ 202] time: 18766.1252, d_loss: 1.67524731, g_loss: 0.32490081
Epoch: [11] [  87/ 202] time: 18774.1466, d_loss: 1.46706390, g_loss: 0.76640201
Epoch: [11] [  88/ 202] time: 18782.2535, d_loss: 1.48182309, g_loss: 0.68395531
Epoch: [11] [  89/ 202] time: 18790.3488, d_loss: 1.16827250, g_loss: 0.64372587
Epoch: [11] [  90/ 202] time: 18798.3789, d_loss: 1.63981533, g_loss: 0.44019261
Epoch: [11] [  91/ 202] time: 18806.5283, d_loss: 2.45218372, g_loss: 0.36199939
Epoch: [11] [  92/ 202] time: 18814.5446, d_loss: 2.01099777, g_loss: 0.41108197
Epoch: [11] [  93/ 202] time: 18822.6208, d_loss: 2.02719259, g_loss: 0.26611245
Epoch: [11] [  94/ 202] time: 18830.6270, d_loss: 1.59746385, g_loss: 0.92958623
Epoch: [11] [  95/ 202] time: 18838.6286, d_loss: 1.39647567, g_loss: 0.59125501
Epoch: [11] [  96/ 202] time: 18846.6908, d_loss: 2.18965554, g_loss: 0.16989616
Epoch: [11] [  97/ 202] time: 18854.8632, d_loss: 1.68985963, g_loss: 0.90288979
Epoch: [11] [  98/ 202] time: 18862.9489, d_loss: 1.55254841, g_loss: 0.46313879
Epoch: [11] [  99/ 202] time: 18871.0192, d_loss: 1.98864520, g_loss: 0.33219683
Epoch: [11] [ 100/ 202] time: 18879.0800, d_loss: 1.67883492, g_loss: 1.15258110
Epoch: [11] [ 101/ 202] time: 18887.1377, d_loss: 1.90010858, g_loss: 0.39161044
Epoch: [11] [ 102/ 202] time: 18895.1710, d_loss: 1.62377059, g_loss: 0.54532623
Epoch: [11] [ 103/ 202] time: 18903.1770, d_loss: 1.27128673, g_loss: 0.56820750
Epoch: [11] [ 104/ 202] time: 18911.2030, d_loss: 1.56000924, g_loss: 0.48111662
Epoch: [11] [ 105/ 202] time: 18919.2673, d_loss: 1.77389729, g_loss: 0.43144274
Epoch: [11] [ 106/ 202] time: 18927.3711, d_loss: 1.56195784, g_loss: 0.55566579
Epoch: [11] [ 107/ 202] time: 18935.5245, d_loss: 1.62524521, g_loss: 0.67235678
Epoch: [11] [ 108/ 202] time: 18943.5001, d_loss: 2.01423407, g_loss: 0.51494342
Epoch: [11] [ 109/ 202] time: 18951.5537, d_loss: 2.22656846, g_loss: 0.22990814
Epoch: [11] [ 110/ 202] time: 18959.6419, d_loss: 1.43604779, g_loss: 1.02098966
Epoch: [11] [ 111/ 202] time: 18967.6609, d_loss: 1.31355059, g_loss: 0.71318436
Epoch: [11] [ 112/ 202] time: 18975.7325, d_loss: 1.46580577, g_loss: 0.44318032
Epoch: [11] [ 113/ 202] time: 18983.8084, d_loss: 1.31620240, g_loss: 0.60215878
Epoch: [11] [ 114/ 202] time: 18991.8206, d_loss: 1.08988261, g_loss: 0.92659527
Epoch: [11] [ 115/ 202] time: 18999.9463, d_loss: 1.25081193, g_loss: 0.68655741
Epoch: [11] [ 116/ 202] time: 19007.9759, d_loss: 1.31941402, g_loss: 0.65118909
Epoch: [11] [ 117/ 202] time: 19016.0223, d_loss: 2.08985806, g_loss: 0.24966970
Epoch: [11] [ 118/ 202] time: 19024.0296, d_loss: 1.92331028, g_loss: 0.71951079
Epoch: [11] [ 119/ 202] time: 19032.0722, d_loss: 2.02690053, g_loss: 0.30568334
Epoch: [11] [ 120/ 202] time: 19040.1969, d_loss: 1.61644936, g_loss: 0.52820373
Epoch: [11] [ 121/ 202] time: 19048.2555, d_loss: 1.77777410, g_loss: 0.45212430
Epoch: [11] [ 122/ 202] time: 19056.2217, d_loss: 1.53632760, g_loss: 0.63094437
Epoch: [11] [ 123/ 202] time: 19064.1826, d_loss: 1.43634474, g_loss: 0.75244766
Epoch: [11] [ 124/ 202] time: 19072.1644, d_loss: 2.13419366, g_loss: 0.20879519
Epoch: [11] [ 125/ 202] time: 19080.2811, d_loss: 2.71838689, g_loss: 0.27893394
Epoch: [11] [ 126/ 202] time: 19088.2786, d_loss: 1.52067494, g_loss: 0.68069220
Epoch: [11] [ 127/ 202] time: 19096.2348, d_loss: 1.52394032, g_loss: 0.73747301
Epoch: [11] [ 128/ 202] time: 19104.3228, d_loss: 1.82924390, g_loss: 0.35294765
Epoch: [11] [ 129/ 202] time: 19112.3568, d_loss: 1.94377112, g_loss: 0.39600724
Epoch: [11] [ 130/ 202] time: 19120.3588, d_loss: 1.80016041, g_loss: 0.53665257
Epoch: [11] [ 131/ 202] time: 19128.3883, d_loss: 1.69085896, g_loss: 0.53764796
Epoch: [11] [ 132/ 202] time: 19136.5345, d_loss: 1.45245194, g_loss: 0.44996321
Epoch: [11] [ 133/ 202] time: 19144.5066, d_loss: 1.04569650, g_loss: 0.79782712
Epoch: [11] [ 134/ 202] time: 19152.5118, d_loss: 1.64844835, g_loss: 0.48367190
Epoch: [11] [ 135/ 202] time: 19160.6451, d_loss: 2.61406136, g_loss: 0.34822404
Epoch: [11] [ 136/ 202] time: 19168.6827, d_loss: 2.55769348, g_loss: 2.81372929
Epoch: [11] [ 137/ 202] time: 19176.8053, d_loss: 1.60633218, g_loss: 0.71059716
Epoch: [11] [ 138/ 202] time: 19184.7873, d_loss: 1.96521258, g_loss: 0.25256491
Epoch: [11] [ 139/ 202] time: 19192.8790, d_loss: 0.99348688, g_loss: 0.79360121
Epoch: [11] [ 140/ 202] time: 19200.8972, d_loss: 0.96879768, g_loss: 1.63461280
Epoch: [11] [ 141/ 202] time: 19208.9427, d_loss: 1.24241209, g_loss: 0.60902536
Epoch: [11] [ 142/ 202] time: 19216.8940, d_loss: 1.44770896, g_loss: 0.46398884
Epoch: [11] [ 143/ 202] time: 19224.8629, d_loss: 1.92500138, g_loss: 0.35005760
Epoch: [11] [ 144/ 202] time: 19232.9061, d_loss: 2.14323354, g_loss: 0.30441642
Epoch: [11] [ 145/ 202] time: 19240.9337, d_loss: 2.28851438, g_loss: 0.66794586
Epoch: [11] [ 146/ 202] time: 19248.9887, d_loss: 1.94424713, g_loss: 0.29415491
Epoch: [11] [ 147/ 202] time: 19257.0165, d_loss: 1.26756501, g_loss: 0.68575561
Epoch: [11] [ 148/ 202] time: 19265.1358, d_loss: 1.48251641, g_loss: 0.51794660
Epoch: [11] [ 149/ 202] time: 19273.1913, d_loss: 2.37939644, g_loss: 0.28819335
Epoch: [11] [ 150/ 202] time: 19281.1917, d_loss: 2.04284430, g_loss: 0.56271893
Epoch: [11] [ 151/ 202] time: 19289.1800, d_loss: 1.59401774, g_loss: 0.66030598
Epoch: [11] [ 152/ 202] time: 19297.1631, d_loss: 1.35959625, g_loss: 0.72464275
Epoch: [11] [ 153/ 202] time: 19305.1786, d_loss: 1.99483597, g_loss: 0.41942275
Epoch: [11] [ 154/ 202] time: 19313.1157, d_loss: 1.72865832, g_loss: 0.62331390
Epoch: [11] [ 155/ 202] time: 19321.1868, d_loss: 1.56963015, g_loss: 0.61299080
Epoch: [11] [ 156/ 202] time: 19329.2055, d_loss: 1.36100495, g_loss: 0.58994913
Epoch: [11] [ 157/ 202] time: 19337.2898, d_loss: 1.40387428, g_loss: 0.69513857
Epoch: [11] [ 158/ 202] time: 19345.2804, d_loss: 1.23072839, g_loss: 0.77734005
Epoch: [11] [ 159/ 202] time: 19353.2288, d_loss: 1.54814720, g_loss: 0.60455287
Epoch: [11] [ 160/ 202] time: 19361.2640, d_loss: 1.82043672, g_loss: 0.39912802
Epoch: [11] [ 161/ 202] time: 19369.4556, d_loss: 1.42086387, g_loss: 0.77975780
Epoch: [11] [ 162/ 202] time: 19377.4785, d_loss: 1.57483840, g_loss: 0.56368983
Epoch: [11] [ 163/ 202] time: 19385.4276, d_loss: 1.50849199, g_loss: 0.51587629
Epoch: [11] [ 164/ 202] time: 19393.4727, d_loss: 1.41214490, g_loss: 0.64694810
Epoch: [11] [ 165/ 202] time: 19401.5916, d_loss: 1.55025017, g_loss: 0.47076541
Epoch: [11] [ 166/ 202] time: 19409.5582, d_loss: 1.80111337, g_loss: 0.74439353
Epoch: [11] [ 167/ 202] time: 19417.5275, d_loss: 1.79376352, g_loss: 0.79027027
Epoch: [11] [ 168/ 202] time: 19425.5431, d_loss: 1.33100152, g_loss: 0.69217610
Epoch: [11] [ 169/ 202] time: 19433.5742, d_loss: 1.31909990, g_loss: 0.48483542
Epoch: [11] [ 170/ 202] time: 19441.5678, d_loss: 1.45989203, g_loss: 0.50943023
Epoch: [11] [ 171/ 202] time: 19449.5833, d_loss: 1.62442744, g_loss: 0.70893085
Epoch: [11] [ 172/ 202] time: 19457.6308, d_loss: 1.93371725, g_loss: 0.38200092
Epoch: [11] [ 173/ 202] time: 19465.7655, d_loss: 1.46762609, g_loss: 0.66220528
Epoch: [11] [ 174/ 202] time: 19473.8025, d_loss: 1.69920564, g_loss: 0.47478491
Epoch: [11] [ 175/ 202] time: 19481.8473, d_loss: 1.68061244, g_loss: 0.45466512
Epoch: [11] [ 176/ 202] time: 19489.8920, d_loss: 1.69699097, g_loss: 0.57989734
[Sample] d_loss: 1.38271940, g_loss: 0.79833305
Epoch: [11] [ 177/ 202] time: 19499.9041, d_loss: 1.38092434, g_loss: 0.53832465
Epoch: [11] [ 178/ 202] time: 19507.9145, d_loss: 1.46484804, g_loss: 0.59409463
Epoch: [11] [ 179/ 202] time: 19515.9617, d_loss: 1.35432827, g_loss: 0.62869680
Epoch: [11] [ 180/ 202] time: 19524.0217, d_loss: 1.58203828, g_loss: 0.53694272
Epoch: [11] [ 181/ 202] time: 19532.0603, d_loss: 1.23004162, g_loss: 0.72860175
Epoch: [11] [ 182/ 202] time: 19540.0618, d_loss: 1.66755092, g_loss: 0.37262896
Epoch: [11] [ 183/ 202] time: 19548.2908, d_loss: 2.10579729, g_loss: 0.31396908
Epoch: [11] [ 184/ 202] time: 19556.3785, d_loss: 1.65769374, g_loss: 0.80117822
Epoch: [11] [ 185/ 202] time: 19564.4151, d_loss: 1.58364093, g_loss: 0.45230326
Epoch: [11] [ 186/ 202] time: 19572.4480, d_loss: 1.50796533, g_loss: 0.60533559
Epoch: [11] [ 187/ 202] time: 19580.4927, d_loss: 1.76365209, g_loss: 0.46205109
Epoch: [11] [ 188/ 202] time: 19588.5420, d_loss: 1.52867270, g_loss: 0.55673593
Epoch: [11] [ 189/ 202] time: 19596.5576, d_loss: 1.73289526, g_loss: 0.57527155
Epoch: [11] [ 190/ 202] time: 19604.5539, d_loss: 1.63808382, g_loss: 0.39669442
Epoch: [11] [ 191/ 202] time: 19612.5328, d_loss: 1.41853940, g_loss: 0.59548372
Epoch: [11] [ 192/ 202] time: 19620.6030, d_loss: 1.48620117, g_loss: 0.77521968
Epoch: [11] [ 193/ 202] time: 19628.5637, d_loss: 1.44484162, g_loss: 0.57824540
Epoch: [11] [ 194/ 202] time: 19636.6631, d_loss: 1.77862620, g_loss: 0.42521125
Epoch: [11] [ 195/ 202] time: 19644.7391, d_loss: 1.35070515, g_loss: 0.62070328
Epoch: [11] [ 196/ 202] time: 19652.8372, d_loss: 1.37165880, g_loss: 0.80181694
Epoch: [11] [ 197/ 202] time: 19660.8017, d_loss: 1.60754871, g_loss: 0.37439129
Epoch: [11] [ 198/ 202] time: 19668.8304, d_loss: 1.70944226, g_loss: 0.47723258
Epoch: [11] [ 199/ 202] time: 19676.8461, d_loss: 1.55895352, g_loss: 0.59776264
Epoch: [11] [ 200/ 202] time: 19684.8700, d_loss: 1.88701093, g_loss: 0.36858952
Epoch: [11] [ 201/ 202] time: 19692.9321, d_loss: 1.50318146, g_loss: 0.54288507
Epoch: [12] [   0/ 202] time: 19701.1825, d_loss: 1.25389838, g_loss: 0.65852106
Epoch: [12] [   1/ 202] time: 19709.2263, d_loss: 1.37749708, g_loss: 0.69415295
Epoch: [12] [   2/ 202] time: 19717.2831, d_loss: 2.17204928, g_loss: 0.19365576
Epoch: [12] [   3/ 202] time: 19725.3309, d_loss: 1.47309911, g_loss: 0.96957207
Epoch: [12] [   4/ 202] time: 19733.3957, d_loss: 1.65452838, g_loss: 0.57950991
Epoch: [12] [   5/ 202] time: 19741.4802, d_loss: 1.64073670, g_loss: 0.47613505
Epoch: [12] [   6/ 202] time: 19749.6484, d_loss: 1.39178801, g_loss: 0.65342981
Epoch: [12] [   7/ 202] time: 19757.6014, d_loss: 1.53249860, g_loss: 0.45040691
Epoch: [12] [   8/ 202] time: 19765.6500, d_loss: 1.21742082, g_loss: 0.85059977
Epoch: [12] [   9/ 202] time: 19773.6661, d_loss: 1.34790993, g_loss: 0.76468492
Epoch: [12] [  10/ 202] time: 19781.9301, d_loss: 1.38487542, g_loss: 0.37774438
Epoch: [12] [  11/ 202] time: 19790.0305, d_loss: 1.98683846, g_loss: 0.34843731
Epoch: [12] [  12/ 202] time: 19798.0385, d_loss: 1.88296723, g_loss: 0.34734869
Epoch: [12] [  13/ 202] time: 19806.0333, d_loss: 1.43522418, g_loss: 1.01331639
Epoch: [12] [  14/ 202] time: 19814.0478, d_loss: 1.96666265, g_loss: 0.38906080
Epoch: [12] [  15/ 202] time: 19822.0244, d_loss: 1.79176879, g_loss: 0.36514160
Epoch: [12] [  16/ 202] time: 19829.9626, d_loss: 1.91311824, g_loss: 0.39570075
Epoch: [12] [  17/ 202] time: 19837.9559, d_loss: 1.28791380, g_loss: 0.95745981
Epoch: [12] [  18/ 202] time: 19845.9645, d_loss: 1.85505223, g_loss: 0.52731848
Epoch: [12] [  19/ 202] time: 19853.9175, d_loss: 1.34984064, g_loss: 0.33841765
Epoch: [12] [  20/ 202] time: 19861.9344, d_loss: 1.25572371, g_loss: 0.72221261
Epoch: [12] [  21/ 202] time: 19869.9160, d_loss: 1.11513352, g_loss: 0.88359565
Epoch: [12] [  22/ 202] time: 19877.9216, d_loss: 1.04577768, g_loss: 0.70219350
Epoch: [12] [  23/ 202] time: 19885.9217, d_loss: 1.40411472, g_loss: 0.49909705
Epoch: [12] [  24/ 202] time: 19893.9263, d_loss: 3.05176234, g_loss: 0.16545787
Epoch: [12] [  25/ 202] time: 19901.9479, d_loss: 3.54914045, g_loss: 2.04814625
Epoch: [12] [  26/ 202] time: 19909.9804, d_loss: 1.68407965, g_loss: 0.69127506
Epoch: [12] [  27/ 202] time: 19917.9421, d_loss: 2.63828540, g_loss: 0.18543908
Epoch: [12] [  28/ 202] time: 19925.9054, d_loss: 1.31157494, g_loss: 0.55755585
Epoch: [12] [  29/ 202] time: 19933.9379, d_loss: 1.51449919, g_loss: 0.96545535
Epoch: [12] [  30/ 202] time: 19941.9215, d_loss: 1.82476044, g_loss: 0.47141212
Epoch: [12] [  31/ 202] time: 19949.9251, d_loss: 2.56572938, g_loss: 0.19535854
Epoch: [12] [  32/ 202] time: 19957.8802, d_loss: 1.66081381, g_loss: 1.03715241
Epoch: [12] [  33/ 202] time: 19965.8761, d_loss: 2.19867396, g_loss: 0.59225166
Epoch: [12] [  34/ 202] time: 19973.8758, d_loss: 1.83208299, g_loss: 0.33737171
Epoch: [12] [  35/ 202] time: 19981.8615, d_loss: 1.51275504, g_loss: 0.71760392
Epoch: [12] [  36/ 202] time: 19989.7776, d_loss: 1.66312277, g_loss: 0.61586529
Epoch: [12] [  37/ 202] time: 19997.8380, d_loss: 1.31338501, g_loss: 0.69374311
Epoch: [12] [  38/ 202] time: 20005.8267, d_loss: 2.12923956, g_loss: 0.29948133
Epoch: [12] [  39/ 202] time: 20013.8084, d_loss: 1.54599929, g_loss: 0.88195324
Epoch: [12] [  40/ 202] time: 20021.8150, d_loss: 1.33097112, g_loss: 0.71355456
Epoch: [12] [  41/ 202] time: 20029.8096, d_loss: 1.75428009, g_loss: 0.35204095
Epoch: [12] [  42/ 202] time: 20037.8287, d_loss: 1.56021237, g_loss: 0.47930050
Epoch: [12] [  43/ 202] time: 20045.8704, d_loss: 1.51058435, g_loss: 0.91754168
Epoch: [12] [  44/ 202] time: 20053.8650, d_loss: 1.71379530, g_loss: 0.41672325
Epoch: [12] [  45/ 202] time: 20061.8341, d_loss: 1.83788836, g_loss: 0.30524623
Epoch: [12] [  46/ 202] time: 20069.8138, d_loss: 1.40304160, g_loss: 0.72826207
Epoch: [12] [  47/ 202] time: 20077.7924, d_loss: 1.45653164, g_loss: 0.51437706
Epoch: [12] [  48/ 202] time: 20085.7080, d_loss: 1.79456472, g_loss: 0.37806690
Epoch: [12] [  49/ 202] time: 20093.7036, d_loss: 1.50134683, g_loss: 0.74359095
Epoch: [12] [  50/ 202] time: 20101.7302, d_loss: 1.48155069, g_loss: 0.73582327
Epoch: [12] [  51/ 202] time: 20109.7537, d_loss: 1.39664042, g_loss: 0.47285664
Epoch: [12] [  52/ 202] time: 20117.7124, d_loss: 1.07052064, g_loss: 0.92990363
Epoch: [12] [  53/ 202] time: 20125.7290, d_loss: 1.19830346, g_loss: 0.90681088
Epoch: [12] [  54/ 202] time: 20133.6887, d_loss: 2.02165508, g_loss: 0.29284704
Epoch: [12] [  55/ 202] time: 20141.6245, d_loss: 1.57667565, g_loss: 0.70475543
Epoch: [12] [  56/ 202] time: 20149.5603, d_loss: 1.87018478, g_loss: 0.55505228
Epoch: [12] [  57/ 202] time: 20157.5345, d_loss: 1.54561901, g_loss: 0.57689381
Epoch: [12] [  58/ 202] time: 20165.5041, d_loss: 1.36110616, g_loss: 0.49001947
Epoch: [12] [  59/ 202] time: 20173.4917, d_loss: 1.26082504, g_loss: 0.77163053
Epoch: [12] [  60/ 202] time: 20181.5542, d_loss: 2.14418125, g_loss: 0.41327026
Epoch: [12] [  61/ 202] time: 20189.5306, d_loss: 1.77248693, g_loss: 0.47527549
Epoch: [12] [  62/ 202] time: 20197.4823, d_loss: 1.45935953, g_loss: 0.86098260
Epoch: [12] [  63/ 202] time: 20205.4540, d_loss: 1.33932471, g_loss: 0.43211833
Epoch: [12] [  64/ 202] time: 20213.4476, d_loss: 1.49397278, g_loss: 0.60400099
Epoch: [12] [  65/ 202] time: 20221.3992, d_loss: 1.74423754, g_loss: 0.55262184
Epoch: [12] [  66/ 202] time: 20229.4575, d_loss: 1.76993442, g_loss: 0.42982978
Epoch: [12] [  67/ 202] time: 20237.4132, d_loss: 1.49914503, g_loss: 0.78636366
Epoch: [12] [  68/ 202] time: 20245.3959, d_loss: 1.31892419, g_loss: 0.82260388
Epoch: [12] [  69/ 202] time: 20253.3811, d_loss: 1.61868608, g_loss: 0.39702374
Epoch: [12] [  70/ 202] time: 20261.3797, d_loss: 1.59223032, g_loss: 0.52889395
Epoch: [12] [  71/ 202] time: 20269.3928, d_loss: 1.53694642, g_loss: 0.68992400
Epoch: [12] [  72/ 202] time: 20277.3871, d_loss: 1.88314867, g_loss: 0.50733531
Epoch: [12] [  73/ 202] time: 20285.3568, d_loss: 2.01602364, g_loss: 0.31664407
Epoch: [12] [  74/ 202] time: 20293.3933, d_loss: 2.06908321, g_loss: 0.41094562
[Sample] d_loss: 1.43311977, g_loss: 0.75223309
Epoch: [12] [  75/ 202] time: 20303.3835, d_loss: 1.66711318, g_loss: 0.53877860
Epoch: [12] [  76/ 202] time: 20311.9636, d_loss: 1.78698325, g_loss: 0.57694089
Epoch: [12] [  77/ 202] time: 20319.9739, d_loss: 1.67322242, g_loss: 0.41851562
Epoch: [12] [  78/ 202] time: 20327.9341, d_loss: 1.44889390, g_loss: 0.65828788
Epoch: [12] [  79/ 202] time: 20335.9324, d_loss: 1.54002547, g_loss: 0.52956408
Epoch: [12] [  80/ 202] time: 20343.9147, d_loss: 1.60702729, g_loss: 0.49530268
Epoch: [12] [  81/ 202] time: 20351.9244, d_loss: 1.56394482, g_loss: 0.65653092
Epoch: [12] [  82/ 202] time: 20359.9033, d_loss: 1.91212177, g_loss: 0.34361973
Epoch: [12] [  83/ 202] time: 20367.8839, d_loss: 1.95543540, g_loss: 0.34750170
Epoch: [12] [  84/ 202] time: 20375.8771, d_loss: 1.72083557, g_loss: 0.82824749
Epoch: [12] [  85/ 202] time: 20383.8752, d_loss: 2.31822777, g_loss: 0.27423286
Epoch: [12] [  86/ 202] time: 20391.8299, d_loss: 1.66295314, g_loss: 0.47800016
Epoch: [12] [  87/ 202] time: 20399.7813, d_loss: 1.70258844, g_loss: 0.85461557
Epoch: [12] [  88/ 202] time: 20407.7041, d_loss: 1.97467351, g_loss: 0.31752566
Epoch: [12] [  89/ 202] time: 20415.7287, d_loss: 1.48700655, g_loss: 0.47541341
Epoch: [12] [  90/ 202] time: 20423.6764, d_loss: 1.54297733, g_loss: 0.47019207
Epoch: [12] [  91/ 202] time: 20431.6740, d_loss: 1.62038541, g_loss: 0.59918290
Epoch: [12] [  92/ 202] time: 20439.6986, d_loss: 1.55584109, g_loss: 0.60884917
Epoch: [12] [  93/ 202] time: 20447.6732, d_loss: 1.51934791, g_loss: 0.50303984
Epoch: [12] [  94/ 202] time: 20455.6250, d_loss: 1.34405065, g_loss: 0.53712320
Epoch: [12] [  95/ 202] time: 20463.6679, d_loss: 1.54299724, g_loss: 0.68546301
Epoch: [12] [  96/ 202] time: 20471.6566, d_loss: 1.20222282, g_loss: 0.83997023
Epoch: [12] [  97/ 202] time: 20479.6881, d_loss: 1.69572735, g_loss: 0.51246011
Epoch: [12] [  98/ 202] time: 20487.6767, d_loss: 1.76391804, g_loss: 0.32987100
Epoch: [12] [  99/ 202] time: 20495.6758, d_loss: 1.50368547, g_loss: 1.04147756
Epoch: [12] [ 100/ 202] time: 20503.7173, d_loss: 1.56167531, g_loss: 0.48558593
Epoch: [12] [ 101/ 202] time: 20511.7628, d_loss: 1.79270768, g_loss: 0.42304271
Epoch: [12] [ 102/ 202] time: 20519.7014, d_loss: 1.51236939, g_loss: 0.87804413
2022-06-09 21:55:35.932065: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 64.00MiB (rounded to 67108864).  Current allocation summary follows.
2022-06-09 21:55:35.934927: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (256):   Total Chunks: 80, Chunks in use: 80. 20.0KiB allocated for chunks. 20.0KiB in use in bin. 8.2KiB client-requested in use in bin.
2022-06-09 21:55:35.936656: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (512):   Total Chunks: 37, Chunks in use: 37. 18.5KiB allocated for chunks. 18.5KiB in use in bin. 18.5KiB client-requested in use in bin.
2022-06-09 21:55:35.937306: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (1024):  Total Chunks: 36, Chunks in use: 35. 36.3KiB allocated for chunks. 35.3KiB in use in bin. 35.0KiB client-requested in use in bin.
2022-06-09 21:55:35.941739: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (2048):  Total Chunks: 31, Chunks in use: 30. 63.5KiB allocated for chunks. 60.0KiB in use in bin. 60.0KiB client-requested in use in bin.
2022-06-09 21:55:35.942528: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (4096):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:35.943341: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (8192):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:35.944473: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (16384):         Total Chunks: 8, Chunks in use: 8. 150.0KiB allocated for chunks. 150.0KiB in use in bin. 150.0KiB client-requested in use in bin.
2022-06-09 21:55:35.945118: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (32768):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:35.946245: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (65536):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:35.953782: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (131072):        Total Chunks: 8, Chunks in use: 8. 1.12MiB allocated for chunks. 1.12MiB in use in bin. 1.00MiB client-requested in use in bin.
2022-06-09 21:55:35.954430: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (262144):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:35.955185: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (524288):        Total Chunks: 10, Chunks in use: 10. 7.81MiB allocated for chunks. 7.81MiB in use in bin. 7.81MiB client-requested in use in bin.
2022-06-09 21:55:35.955945: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (1048576):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:35.956667: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (2097152):       Total Chunks: 8, Chunks in use: 8. 25.00MiB allocated for chunks. 25.00MiB in use in bin. 25.00MiB client-requested in use in bin.
2022-06-09 21:55:35.957341: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (4194304):       Total Chunks: 1, Chunks in use: 0. 5.64MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:35.958085: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (8388608):       Total Chunks: 13, Chunks in use: 11. 150.81MiB allocated for chunks. 128.00MiB in use in bin. 128.00MiB client-requested in use in bin.
2022-06-09 21:55:35.959074: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (16777216):      Total Chunks: 10, Chunks in use: 9. 176.66MiB allocated for chunks. 160.66MiB in use in bin. 126.00MiB client-requested in use in bin.
2022-06-09 21:55:35.968050: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (33554432):      Total Chunks: 7, Chunks in use: 4. 281.71MiB allocated for chunks. 154.27MiB in use in bin. 128.00MiB client-requested in use in bin.
2022-06-09 21:55:35.969862: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (67108864):      Total Chunks: 8, Chunks in use: 8. 734.58MiB allocated for chunks. 734.58MiB in use in bin. 516.03MiB client-requested in use in bin.
2022-06-09 21:55:35.970567: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (134217728):     Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:35.971278: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (268435456):     Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:35.972344: I tensorflow/core/common_runtime/bfc_allocator.cc:885] Bin for 64.00MiB was 64.00MiB, Chunk State:
2022-06-09 21:55:35.972825: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 1048576
2022-06-09 21:55:35.973965: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501220000 next 1 of size 2048
2022-06-09 21:55:35.974480: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501220800 next 2 of size 256
2022-06-09 21:55:35.975296: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501220900 next 3 of size 131072
2022-06-09 21:55:35.976071: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501240900 next 4 of size 2048
2022-06-09 21:55:35.977058: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501241100 next 5 of size 2048

2022-06-09 21:55:36.306121: I tensorflow/core/common_runtime/bfc_allocator.cc:929] Stats:
Limit:                  1450826139
InUse:                  1270577920
MaxInUse:               1415519488
NumAllocs:                 2175184
MaxAllocSize:            376035584

2022-06-09 21:55:36.306776: W tensorflow/core/common_runtime/bfc_allocator.cc:424] **********************************xxxx********************xx****_******xxx****_********____******xxx
2022-06-09 21:55:36.307492: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 64.00MiB (rounded to 67108864).  Current allocation summary follows.
2022-06-09 21:55:36.308093: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (256):   Total Chunks: 80, Chunks in use: 80. 20.0KiB allocated for chunks. 20.0KiB in use in bin. 8.2KiB client-requested in use in bin.
2022-06-09 21:55:36.308725: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (512):   Total Chunks: 37, Chunks in use: 37. 18.5KiB allocated for chunks. 18.5KiB in use in bin. 18.5KiB client-requested in use in bin.
2022-06-09 21:55:36.309409: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (1024):  Total Chunks: 36, Chunks in use: 35. 36.3KiB allocated for chunks. 35.3KiB in use in bin. 35.0KiB client-requested in use in bin.
2022-06-09 21:55:36.309615: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at conv_grad_input_ops.cc:1209 : Resource exhausted: OOM when allocating tensor with shape[64,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
2022-06-09 21:55:36.310122: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (2048):  Total Chunks: 31, Chunks in use: 30. 63.5KiB allocated for chunks. 60.0KiB in use in bin. 60.0KiB client-requested in use in bin.
2022-06-09 21:55:36.311402: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (4096):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:36.312052: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (8192):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:36.312703: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (16384):         Total Chunks: 8, Chunks in use: 8. 150.0KiB allocated for chunks. 150.0KiB in use in bin. 150.0KiB client-requested in use in bin.
2022-06-09 21:55:36.313333: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (32768):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:36.313979: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (65536):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:36.314617: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (131072):        Total Chunks: 8, Chunks in use: 8. 1.12MiB allocated for chunks. 1.12MiB in use in bin. 1.00MiB client-requested in use in bin.
2022-06-09 21:55:36.315411: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (262144):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:36.316239: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (524288):        Total Chunks: 10, Chunks in use: 10. 7.81MiB allocated for chunks. 7.81MiB in use in bin. 7.81MiB client-requested in use in bin.
2022-06-09 21:55:36.317064: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (1048576):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:36.317963: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (2097152):       Total Chunks: 8, Chunks in use: 8. 25.00MiB allocated for chunks. 25.00MiB in use in bin. 25.00MiB client-requested in use in bin.
2022-06-09 21:55:36.328833: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (4194304):       Total Chunks: 1, Chunks in use: 0. 5.64MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:36.333051: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (8388608):       Total Chunks: 13, Chunks in use: 11. 150.81MiB allocated for chunks. 128.00MiB in use in bin. 128.00MiB client-requested in use in bin.
2022-06-09 21:55:36.333925: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (16777216):      Total Chunks: 10, Chunks in use: 9. 176.66MiB allocated for chunks. 160.66MiB in use in bin. 126.00MiB client-requested in use in bin.
2022-06-09 21:55:36.334614: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (33554432):      Total Chunks: 7, Chunks in use: 4. 281.71MiB allocated for chunks. 154.27MiB in use in bin. 128.00MiB client-requested in use in bin.
2022-06-09 21:55:36.335266: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (67108864):      Total Chunks: 8, Chunks in use: 8. 734.58MiB allocated for chunks. 734.58MiB in use in bin. 516.03MiB client-requested in use in bin.
2022-06-09 21:55:36.335869: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (134217728):     Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:36.336517: I tensorflow/core/common_runtime/bfc_allocator.cc:869] Bin (268435456):     Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-06-09 21:55:36.337584: I tensorflow/core/common_runtime/bfc_allocator.cc:885] Bin for 64.00MiB was 64.00MiB, Chunk State:
2022-06-09 21:55:36.338565: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 1048576
2022-06-09 21:55:36.339122: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501220000 next 1 of size 2048
2022-06-09 21:55:36.339704: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501220800 next 2 of size 256
2022-06-09 21:55:36.340257: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501220900 next 3 of size 131072
2022-06-09 21:55:36.340807: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501240900 next 4 of size 2048
2022-06-09 21:55:36.341367: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501241100 next 5 of size 2048
2022-06-09 21:55:36.341968: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501241900 next 6 of size 2048
2022-06-09 21:55:36.342508: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501242100 next 7 of size 2048
2022-06-09 21:55:36.343049: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501242900 next 8 of size 2048
2022-06-09 21:55:36.343702: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501243100 next 9 of size 2048
2022-06-09 21:55:36.344289: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501243900 next 10 of size 256
2022-06-09 21:55:36.344889: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501243A00 next 11 of size 1024
2022-06-09 21:55:36.345452: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501243E00 next 12 of size 1024
2022-06-09 21:55:36.346013: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501244200 next 13 of size 1024
2022-06-09 21:55:36.346546: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501244600 next 14 of size 1024
2022-06-09 21:55:36.347095: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501244A00 next 15 of size 256
2022-06-09 21:55:36.347681: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501244B00 next 16 of size 1024
2022-06-09 21:55:36.348661: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501244F00 next 17 of size 256
2022-06-09 21:55:36.356417: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501245000 next 18 of size 256
2022-06-09 21:55:36.357020: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501245100 next 19 of size 2048
2022-06-09 21:55:36.358545: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501245900 next 20 of size 512
2022-06-09 21:55:36.359117: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501245B00 next 21 of size 512
2022-06-09 21:55:36.359700: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501245D00 next 22 of size 512
2022-06-09 21:55:36.360265: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501245F00 next 23 of size 256
2022-06-09 21:55:36.360931: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501246000 next 24 of size 512
2022-06-09 21:55:36.361535: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501246200 next 25 of size 512
2022-06-09 21:55:36.362105: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501246400 next 26 of size 256
2022-06-09 21:55:36.362716: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501246500 next 27 of size 256
2022-06-09 21:55:36.363261: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501246600 next 28 of size 256
2022-06-09 21:55:36.363858: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501246700 next 29 of size 256
2022-06-09 21:55:36.364552: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501246800 next 30 of size 256
2022-06-09 21:55:36.365716: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501246900 next 31 of size 1024
2022-06-09 21:55:36.366732: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501246D00 next 32 of size 256
2022-06-09 21:55:36.372400: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501246E00 next 33 of size 256
2022-06-09 21:55:36.373022: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501246F00 next 34 of size 256
2022-06-09 21:55:36.373592: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501247000 next 35 of size 256
2022-06-09 21:55:36.374144: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501247100 next 36 of size 256
2022-06-09 21:55:36.374690: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501247200 next 37 of size 512
2022-06-09 21:55:36.375310: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501247400 next 38 of size 512
2022-06-09 21:55:36.375838: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501247600 next 39 of size 512
2022-06-09 21:55:36.376385: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501247800 next 40 of size 512
2022-06-09 21:55:36.376958: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501247A00 next 41 of size 512
2022-06-09 21:55:36.377601: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501247C00 next 42 of size 512
2022-06-09 21:55:36.378210: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501247E00 next 43 of size 256
2022-06-09 21:55:36.378767: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501247F00 next 44 of size 1024
2022-06-09 21:55:36.379344: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501248300 next 45 of size 1024
2022-06-09 21:55:36.379869: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501248700 next 46 of size 1024
2022-06-09 21:55:36.387749: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501248B00 next 47 of size 1024
2022-06-09 21:55:36.388299: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501248F00 next 48 of size 256
2022-06-09 21:55:36.389816: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501249000 next 49 of size 1024
2022-06-09 21:55:36.390470: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501249400 next 50 of size 256
2022-06-09 21:55:36.391049: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501249500 next 51 of size 256
2022-06-09 21:55:36.391599: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501249600 next 52 of size 256
2022-06-09 21:55:36.392239: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501249700 next 53 of size 2048
2022-06-09 21:55:36.392839: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501249F00 next 54 of size 2048
2022-06-09 21:55:36.393393: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050124A700 next 55 of size 2048
2022-06-09 21:55:36.393961: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050124AF00 next 56 of size 256
2022-06-09 21:55:36.394514: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050124B000 next 57 of size 256
2022-06-09 21:55:36.395159: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050124B100 next 58 of size 512
2022-06-09 21:55:36.395687: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050124B300 next 59 of size 1024
2022-06-09 21:55:36.396705: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050124B700 next 61 of size 131072
2022-06-09 21:55:36.403319: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050126B700 next 66 of size 19200
2022-06-09 21:55:36.405441: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501270200 next 67 of size 19200
2022-06-09 21:55:36.406057: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501274D00 next 70 of size 1280
2022-06-09 21:55:36.406645: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501275200 next 73 of size 512
2022-06-09 21:55:36.407201: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501275400 next 74 of size 256
2022-06-09 21:55:36.407780: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501275500 next 75 of size 2048
2022-06-09 21:55:36.408326: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501275D00 next 77 of size 1024
2022-06-09 21:55:36.408917: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501276100 next 78 of size 512
2022-06-09 21:55:36.409531: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501276300 next 79 of size 256
2022-06-09 21:55:36.410139: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501276400 next 80 of size 256
2022-06-09 21:55:36.410667: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501276500 next 81 of size 256
2022-06-09 21:55:36.411258: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501276600 next 82 of size 19200
2022-06-09 21:55:36.411872: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050127B100 next 83 of size 2048
2022-06-09 21:55:36.418151: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050127B900 next 84 of size 1024
2022-06-09 21:55:36.418794: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050127BD00 next 86 of size 19200
2022-06-09 21:55:36.420128: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501280800 next 87 of size 256
2022-06-09 21:55:36.420690: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501280900 next 88 of size 256
2022-06-09 21:55:36.421313: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501280A00 next 89 of size 256
2022-06-09 21:55:36.421884: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501280B00 next 90 of size 2048
2022-06-09 21:55:36.422428: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501281300 next 91 of size 2048
2022-06-09 21:55:36.422975: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501281B00 next 92 of size 1024
2022-06-09 21:55:36.423521: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501281F00 next 93 of size 256
2022-06-09 21:55:36.424068: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501282000 next 94 of size 2048
2022-06-09 21:55:36.424614: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501282800 next 95 of size 256
2022-06-09 21:55:36.425170: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501282900 next 96 of size 2048
2022-06-09 21:55:36.425715: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501283100 next 97 of size 256
2022-06-09 21:55:36.426276: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501283200 next 98 of size 1024
2022-06-09 21:55:36.427437: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501283600 next 99 of size 1024
2022-06-09 21:55:36.433847: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501283A00 next 100 of size 1024
2022-06-09 21:55:36.435379: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501283E00 next 101 of size 256
2022-06-09 21:55:36.435981: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501283F00 next 102 of size 512
2022-06-09 21:55:36.436546: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501284100 next 103 of size 19200
2022-06-09 21:55:36.437101: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501288C00 next 105 of size 512
2022-06-09 21:55:36.437661: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501288E00 next 106 of size 512
2022-06-09 21:55:36.438204: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501289000 next 107 of size 256
2022-06-09 21:55:36.438760: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501289100 next 108 of size 2048
2022-06-09 21:55:36.439379: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501289900 next 109 of size 512
2022-06-09 21:55:36.439923: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501289B00 next 110 of size 512
2022-06-09 21:55:36.440466: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501289D00 next 111 of size 1024
2022-06-09 21:55:36.441021: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050128A100 next 112 of size 19200
2022-06-09 21:55:36.441562: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050128EC00 next 113 of size 2048
2022-06-09 21:55:36.442313: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050128F400 next 115 of size 131072
2022-06-09 21:55:36.447724: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012AF400 next 117 of size 512
2022-06-09 21:55:36.449942: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012AF600 next 118 of size 512
2022-06-09 21:55:36.450492: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012AF800 next 119 of size 256
2022-06-09 21:55:36.451051: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012AF900 next 120 of size 256
2022-06-09 21:55:36.451562: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012AFA00 next 121 of size 256
2022-06-09 21:55:36.454246: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012AFB00 next 127 of size 512
2022-06-09 21:55:36.454781: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012AFD00 next 128 of size 512
2022-06-09 21:55:36.455302: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012AFF00 next 129 of size 512
2022-06-09 21:55:36.455808: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B0100 next 130 of size 1024
2022-06-09 21:55:36.456333: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B0500 next 131 of size 1024
2022-06-09 21:55:36.456850: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B0900 next 132 of size 1024
2022-06-09 21:55:36.457368: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B0D00 next 134 of size 256
2022-06-09 21:55:36.457884: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B0E00 next 136 of size 1024
2022-06-09 21:55:36.466188: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B1200 next 141 of size 512
2022-06-09 21:55:36.466652: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B1400 next 142 of size 512
2022-06-09 21:55:36.468074: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B1600 next 143 of size 512
2022-06-09 21:55:36.468695: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B1800 next 144 of size 1024
2022-06-09 21:55:36.469278: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B1C00 next 145 of size 2048
2022-06-09 21:55:36.469833: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B2400 next 146 of size 512
2022-06-09 21:55:36.470412: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B2600 next 147 of size 256
2022-06-09 21:55:36.471035: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B2700 next 149 of size 512
2022-06-09 21:55:36.471579: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B2900 next 151 of size 256
2022-06-09 21:55:36.472124: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B2A00 next 152 of size 1024
2022-06-09 21:55:36.472712: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B2E00 next 153 of size 19200
2022-06-09 21:55:36.473236: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012B7900 next 154 of size 19200
2022-06-09 21:55:36.473926: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012BC400 next 155 of size 1024
2022-06-09 21:55:36.479613: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012BC800 next 156 of size 1024
2022-06-09 21:55:36.480201: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012BCC00 next 157 of size 1024
2022-06-09 21:55:36.481924: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012BD000 next 159 of size 2048
2022-06-09 21:55:36.482947: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012BD800 next 160 of size 131072
2022-06-09 21:55:36.483517: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012DD800 next 161 of size 1024
2022-06-09 21:55:36.484041: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012DDC00 next 162 of size 2048
2022-06-09 21:55:36.484548: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012DE400 next 163 of size 512
2022-06-09 21:55:36.485072: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012DE600 next 164 of size 512
2022-06-09 21:55:36.485573: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012DE800 next 165 of size 256
2022-06-09 21:55:36.486081: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012DE900 next 166 of size 256
2022-06-09 21:55:36.486586: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012DEA00 next 167 of size 256
2022-06-09 21:55:36.487108: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012DEB00 next 168 of size 1024
2022-06-09 21:55:36.487629: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012DEF00 next 169 of size 1024
2022-06-09 21:55:36.488131: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012DF300 next 170 of size 1024
2022-06-09 21:55:36.488650: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012DF700 next 171 of size 2048
2022-06-09 21:55:36.489152: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012DFF00 next 172 of size 2048
2022-06-09 21:55:36.489974: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012E0700 next 173 of size 512
2022-06-09 21:55:36.495376: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012E0900 next 174 of size 512
2022-06-09 21:55:36.495957: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012E0B00 next 175 of size 2048
2022-06-09 21:55:36.497423: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012E1300 next 176 of size 2048
2022-06-09 21:55:36.498364: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005012E1B00 next 18446744073709551615 of size 255232
2022-06-09 21:55:36.499060: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 16777216
2022-06-09 21:55:36.499768: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000501320000 next 18446744073709551615 of size 16777216
2022-06-09 21:55:36.500392: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 16777216
2022-06-09 21:55:36.500974: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000502320000 next 18446744073709551615 of size 16777216
2022-06-09 21:55:36.501521: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 33554432
2022-06-09 21:55:36.502074: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000503320000 next 64 of size 3276800
2022-06-09 21:55:36.502639: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000503640000 next 65 of size 819200
2022-06-09 21:55:36.503180: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000503708000 next 68 of size 819200
2022-06-09 21:55:36.503725: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005037D0000 next 69 of size 3276800
2022-06-09 21:55:36.504270: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000503AF0000 next 18446744073709551615 of size 25362432
2022-06-09 21:55:36.504811: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 67108864
2022-06-09 21:55:36.505362: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000505320000 next 72 of size 3276800
2022-06-09 21:55:36.506351: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000505640000 next 76 of size 13107200
2022-06-09 21:55:36.515478: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005062C0000 next 85 of size 3276800
2022-06-09 21:55:36.517200: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005065E0000 next 104 of size 819200
2022-06-09 21:55:36.517889: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005066A8000 next 114 of size 13107200
2022-06-09 21:55:36.518486: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000507328000 next 116 of size 819200
2022-06-09 21:55:36.519026: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005073F0000 next 122 of size 819200
2022-06-09 21:55:36.519580: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005074B8000 next 123 of size 13107200
2022-06-09 21:55:36.520165: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000508138000 next 18446744073709551615 of size 18776064
2022-06-09 21:55:36.520882: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 134217728
2022-06-09 21:55:36.521430: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000509320000 next 125 of size 13107200
2022-06-09 21:55:36.522023: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000509FA0000 next 126 of size 3276800
2022-06-09 21:55:36.522566: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050A2C0000 next 133 of size 13107200
2022-06-09 21:55:36.523109: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050AF40000 next 135 of size 3276800
2022-06-09 21:55:36.523690: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050B260000 next 137 of size 3276800
2022-06-09 21:55:36.524242: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050B580000 next 138 of size 3276800
2022-06-09 21:55:36.524791: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050B8A0000 next 139 of size 13107200
2022-06-09 21:55:36.525349: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050C520000 next 140 of size 13107200
2022-06-09 21:55:36.526014: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050D1A0000 next 148 of size 819200
2022-06-09 21:55:36.526574: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050D268000 next 150 of size 819200
2022-06-09 21:55:36.527095: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050D330000 next 158 of size 13107200
2022-06-09 21:55:36.527615: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050DFB0000 next 177 of size 819200
2022-06-09 21:55:36.528121: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E078000 next 178 of size 2048
2022-06-09 21:55:36.528646: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E078800 next 179 of size 2048
2022-06-09 21:55:36.529157: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E079000 next 180 of size 256
2022-06-09 21:55:36.529681: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E079100 next 181 of size 1024
2022-06-09 21:55:36.530207: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E079500 next 182 of size 1024
2022-06-09 21:55:36.530709: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E079900 next 183 of size 2048
2022-06-09 21:55:36.531242: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E07A100 next 184 of size 2048
2022-06-09 21:55:36.531890: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E07A900 next 185 of size 131072
2022-06-09 21:55:36.532551: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E09A900 next 186 of size 131072
2022-06-09 21:55:36.533329: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E0BA900 next 187 of size 131072
2022-06-09 21:55:36.533996: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E0DA900 next 188 of size 512
2022-06-09 21:55:36.534559: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E0DAB00 next 189 of size 256
2022-06-09 21:55:36.535073: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E0DAC00 next 190 of size 256
2022-06-09 21:55:36.543104: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E0DAD00 next 217 of size 256
2022-06-09 21:55:36.549771: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E0DAE00 next 218 of size 256
2022-06-09 21:55:36.550910: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E0DAF00 next 214 of size 256
2022-06-09 21:55:36.551538: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E0DB000 next 215 of size 256
2022-06-09 21:55:36.552367: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E0DB100 next 208 of size 256
2022-06-09 21:55:36.557006: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E0DB200 next 209 of size 256
2022-06-09 21:55:36.557721: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E0DB300 next 213 of size 256
2022-06-09 21:55:36.558474: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E0DB400 next 219 of size 256
2022-06-09 21:55:36.559074: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E0DB500 next 211 of size 256
2022-06-09 21:55:36.559661: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E0DB600 next 221 of size 8388608
2022-06-09 21:55:36.560183: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000050E8DB600 next 18446744073709551615 of size 44321280
2022-06-09 21:55:36.560697: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 268435456
2022-06-09 21:55:36.561204: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000511320000 next 222 of size 16777216
2022-06-09 21:55:36.561739: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000512320000 next 207 of size 67108864
2022-06-09 21:55:36.562240: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000516320000 next 220 of size 256
2022-06-09 21:55:36.562768: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000516320100 next 216 of size 256
2022-06-09 21:55:36.563268: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000516320200 next 192 of size 256
2022-06-09 21:55:36.563807: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000516320300 next 239 of size 256
2022-06-09 21:55:36.564316: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000516320400 next 226 of size 256
2022-06-09 21:55:36.565000: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000516320500 next 196 of size 256
2022-06-09 21:55:36.565649: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000516320600 next 253 of size 256
2022-06-09 21:55:36.566508: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000516320700 next 231 of size 256
2022-06-09 21:55:36.567161: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000516320800 next 199 of size 256
2022-06-09 21:55:36.568065: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000516320900 next 202 of size 256
2022-06-09 21:55:36.576962: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000516320A00 next 223 of size 256
2022-06-09 21:55:36.578465: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000516320B00 next 228 of size 16777216
2022-06-09 21:55:36.579008: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000517320B00 next 212 of size 8388608
2022-06-09 21:55:36.579569: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000517B20B00 next 240 of size 33554432
2022-06-09 21:55:36.580146: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000519B20B00 next 18446744073709551615 of size 125826304
2022-06-09 21:55:36.580688: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 536870912
2022-06-09 21:55:36.581567: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000521FE0000 next 233 of size 16777216
2022-06-09 21:55:36.582206: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000522FE0000 next 244 of size 67108864
2022-06-09 21:55:36.582890: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000526FE0000 next 248 of size 69222400
2022-06-09 21:55:36.584154: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000052B1E4000 next 191 of size 67108864
2022-06-09 21:55:36.584838: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000052F1E4000 next 254 of size 123748352
2022-06-09 21:55:36.585660: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005367E8000 next 273 of size 33554432
2022-06-09 21:55:36.592040: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000005387E8000 next 266 of size 33554432
2022-06-09 21:55:36.592661: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000053A7E8000 next 18446744073709551615 of size 125796352
2022-06-09 21:55:36.593222: I tensorflow/core/common_runtime/bfc_allocator.cc:898] Next region of size 376035584
2022-06-09 21:55:36.593905: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000541FE0000 next 230 of size 256
2022-06-09 21:55:36.594479: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000541FE0100 next 245 of size 256
2022-06-09 21:55:36.595020: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000541FE0200 next 256 of size 256
2022-06-09 21:55:36.595531: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000541FE0300 next 203 of size 256
2022-06-09 21:55:36.596057: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000541FE0400 next 224 of size 256
2022-06-09 21:55:36.596565: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000541FE0500 next 242 of size 256
2022-06-09 21:55:36.597084: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000541FE0600 next 205 of size 256
2022-06-09 21:55:36.597609: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000541FE0700 next 260 of size 256
2022-06-09 21:55:36.598251: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000541FE0800 next 194 of size 256
2022-06-09 21:55:36.598896: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000541FE0900 next 247 of size 256
2022-06-09 21:55:36.599735: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000541FE0A00 next 197 of size 256
2022-06-09 21:55:36.605460: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000541FE0B00 next 236 of size 256
2022-06-09 21:55:36.606114: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000541FE0C00 next 259 of size 256
2022-06-09 21:55:36.607582: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000541FE0D00 next 225 of size 13434624
2022-06-09 21:55:36.608172: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000542CB0C00 next 198 of size 512
2022-06-09 21:55:36.608763: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000542CB0E00 next 262 of size 512
2022-06-09 21:55:36.609340: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000542CB1000 next 243 of size 1024
2022-06-09 21:55:36.609909: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000542CB1400 next 268 of size 512
2022-06-09 21:55:36.610588: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000542CB1600 next 276 of size 3584
2022-06-09 21:55:36.611213: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000542CB2400 next 270 of size 819200
2022-06-09 21:55:36.611822: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000542D7A400 next 232 of size 819200
2022-06-09 21:55:36.612395: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000542E42400 next 279 of size 5917952
2022-06-09 21:55:36.612989: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000005433E7100 next 238 of size 12582912
2022-06-09 21:55:36.613574: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000543FE7100 next 246 of size 16777216
2022-06-09 21:55:36.614141: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000544FE7100 next 206 of size 33554432
2022-06-09 21:55:36.615295: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000546FE7100 next 241 of size 50331648
2022-06-09 21:55:36.615868: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000549FE7100 next 258 of size 23658496
2022-06-09 21:55:36.621418: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 000000054B677100 next 267 of size 10485760
2022-06-09 21:55:36.622061: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000054C077100 next 250 of size 16777216
2022-06-09 21:55:36.623550: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 000000054D077100 next 252 of size 66519040
2022-06-09 21:55:36.624156: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000550FE7100 next 18446744073709551615 of size 124348416
2022-06-09 21:55:36.624706: I tensorflow/core/common_runtime/bfc_allocator.cc:914]      Summary of in-use Chunks by size:
2022-06-09 21:55:36.625339: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 80 Chunks of size 256 totalling 20.0KiB
2022-06-09 21:55:36.625948: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 37 Chunks of size 512 totalling 18.5KiB
2022-06-09 21:55:36.626471: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 34 Chunks of size 1024 totalling 34.0KiB
2022-06-09 21:55:36.626982: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1280 totalling 1.3KiB
2022-06-09 21:55:36.627504: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 30 Chunks of size 2048 totalling 60.0KiB
2022-06-09 21:55:36.628010: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 8 Chunks of size 19200 totalling 150.0KiB
2022-06-09 21:55:36.628541: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 7 Chunks of size 131072 totalling 896.0KiB
2022-06-09 21:55:36.629127: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 255232 totalling 249.3KiB
2022-06-09 21:55:36.629602: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 10 Chunks of size 819200 totalling 7.81MiB
2022-06-09 21:55:36.630247: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 8 Chunks of size 3276800 totalling 25.00MiB
2022-06-09 21:55:36.636632: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 8388608 totalling 16.00MiB
2022-06-09 21:55:36.638093: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 12582912 totalling 12.00MiB
2022-06-09 21:55:36.638706: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 8 Chunks of size 13107200 totalling 100.00MiB
2022-06-09 21:55:36.639276: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 6 Chunks of size 16777216 totalling 96.00MiB
2022-06-09 21:55:36.639828: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 18776064 totalling 17.91MiB
2022-06-09 21:55:36.640399: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 23658496 totalling 22.56MiB
2022-06-09 21:55:36.640944: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 25362432 totalling 24.19MiB
2022-06-09 21:55:36.641492: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 33554432 totalling 64.00MiB
2022-06-09 21:55:36.642054: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 44321280 totalling 42.27MiB
2022-06-09 21:55:36.642604: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 50331648 totalling 48.00MiB
2022-06-09 21:55:36.643148: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 3 Chunks of size 67108864 totalling 192.00MiB
2022-06-09 21:55:36.643835: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 69222400 totalling 66.02MiB
2022-06-09 21:55:36.644403: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 123748352 totalling 118.02MiB
2022-06-09 21:55:36.644947: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 124348416 totalling 118.59MiB
2022-06-09 21:55:36.645781: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 125796352 totalling 119.97MiB
2022-06-09 21:55:36.651421: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 125826304 totalling 120.00MiB
2022-06-09 21:55:36.652906: I tensorflow/core/common_runtime/bfc_allocator.cc:921] Sum Total of in-use chunks: 1.18GiB
2022-06-09 21:55:36.653511: I tensorflow/core/common_runtime/bfc_allocator.cc:923] total_region_allocated_bytes_: 1450825984 memory_limit_: 1450826139 available bytes: 155 curr_region_allocation_bytes_: 2147483648
2022-06-09 21:55:36.654107: I tensorflow/core/common_runtime/bfc_allocator.cc:929] Stats:
Limit:                  1450826139
InUse:                  1270577920
MaxInUse:               1415519488
NumAllocs:                 2175184
MaxAllocSize:            376035584

2022-06-09 21:55:36.654764: W tensorflow/core/common_runtime/bfc_allocator.cc:424] **********************************xxxx********************xx****_******xxx****_********____******xxx
2022-06-09 21:55:36.655382: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at conv_grad_input_ops.cc:1209 : Resource exhausted: OOM when allocating tensor with shape[64,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
Traceback (most recent call last):
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\client\session.py", line 1365, in _do_call
    return fn(*args)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\client\session.py", line 1350, in _run_fn
    target_list, run_metadata)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\client\session.py", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[64,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[{{node gradients/discriminator_1/d_h1_conv/Conv2D_grad/Conv2DBackpropInput}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "main.py", line 123, in <module>
    tf.compat.v1.app.run()
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\platform\app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "D:\python3.10\lib\site-packages\absl\app.py", line 312, in run
    _run_main(main, args)
  File "D:\python3.10\lib\site-packages\absl\app.py", line 258, in _run_main
    sys.exit(main(argv))
  File "main.py", line 106, in main
    dcgan.train(FLAGS)
  File "C:\Users\admin\Desktop\Person-reid-GAN-pytorch-master\DCGAN-tensorflow\model.py", line 265, in train
    _, summary_str = self.sess.run([d_optim, self.d_sum],
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\client\session.py", line 956, in run
    run_metadata_ptr)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\client\session.py", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\client\session.py", line 1359, in _do_run
    run_metadata)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\client\session.py", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[64,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[node gradients/discriminator_1/d_h1_conv/Conv2D_grad/Conv2DBackpropInput (defined at D:\python3.10\lib\site-packages\tensorflow_core\python\framework\ops.py:1748) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.


Original stack trace for 'gradients/discriminator_1/d_h1_conv/Conv2D_grad/Conv2DBackpropInput':
  File "main.py", line 123, in <module>
    tf.compat.v1.app.run()
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\platform\app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "D:\python3.10\lib\site-packages\absl\app.py", line 312, in run
    _run_main(main, args)
  File "D:\python3.10\lib\site-packages\absl\app.py", line 258, in _run_main
    sys.exit(main(argv))
  File "main.py", line 106, in main
    dcgan.train(FLAGS)
  File "C:\Users\admin\Desktop\Person-reid-GAN-pytorch-master\DCGAN-tensorflow\model.py", line 154, in train
    d_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\training\optimizer.py", line 403, in minimize
    grad_loss=grad_loss)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\training\optimizer.py", line 512, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\ops\gradients_impl.py", line 158, in gradients
    unconnected_gradients)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\ops\gradients_util.py", line 679, in _GradientsHelper
    lambda: grad_fn(op, *out_grads))
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\ops\gradients_util.py", line 350, in _MaybeCompile
    return grad_fn()  # Exit early
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\ops\gradients_util.py", line 679, in <lambda>
    lambda: grad_fn(op, *out_grads))
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\ops\nn_grad.py", line 596, in _Conv2DGrad
    data_format=data_format),
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\ops\gen_nn_ops.py", line 1407, in conv2d_backprop_input
    name=name)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\framework\op_def_library.py", line 794, in _apply_op_helper
    op_def=op_def)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\util\deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\framework\ops.py", line 3357, in create_op
    attrs, op_def, compute_device)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\framework\ops.py", line 3426, in _create_op_internal
    op_def=op_def)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\framework\ops.py", line 1748, in __init__
    self._traceback = tf_stack.extract_stack()

...which was originally created as op 'discriminator_1/d_h1_conv/Conv2D', defined at:
  File "main.py", line 123, in <module>
    tf.compat.v1.app.run()
[elided 2 identical lines from previous traceback]
  File "D:\python3.10\lib\site-packages\absl\app.py", line 258, in _run_main
    sys.exit(main(argv))
  File "main.py", line 101, in main
    sample_dir=FLAGS.sample_dir)
  File "C:\Users\admin\Desktop\Person-reid-GAN-pytorch-master\DCGAN-tensorflow\model.py", line 93, in __init__
  File "C:\Users\admin\Desktop\Person-reid-GAN-pytorch-master\DCGAN-tensorflow\model.py", line 118, in build_model
    self.sampler            = self.sampler(self.z, self.y)
  File "C:\Users\admin\Desktop\Person-reid-GAN-pytorch-master\DCGAN-tensorflow\model.py", line 325, in discriminator
    h0 = lrelu(conv2d(image, self.df_dim, name='d_h0_conv'))
  File "C:\Users\admin\Desktop\Person-reid-GAN-pytorch-master\DCGAN-tensorflow\ops.py", line 67, in conv2d
    conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\ops\nn_ops.py", line 2010, in conv2d
    name=name)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\ops\gen_nn_ops.py", line 1071, in conv2d
    data_format=data_format, dilations=dilations, name=name)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\framework\op_def_library.py", line 794, in _apply_op_helper
    op_def=op_def)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\util\deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\framework\ops.py", line 3357, in create_op
    attrs, op_def, compute_device)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\framework\ops.py", line 3426, in _create_op_internal
    op_def=op_def)
  File "D:\python3.10\lib\site-packages\tensorflow_core\python\framework\ops.py", line 1748, in __init__
    self._traceback = tf_stack.extract_stack()